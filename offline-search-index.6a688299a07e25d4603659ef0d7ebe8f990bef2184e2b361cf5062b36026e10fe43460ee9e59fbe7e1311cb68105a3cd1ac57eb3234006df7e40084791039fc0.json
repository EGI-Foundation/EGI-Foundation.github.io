[{"body":"Jupyter is an extensible environment that supports different programming languages. Each language is available as a different kernel.\nFor the EGI service we have enabled a set of kernels that are automatically built from the EGI-Foundation/egi-notebooks-images GitHub repository.\nPython Default Python 3 kernel, it includes commonly used data analysis and machine learning libraries. Created from the jupyter/scipy-notebook stack.\nDIRAC / Python 2 A python 2 kernel that includes a DIRAC installation for interacting with the EGI Workload Manager service.\nJulia The Julia programming language with the libraries described in jupyter/datascience-notebook.\nR The R programming language with several packages from the R ecosystem as provided by jupyter/r-notebook and some extra libraries.\nOctave The Octave programming language installed on its own conda environment (named octave).\nYour own kernel If you want to add a new kernel, just let us know and we will discuss the best way to support your request.\n","excerpt":"Jupyter is an extensible environment that supports different programming languages. Each language is …","ref":"/users/notebooks/kernels/","title":"Notebooks Kernels"},{"body":"The EGI Applications on Demand (AoD) service is EGI\u0026rsquo;s response to the requirements of researchers who are interested in using applications in a on-demand fashion together with the compute and storage environment needed to compute and store data.\nYou can order and access the service through the EGI Marketplace.\nService Description The service combines compute and storage cloud with Application-development and hosting frameworks to run custom scientific applications, and/or to turn those into applications into online data analysis services that can be accessed by scientists worldwide.\nThe portfolio of applications is currently composed by a readily available set of applications relevant to different scientific and research areas. This portfolio is open to be extended thanks to the contributions of users of the service. If you are interested in this, please get in touch with us: support (at) egi.eu\nIntended user groups The main target groups of this service are:\n Application developers who want to make their applications and tools accessible in a scalable way for researchers internationally. Algorithm developers (researchers) who want to run their own codes at scale in a compute cloud.  The main target groups of the applications that are already hosted in this service are:\n Researchers and innovators who want to run a specific scientific application that is already available in the platform.  Scientific applications The scientific applications that are already available in this service are:\n  Chipster a user-friendly analysis software for high-throughput data. It contains over 300 analysis tools for next generation sequencing (NGS), microarray, proteomics and sequence data. The application is available through the Science Software on Demand Service (SSoD). Instructions to run the application are available here.\n  NAMD a parallel molecular dynamics code designed for high-performance simulation of large bio-molecular systems. The application is available through the EC3 portal.\n  ECAS a complete environment enabling data analysis experiments from the ENES Climate Analytics Service.\n  The service includes:\n  Cloud compute and storage resources to host and scale up scientific applications.\n  Cloud access and application-hosting frameworks (to run and to operate your own scientific application in the cloud environment): that offer integrated development environments to port custom applications with cloud resources.\n  VMOps dashboard: a graphical environment for the management of Virtual Machines (VM) in the federated network of clouds that enable the Applications on Demand service. User documentation is available here.\n  Elastic Cloud Compute Cluster (EC3): a portal that allows the creation of elastic virtual clusters in the cloud. Those clusters can then host your scientific application either directly, or via Apache Mesos, Chronos, Kubernetes, Marathon, OSCAR or SLURM. Instructions for application developers are available here.\n  Science Software on Demand (SSoD): a programmable interface of a RESTful API Server to provide an easy access PaaS layer by leveraging recent Web technologies. Instructions for application developers are available here\n  Requirements and user registration The service is open for any scientific software developer who needs a scalable and user-friendly application execution and hosting environment to offer data/compute intensive scientific applications online.\nAccess requires acceptance of Acceptable Use Policy (AUP) and Conditions of the 'EGI Applications on Demand Service'.\nAcknowledgment Users of the service are asked to provide appropriate acknowledgement of the use in scientific publications. The following acknowledgement text can be used for this purpose:\nThis work used the EGI Applications on Demand service, which is co-funded by the EOSC-hub project (grant number 777536). The HNSciCloud project (grant number 687614) is also sponsoring the service, allowing users to access the HNSciCloud services pilot for limited scale usage using the voucher schemes provided by the Exoscale contractor.\n When requesting access to AoD users are guided through a lightweight registration process. Members of the EGI support team will perform a lightweight vetting process to validate the users' requests before granting the access to the resources.\nService grant Once granted access, each user will have a grant with a pre-defined quota of resources, which can be used to run the application of choice. This grant includes:\n up to 4 CPU cores, 8 GB of RAM, 100GB of block storage.  The grant to run applications is initially valid for 6 months and can be extended/renewed upon request.\nHow can you access the service?  Login to the EGI Marketplace with the EGI AAI Check-In service. Setup a profile, including details about your affiliation and role within a research institute/project/team. Navigate the marketplace top-menu and click on the category: Applications. Click on the Applications on Demand service and submit an order for one of the available applications. When the request is approved, run the requested application(s) as described below.  Please check the EGI Marketplace guide for further details.\nReferences Main scientific paper describing the service and status:\n EGI Applications On Demand Service - Catering for the computational needs of the long tail of science (May 2017). IWSG2017 Proceeding.  Presentations about the service:\n Slideset about the Applications on Demand (AoD) service introduced at IWSG 2017 (June 2017). Webinar to introduce the Applicatios on Demand (AoD) service to NGIs/USTs representatives, RI architects, resource providers and researchers (June 2017). Slideset about the status report of the platform at the EGI Conference 2016. Slideset about the status report of the EGI platform at the DI4R Conference 2016. Overview of the EGI Infrastructure for serving the long tail (EGI Community Forum, November 2015). Poster and animated slides from Demo at EGI Community Forum, November 2015 (Winner of best demo prize). Slideset about the authentication and authorization model adopted (from Nov. 2015). Slideset about the concept of the EGI long-tail of science platform (from Nov. 2014).  ","excerpt":"The EGI Applications on Demand (AoD) service is EGI\u0026rsquo;s response to the requirements of …","ref":"/users/applications-on-demand/aod/","title":"Applications on Demand (AoD)"},{"body":"The EGI Notebooks service relies on the following technologies to provide its functionality:\n JupyterHub with custom EGI Check-in oauthentication configured to spawn pods on Kubernetes. Kubernetes as container orchestration platform running on top of EGI Cloud resources. Within the service it is in charge of managing the allocated resources and providing the right abstraction to deploy the containers that build the service. Resources are provided by EGI Federated Cloud providers, including persistent storage for users notebooks. CA authority to allocate recognised certificates for the HTTPS server Prometheus for monitoring resource consumption. Specific EGI hooks for monitoring, accounting and backup. VO-Specific storage/Big data facilities or any pluggable tools into the notebooks environment can be added to community specific instances.  Kubernetes A Kubernetes (k8s) cluster deployed into a resource provider is in charge of managing the containers that will provide the service. On this cluster there are:\n 1 master node that manages the whole cluster Support for load balancer or alternatively 1 or more edge nodes with a public IP and corresponding public DNS name (e.g. notebooks.egi.eu) where a k8s ingress HTTP reverse proxy redirects requests from user to other components of the service. The HTTP server has a valid certificate from one CA recognised at most browsers (e.g. Let's Encrypt). 1 or more nodes that host the JupyterHub server, the notebooks servers where the users will run their notebooks. Hub is deployed using the JupyterHub helm charts. These nodes should have enough capacity to run as many concurrent user notebooks as needed. Main constraint is usually memory. Support for Kubernetes PersistentVolumeClaims for storing the persistent folders. Default EGI-Notebooks installation uses NFS, but any other volume type with ReadWriteOnce capabilities can be used. Prometheus installation to monitor the usage of resources so accounting records are generated.  All communication with the user goes via HTTPS and the service only needs a publicly accessible entry point (public IP with resolvable name)\nMonitoring and accounting are provided by hooking into the respective monitoring and accounting EGI services.\nThere are no specific hardware requirements and the whole environment can run on commodity virtual machines.\nEGI Customisations EGI Notebooks is deployed as a set of customisations of the JupyterHub helm charts.\nAuthentication EGI Check-in can be easily configured as a OAuth2.0 provider for JupyterHub's oauthenticator. See below a sample configuration for the helm chart using Check-in production environment:\nhub: extraEnv: OAUTH2_AUTHORIZE_URL: https://aai.egi.eu/oidc/authorize OAUTH2_TOKEN_URL: https://aai.egi.eu/oidc/token OAUTH_CALLBACK_URL: https://\u0026lt;your host\u0026gt;/hub/oauth_callback auth: type: custom custom: className: oauthenticator.generic.GenericOAuthenticator config: login_service: \u0026quot;EGI Check-in\u0026quot; client_id: \u0026quot;\u0026lt;your client id\u0026gt;\u0026quot; client_secret: \u0026quot;\u0026lt;your client secret\u0026gt;\u0026quot; oauth_callback_url: \u0026quot;https://\u0026lt;your host\u0026gt;/hub/oauth_callback\u0026quot; username_key: \u0026quot;sub\u0026quot; token_url: \u0026quot;https://aai.egi.eu/oidc/token\u0026quot; userdata_url: \u0026quot;https://aai.egi.eu/oidc/userinfo\u0026quot; scope: [\u0026quot;openid\u0026quot;, \u0026quot;profile\u0026quot;, \u0026quot;email\u0026quot;, \u0026quot;eduperson_scoped_affiliation\u0026quot;, \u0026quot;eduperson_entitlement\u0026quot;] To simplify the configuration and to add refresh capabilities to the credentials, we have created a new EGI Check-in authenticator that can be configued as follows:\nauth: state: enabled: true cryptoKey: \u0026lt;some unique crypto key\u0026gt; type: custom custom: className: oauthenticator.egicheckin.EGICheckinAuthenticator config: client_id: \u0026quot;\u0026lt;your client id\u0026gt;\u0026quot; client_secret: \u0026quot;\u0026lt;your client secret\u0026gt;\u0026quot; oauth_callback_url: \u0026quot;https://\u0026lt;your host\u0026gt;/hub/oauth_callback\u0026quot; scope: [\u0026quot;openid\u0026quot;, \u0026quot;profile\u0026quot;, \u0026quot;email\u0026quot;, \u0026quot;offline_access\u0026quot;, \u0026quot;eduperson_scoped_affiliation\u0026quot;, \u0026quot;eduperson_entitlement\u0026quot;] The auth.state configuration allows to store refresh tokens for the users that will allow to get up-to-date valid credentials as needed.\nAccounting Warning This is Work in progress, expect changes!  Accounting module generates VM-like accounting records for each of the notebooks started at the service. It's available as a helm chart that can be deployed in the same namespace as the JupyterHub chart. The only needed configuration for the chart is an IGTF-recognised certificate for the host registered in GOCDB as accounting.\nssm: hostcert: |- \u0026lt;hostcert\u0026gt; hostkey: |- \u0026lt;hostkey\u0026gt; Monitoring Monitoring is performed by trying to execute a user notebook every hour. This is accomplished by registering a new service in the hub that has admin permissions. Monitoring is then deployed as a helm chart that must be deployed in the same namespace as the JupyterHub chart. Configuration of JupyterHub must include this section:\nhub: services: status: url: \u0026quot;http://status-web/\u0026quot; admin: true apiToken: \u0026quot;\u0026lt;a unique API token\u0026gt;\u0026quot; Likewise the monitoring chart is configured as follows:\nservice: api_token: \u0026quot;\u0026lt;same API token as above\u0026gt;\u0026quot; Docker images Our service relies on custom images for the hub and the single-user notebooks. Dockerfiles are available at EGI Notebooks images git repository and automatically build for every commit pushed to the repo to eginotebooks @ dockerhub.\nHub image Builds from the JupyterHub k8s-hub image and adds:\n EGI and D4Science authenticators EGISpawner EGI look and feel for the login page  Single-user image Builds from Jupyter datasicence-notebook and adds a wide range of libraries as requested by users of the services. We are currently looking into alternatives for better managing this image with CVMFS as a possible solution.\nSample helm configuration If you want to build your own EGI Notebooks instance, you can start from the following sample configuration and adapt to your needs by setting:\n secret tokens (for proxy.secretToken, hub.services.status.api_token, auth.state.cryptoKey). They can be generated with openssl rand -hex 32. A valid host name (\u0026lt;your notebooks host\u0026gt; below) that resolves to your Kubernetes Ingress Valid EGI Check-in client credentials, these can be obtained by creating a new client at EGI AAI OpenID Connect Provider. When moving to EGI Check-in production environment, make sure to remove the hub.extraEnv.EGICHECKIN_HOST variable.  --- proxy: secretToken: \u0026quot;\u0026lt;some secret\u0026gt;\u0026quot; service: type: NodePort ingress: enabled: true annotations: kubernetes.io/tls-acme: \u0026quot;true\u0026quot; hosts: [\u0026lt;your notebooks host\u0026gt;] tls: - hosts: - \u0026lt;your notebooks host\u0026gt; secretName: acme-tls-notebooks enabled: true hosts: [\u0026lt;your notebooks host\u0026gt;] singleuser: storage: capacity: 1Gi dynamic: pvcNameTemplate: claim-{userid}{servername} volumeNameTemplate: vol-{userid}{servername} storageAccessModes: [\u0026quot;ReadWriteMany\u0026quot;] memory: limit: 1G guarantee: 512M cpu: limit: 2 guarantee: .02 defaultUrl: \u0026quot;/lab\u0026quot; image: name: eginotebooks/single-user tag: c1b2a2a hub: image: name: eginotebooks/hub tag: c1b2a2a extraConfig: enable-lab: |- c.KubeSpawner.cmd = ['jupyter-labhub'] volume-handling: |- from egispawner.spawner import EGISpawner c.JupyterHub.spawner_class = EGISpawner extraEnv: JUPYTER_ENABLE_LAB: 1 EGICHECKIN_HOST: aai-dev.egi.eu services: status: url: \u0026quot;http://status-web/\u0026quot; admin: true api_token: \u0026quot;\u0026lt;monitor token\u0026gt;\u0026quot; auth: type: custom state: enabled: true cryptoKey: \u0026quot;\u0026lt;a unique crypto key\u0026gt;\u0026quot; admin: access: true users: [\u0026lt;list of EGI Check-in users with admin powers\u0026gt;] custom: className: oauthenticator.egicheckin.EGICheckinAuthenticator config: client_id: \u0026quot;\u0026lt;your egi checkin_client_id\u0026gt;\u0026quot; client_secret: \u0026quot;\u0026lt;your egi checkin_client_secret\u0026gt;\u0026quot; oauth_callback_url: \u0026quot;https://\u0026lt;your notebooks host\u0026gt;/hub/oauth_callback\u0026quot; enable_auth_state: true scope: [\u0026quot;openid\u0026quot;, \u0026quot;profile\u0026quot;, \u0026quot;email\u0026quot;, \u0026quot;offline_access\u0026quot;, \u0026quot;eduperson_scoped_affiliation\u0026quot;, \u0026quot;eduperson_entitlement\u0026quot;] ","excerpt":"The EGI Notebooks service relies on the following technologies to provide its functionality: …","ref":"/providers/notebooks/architecture/","title":"Architecture"},{"body":"The Oneclient code and basic documentation are available on GitHub.\nThe official documentation is hosted on the Onedata homepage.\nUsing the web interface Using EGI Check-in it's possible to connect with your institute credentials.\nOn this page it\u0026rsquo;s possible to have an overview of all the spaces and their supporting providers.\nOn this capture, the information about the spaces supported by a specific provider is displayed.\nThe data space can be managed (i.e. uploading/downloading/managing files and metadata, managing space access) using the web browser.\nGenerating tokens for using Oneclient or APIs Important In order to be able to access your spaces using Oneclient or APIs, it\u0026rsquo;s required to generate an access token.  Tokens have to be generated from the EGI DataHub (Onezone) interface.\nThe access tokens can be created and managed using the EGI DataHub web interface.\nInstalling and testing Oneclient in a docker container A quick and simple solution for testing is to install the client on demand in a container for a supported Operating System flavor (mainly various CentOS and Ubuntu releases).\nThe following variables have to be exported in the container:\n ONECLIENT_ACCESS_TOKEN: access token allowing to access all the spaces. ONECLIENT_PROVIDER_HOST: name or IP of the Oneprovider the client should connect to.  Important In order to be able to use FUSE, the container should run in privileged mode.  docker run -it --privileged centos:7 /bin/bash root@81dbd7e84438 /]# curl -sS http://get.onedata.org/oneclient-1902.sh | bash # (...) Complete! Installation has been completed successfully. Run \u0026#39;oneclient --help\u0026#39; for usage info. root@81dbd7e84438 /]# export ONECLIENT_ACCESS_TOKEN=\u0026lt;ACCESS_TOKEN_FROM_ONEZONE\u0026gt; root@81dbd7e84438 /]# export ONECLIENT_PROVIDER_HOST=plg-cyfronet-01.datahub.egi.eu root@81dbd7e84438 /]# mkdir /tmp/space root@81dbd7e84438 /]# oneclient /tmp/space root@81dbd7e84438 /]# ls /tmp/space Here the data is mounted in /tmp/space, creating a file into it will push it to the Oneprovider and it will be accessible in the web interface and from other providers supporting the space.\nFor a real production usage it's preferable to use the Oneclient container as a source for a volume mounted into another container.\nTesting Oneclient in a Oneclient docker container with NFS or samba Docker containers for the Oneclient are available, the existing versions can be seen on the Oneclient docker hub.\nIt\u0026rsquo;s possible to use the most recent version by specifying the latest tag. We also recommend using the same version as shown on the Onezone and Oneprovider pages.\nThe following variables have to be exported to be used in the container:\n ONECLIENT_ACCESS_TOKEN: access token allowing to access all the spaces. ONECLIENT_PROVIDER_HOST: name or IP of the Oneprovider the client should connect to.  Important In order to be able to use FUSE, the container should run in privileged mode.  export ONECLIENT_ACCESS_TOKEN=\u0026lt;ACCESS_TOKEN_FROM_ONEZONE\u0026gt; export ONECLIENT_PROVIDER_HOST=plg-cyfronet-01.datahub.egi.eu docker run -it --privileged -e ONECLIENT_ACCESS_TOKEN=$ONECLIENT_ACCESS_TOKEN -e ONECLIENT_PROVIDER_HOST=$ONECLIENT_PROVIDER_HOST onedata/oneclient:19.02.0-rc2 Connecting to provider \u0026#39;plg-cyfronet-01.datahub.egi.eu:443\u0026#39; using session ID: \u0026#39;4138963898952098752\u0026#39;... Getting configuration... Oneclient has been successfully mounted in \u0026#39;/mnt/oneclient\u0026#39; Now the client will run in the background and the data will be available through samba/CIFS or nfs protocols:\n# Identifying the IP of the container docker inspect --format \u0026#34;{{ .NetworkSettings.IPAddress }}\u0026#34; $(docker ps -ql) 172.17.0.2 So the data can be accessed at\n smb://172.17.0.2/onedata nfs://172.17.0.2/onedata  Testing Oneclient in a Oneclient docker container with local file access Another solution is to mount a local directory as a volume in the container, allowing to access both the working directory as well as the Onedata spaces, thus allowing to easily exchange files between a local directory and a Onedata space.\nIn order to do this we will open a bash shell in the container then we will mount manually the Onedata spaces.\n ONECLIENT_ACCESS_TOKEN: access token allowing to access all the spaces. ONECLIENT_PROVIDER_HOST: name or IP of the Oneprovider the client should connect to.  Important In order to be able to use FUSE, the container should run in privileged mode.  export ONECLIENT_ACCESS_TOKEN=\u0026lt;ACCESS_TOKEN_FROM_ONEZONE\u0026gt; export ONECLIENT_PROVIDER_HOST=plg-cyfronet-01.datahub.egi.eu docker run -it --privileged -e ONECLIENT_ACCESS_TOKEN=$ONECLIENT_ACCESS_TOKEN -e ONECLIENT_PROVIDER_HOST=$ONECLIENT_PROVIDER_HOST -v $PWD:/mnt/src --entrypoint bash onedata/oneclient:19.02.0-rc2 root@aca612a84fb4:/tmp# oneclient /mnt/oneclient Connecting to provider \u0026#39;plg-cyfronet-01.datahub.egi.eu:443\u0026#39; using session ID: \u0026#39;1641165171427694510\u0026#39;... Getting configuration... Oneclient has been successfully mounted in \u0026#39;/mnt/oneclient\u0026#39;. root@aca612a84fb4:/tmp# ls /mnt/oneclient (...) root@aca612a84fb4:/tmp# ls /mnt/src (...) Now it's possible to use the following mount points:\n /mnt/oneclient: the Onedata spaces /mnt/src: the local directory (any absolute path could have been used instead of $PWD that points to the working directory)  Testing Oneclient in a Virtual Machine The following variables have to be exported:\n ONECLIENT_ACCESS_TOKEN: access token allowing to access all the spaces. ONECLIENT_PROVIDER_HOST: name or IP of the Oneprovider the client should connect to.  curl -sS http://get.onedata.org/oneclient-1902.sh | bash export ONECLIENT_ACCESS_TOKEN=\u0026lt;ACCESS_TOKEN_FROM_ONEZONE\u0026gt; export ONECLIENT_PROVIDER_HOST=plg-cyfronet-01.datahub.egi.eu mkdir /tmp/space oneclient /tmp/space Testing Oneclient in a Vagrant box It's possible to quickly test Oneclient using Vagrant.\nThe following variables have to be exported:\n ONECLIENT_ACCESS_TOKEN: access token allowing to access all the spaces. ONECLIENT_PROVIDER_HOST: name or IP of the Oneprovider the client should connect to.  vagrant init ubuntu/xenial64 vagrant up vagrant ssh curl -sS http://get.onedata.org/oneclient-1902.sh | bash export ONECLIENT_ACCESS_TOKEN=\u0026lt;ACCESS_TOKEN_FROM_ONEZONE\u0026gt; export ONECLIENT_PROVIDER_HOST=plg-cyfronet-01.datahub.egi.eu mkdir /tmp/space oneclient /tmp/space ","excerpt":"The Oneclient code and basic documentation are available on GitHub.\nThe official documentation is …","ref":"/users/datahub/clients/","title":"Clients"},{"body":"Every user of the EGI Notebooks catch-all instance has a 1GB persistent home to store any notebooks and associated data. The content of this home directory will be kept even if your notebook server is stopped (which can happen if there is no activity for more than 1 hour). Modifications to the notebooks environment outside the home directory are not kept (e.g. installation of libraries). If you need those changes to persist, let us know via a GGUS ticket to the Notebooks Support Unit. You can also ask for increasing the 1GB home via ticket.\nGetting data in/out Your notebooks have outgoing internet connectivity so you can connect to any external service to bring data in for analysis. As with input data, you can connect to any external service to deposit the notebooks output.\nThis is convenient for smaller datasets but not practical for larger ones, for those cases we can offer integration with several data services. These are not enabled in the catch-all instance but can be made available on demand.\nEGI DataHub DataHub provides a scalable distributed data infrastructure. It offers a tight integration with Jupyter and notebooks with specific drivers that make the DataHub Spaces accessible from any notebook.\nThe folders are browseable from the notebooks interface. Opening files from your code requires you to use the fs-onedatafs library. For convenience, the ONEPROVIDER_HOST environment variable will point to the default oneprovider for the Notebooks and the ONECLIENT_ACCESS_TOKEN variable will contain a valid access token for the service.\nfrom fs.onedatafs import OnedataFS # create the OnedataFS driver using defaults from env odfs = OnedataFS(os.environ[\u0026#39;ONEPROVIDER_HOST\u0026#39;], os.environ[\u0026#39;ONECLIENT_ACCESS_TOKEN\u0026#39;], force_direct_io=True) # use it to open a file f = odfs.open(\u0026#34;\u0026lt;datahub file path\u0026gt;\u0026#34;) The ONEPROVIDER_HOST and ONECLIENT_ACCESS_TOKEN variables are obtained as part of the login process and made available in the notebooks environment automatically. You can also specify a different oneprovider host if needed.\nEUDAT B2DROP EUDAT B2DROP offers a WebDAV interface that can be used to mount your files from the notebooks. Files are accessed as any regular file from the notebooks interface or from your code. This feature requires users to create a client in B2DROP and provide the client\u0026rsquo;s credentials to the EGI notebooks service.\nD4Science Workspace D4Science VREs provide a shared workspace via a dedicated API. EGI Notebooks embedded in D4Science VREs will automatically show the user\u0026rsquo;s workspace at the workspace directory. You can browse and use as any regular file.\nShared folders The Notebooks service can enable shared folders for users, either in read-only or read-write mode. These are specially meant for community instances for easing the sharing of data between all the users of the service. In the catch-all instance the datasets directory serves as an example of such feature.\nOther services We are open for integration with other services for facilitating the access to input and output data. Please contact support _at_ egi.eu with your request so we can investigate the best way to support your needs.\n","excerpt":"Every user of the EGI Notebooks catch-all instance has a 1GB persistent home to store any notebooks …","ref":"/users/notebooks/data/","title":"Data Management"},{"body":"Training events supported by the EGI Training Infrastructure are listed below:\n EGI Federated Cloud tutorial package (Software Carpentry Bootcamp, 17 July 2015 Feltham, London, UK). EGI Federated Cloud tutorial package (HPCS 2015 conference, 20-24 July 2015, Amsterdam, NL). EGI Federated Cloud for users (Training for MTA SZTAKI, 14 October 2015, Budapest, HU). Next Generation Sequencing Analysis Training Workshop (21 October, 2015, Thessaloniki, GR). Tutorials at the EGI Community Forum (10-12 November 2015, Bari, IT). EGI Technical Support for ENVRI+ Use Cases Workshop (May 2016, Zandvoord, NL). Running CHIPSTER, Galaxy, Jupyter Notebook on the EGI Federated Cloud (ELIXIR-FI workshop). EGI Federated Cloud for developers (DI4R, 28 September 2016, Krakow, PL). UberCloud - EGI webinar: Cloud for SMEs in CAE \u0026ndash; OpenFOAM demo (20 October 2016); Webinar recording. EGI training (ENVRIplus week, 14-18 November 2016, Prague, CZ). MEDGENET-Workshop INAB (15 December 2016, Thessaloniki, GR). Cloud Tutorial at EUDAT summer School (03-07 July 2017, Heraklion, GR). CODATA-RDA Research Data Science Summer School (21 July, 2017, Trieste, IT). Scipion tutorial on Cloud (17-19 January 2017, Madrid, ES). CODATA-RDA Research Data Science Summer School (17 August 2018, Trieste, IT). NGSchool 2018. 3rd Int'l Summer School on Data Science (SSDS 2018). Training for PhD students at the University of Genoa (04 June 2019). Introduction to Jupyter and Open Science - Training (27 September 2019, Yervan). HPC graduate class (August - November 2019) at UNICAM (Brazil) NGSChool 2019 (October, 24-31) Open Science with Jupyter, Zenodo and Binder (tutorial), 04 Dec. 2019 [Hercules European School (April 2020)] (http://hercules-school.eu/)  ","excerpt":"Training events supported by the EGI Training Infrastructure are listed below:\n EGI Federated Cloud …","ref":"/users/training/events/","title":"Events"},{"body":"Please find the list of internal services on the EGI website.\nRequest for information You can ask for more information about the services at: here.\n","excerpt":"Please find the list of internal services on the EGI website.\nRequest for information You can ask …","ref":"/internal/getting-started/","title":"Getting Started"},{"body":"The pages under this section depict how to join the EGI infrastructure as a service providers offering innovative services to the European Research Area.\n Interested in integrating your service with Check-in? Head to the Check-in for service provicers!\n  Interested in connecting your Identity Providres and allowing your users to access services via Check-in? Head to the Check-in for Identity Providers!\n  Interested in joining the EGI Federated Cloud? Head to the section on Cloud Compute!\n  Willing to deploy a Oneprovider? Head to DataHub section!\n  And if you want learn about EGI Notebooks, head to the Notebooks section!\n ","excerpt":"The pages under this section depict how to join the EGI infrastructure as a service providers …","ref":"/providers/getting-started/","title":"Getting Started"},{"body":"EGI Account You need to sign up for an account for accessing the EGI services. This process is not about creating yet another (username/password) credential but to link your existing credential (for example using an eduGAIN IdP) with EGI.\nFollow the sign up process to get started.\nVirtual Organisations (VOs) Service access is based on Virtual Organisations (VOs). A Virtual Organisation is a group of users and the service providers from the federation who allocate capacity for a specific user group. Users are not individually enabled in the services but through VOs.\nVOs are fully managed by communities allowing them to manage their users and grant control access to the services and resources. Usually there is one-to-one mapping between research communities and Virtual Organizations (although this is not mandatory). Users can also belong to different VOs, e.g. they work with different communities. Fine-grained authorisation mechanisms can be enabled within a VOs, for example only a subset of the users of a given VO may have access rights to manage software applications for that VO.\nYou have to join a VO before you can interact with most of the EGI services. The Operations portal provides the full list of available VOs.\nVOMS based VOs Some services require the use of X.509 certificates for user authentication and authorisation. These use VOMS for managing VO membership. Learn about how to get certificates and join a VOMS based Virtual Organisation in the Check-in documentation.\n","excerpt":"EGI Account You need to sign up for an account for accessing the EGI services. This process is not …","ref":"/users/getting-started/","title":"Getting Started"},{"body":"This page contains information about integrating your identity provider (IdP) with Check-in in order to allow users in your community to access EGI tools and services.\nOrganisations who want to register their IdP in Check-in needs to fill this form in case the IdP is not publishing REFEDS R\u0026amp;S and Sirtfi compliance in eduGAIN. A PDF scan of a printed and signed copy should be sent to operations_at_egi.eu\nIdentity Provider integration workflow To integrate your Identity Provider with the EGI Check-in service, you need to submit a GGUS ticket indicating your request. The responsible support unit is AAI Support. The integration follows a two-step process:\n Register your Identity Provider and test integration with the development instance of EGI Check-in. The development instance allows for testing authentication and authorisation to EGI services and resources without affecting the production environment of EGI. Note that the development instance is not connected to the production service and no information is shared between the two systems. Register your Identity Provider with the production instance of EGI Check-in to allow members of your Community to access production EGI services and resources protected by Check-in. This requires that your Identity Provider meets all the policy requirements and that integration has been thoroughly tested during Step 1.  The most important URLs for each environment are listed in the table below but more information can be found in the protocol-specific sections that follow.\n   Protocol Development environment Demo environment Production environment     SAML https://aai-dev.egi.eu/proxy/module.php/saml/sp/metadata.php/sso https://aai-demo.egi.eu/proxy/module.php/saml/sp/metadata.php/sso https://aai.egi.eu/proxy/module.php/saml/sp/metadata.php/sso   OpenID Connect See client registration See client registration See client registration    General requirements for integrating identity providers An institution or a community may connect their IdP with Check-in to allow their users to access EGI services, or any other services that have enabled Check-in as an authentication provider. This section presents the general requirements for integrating an IdP with EGI Check-in, while protocol-specific instructions are provided in the sections that follow.\nAttribute release requirements As a bare minimum, the IdP of a user\u0026rsquo;s Home Organisation or Community is expected to release a non-reassignable identifier that uniquely identifies the user within the scope of that organisation or community. The unique identifier must be accompanied with a minimum set of attributes which the Check-in Service Provider Proxy will attempt to retrieve from the user\u0026rsquo;s IdP. If this is not possible, the missing user attributes will be acquired and verified through the user registration process with the EGI Account Registry. The following table describes the data requested from the user\u0026rsquo;s Home Organisation, which are communicated to the Check-in SP as either SAML attributes or OIDC claims, depending on the protocol supported by the authenticating IdP.\n   Description Notes     At least one of the following unique user identifiers:pseudonymous, non-targeted identifier;name-based, non-targeted identifier;pseudonymous, targeted identifier    Preferred name for display purposes For example to be used in a greeting or a descriptive listing   First name    Surname    Email address    Affiliation within Home Organisation or Community To be released only if relevant for accessing EGI services    Note that the above set of requested attributes, particularly the identifier, name, email and affiliation information, complies with the REFEDS R\u0026amp;S attribute bundle.\nInformation about group membership and role information released by your IdP should follow the URN scheme below (see also AARC-G002):\n\u0026lt;NAMESPACE\u0026gt;:group:\u0026lt;GROUP\u0026gt;[:\u0026lt;SUBGROUP\u0026gt;*]][:role=\u0026lt;ROLE\u0026gt;]#\u0026lt;GROUP-AUTHORITY\u0026gt;  where:\n \u0026lt;NAMESPACE\u0026gt; is in the form of urn:\u0026lt;NID\u0026gt;:\u0026lt;DELEGATED-NAMESPACE\u0026gt;[:\u0026lt;SUBNAMESPACE\u0026gt;*], where  \u0026lt;NID\u0026gt; is the namespace identifier associated with a URN namespace registered with IANA, as per RFC8141, ensuring global uniqueness. Implementers can and should use one of the existing registered URN namespaces, such as urn:geant and urn:mace; \u0026lt;DELEGATED-NAMESPACE\u0026gt; is a URN sub-namespace delegated from one of the IANA registered NIDs    to an organisation representing the e-infrastructure, research infrastructure or research collaboration.\n \u0026lt;GROUP\u0026gt; is the name of a VO, research collaboration or a top level arbitrary group. \u0026lt;GROUP\u0026gt; names are unique within the urn:mace:egi.eu:group namespace; zero or more \u0026lt;SUBGROUP\u0026gt; components represent the hierarchy of subgroups in the \u0026lt;GROUP\u0026gt;; specifying sub-groups is optional the optional \u0026lt;ROLE\u0026gt; component is scoped to the rightmost (sub)group; if no group information is specified, the role applies to the VO \u0026lt;GROUP-AUTHORITY\u0026gt; is a non-empty string that indicates the authoritative source for the entitlement value. For example, it can be the FQDN of the group management system that is responsible for the identified group membership information  Example entitlement values expressing VO/group membership and role information:\nurn:geant:dariah.eu:group:egi-interop:role=member#aaiproxy.de.dariah.eu urn:geant:dariah.eu:group:egi-interop:role=vm_operator#aaiproxy.de.dariah.eu  Operational and security requirements The IdP needs to comply with additional requirements to achieve a higher level of assurance and allow its users to gain access to a wider set of EGI services. A first group of additional requirements are defined by the Sirtfi framework v1.0. Adherence to these requirements can be asserted either by publishing Sirtfi compliance in the eduGAIN metadata or by declaring it in this form. These requirements are in the areas of operational security, incident response, traceability and IdPs and users responsibility.\nBranding requirements Check-in provides a central Discovery Service (or \u0026ldquo;Where Are You From\u0026rdquo; - WAYF) page where users in your Home Organisation or Community will be automatically redirected when necessary to select to authenticate at your IdP. You can provide us with a logo of your Organisation or Community (in high-res png or preferably in svg format) to include a dedicated login button that will allow users to easily identify your IdP.\nSAML Identity Provider To allow users in your community to sign into federated EGI applications, you need to connect to the EGI AAI SP Proxy as a SAML Identity Provider (IdP). Users of the application will be redirected to the central Discovery Service page of the EGI AAI Proxy where they will able to select to authenticate at your IdP. Once the user is authenticated, the EGI AAI Proxy will return a SAML assertion to the application containing the information returned by your IdP about the authenticated user.\nMetadata registration SAML authentication relies on the use of metadata. Both parties (you as an IdP and the EGI AAI SP) need to exchange metadata in order to know and trust each other. The metadata include information such as the location of the service endpoints that need to be invoked, as well as the certificates that will be used to sign SAML messages. The format of the exchanged metadata should be based on the XML-based SAML 2.0 specification. Usually, you will not need to manually create such an XML document, as this is automatically generated by all major SAML 2.0 IdP software solutions (e.g., Shibboleth, SimpleSAMLphp). It is important that you serve your metadata over HTTPS using a browser-friendly SSL certificate, i.e. issued by a trusted certificate authority.\nTo exchange metadata, please send an email including the following information:\n entityID Metadata URL  Depending on the software you are using, the authoritative XML metadata URL for your IdP might be in the following form:\n https://your.idp.example.eu/idp/shibboleth (Shibboleth) https://your.idp.example.eu/simplesaml/module.php/saml2/idp/metadata.php (SimpleSAMLphp)  Note that if your IdP is part of a federation, then it would be preferred to send us the URL to a signed federation metadata aggregate. We can then cherry pick the appropriate entityID from that.\nYou can get the metadata of the EGI Check-in SP Proxy on a dedicated URL that depends on the integration environment being used:\n   Development environment Demo environment Production environment     https://aai-dev.egi.eu/proxy/module.php/saml/sp/metadata.php/sso https://aai-demo.egi.eu/proxy/module.php/saml/sp/metadata.php/sso https://aai.egi.eu/proxy/module.php/saml/sp/metadata.php/sso    For the production environment, it is recommended that you get the metadata for the EGI Check-in SP (entityID: https://aai.egi.eu/proxy/module.php/saml/sp/metadata.php/sso) from a signed eduGAIN metadata aggregate. For example, the following aggregates are provided by GRNET:\n GRNET federation's metadata eduGAIN SP metadata  Attribute release The SAML based Identity Provider of your Home Organisation or Community is expected to release a non-reassignable identifier that uniquely identifies the user within the scope of that organisation or community, along with a set of additional information as described in the following table (see also general attribute release requirements):\n   Description SAML attribute     At least one of the following unique user identifiers:pseudonymous, non-targeted identifier;name-based, non-targeted identifier;pseudonymous, targeted identifier SubjectID (public) or eduPersonUniqueIdeduPersonPrincipalNameSubjectID (pairwise) or eduPersonTargetedID or SAML persistent identifier   Preferred name for display purposes displayName   First name givenName   Surname sn   Email address mail   Affiliation within Home Organisation or Community eduPersonScopedAffiliation   Group(s)/role(s) within Home Organisation or Community eduPersonEntitlement    OpenID Connect Identity Provider Users in your community can sign into federated EGI applications through the Check-in service using your OpenID Connect or OAuth 2.0 based Identity Provider.\nClient registration To enable your OIDC Identity Provider for user login, Check-in needs to be registered as a client in order to obtain OAuth 2.0 credentials, such as a client ID and client secret, and to register one or more redirect URIs. Once Check-in is registered as a client, your users will be redirected to the central Discovery Service page of Check-in when logging into EGI federated applications, where they will able to select to authenticate at your IdP. Once the user is authenticated, Check-in will be responsible for communicating the information returned by your IdP about the authenticated user to the connected application. Depending on the protocol, this information will be expressed through a SAML assertion, a set of OIDC claims or a (proxy) X.509 certificate.\nProvider configuration Check-in needs to obtain your OpenID Provider's configuration information, including the location of the Authorisation, Token and UserInfo endpoints. Your OpenID Provider is expected to make a JSON document available at the path formed by concatenating the string /.well-known/openid-configuration to the Issuer, following the OpenID Connect Discovery 1.0 specification.\nAttribute release The OpenID Connect or OAuth 2.0 based Identity Provider of your Home Organisation or Community is expected to release a non-reassignable identifier that uniquely identifies the user within the scope of that organisation or community, along with a set of additional information as described in the following table (see also general attribute release requirements):\n   Description OIDC claim     At least one of the following unique user identifiers:pseudonymous, non-targeted identifier;name-based, non-targeted identifier;pseudonymous, targeted identifier sub (public)N/Asub (pairwise)   Preferred name for display purposes name   First name given_name   Surname family_name   Email address email   Affiliation within Home Organisation or Community eduperson_scoped_affiliation   Group(s)/role(s) within Home Organisation or Community eduPerson_entitlement    Integration success stories  EGI AAI integration with ELIXIR  ","excerpt":"This page contains information about integrating your identity provider (IdP) with Check-in in order …","ref":"/providers/check-in/idp/","title":"Identity Providers"},{"body":"You can find here documentation on how to deploy a sample SLURM cluster, which you can then adapt to create other kind of clusters easily.\nGetting started We will use docker for running EC3, direct installation is also possible and described at EC3 documentation. First get the docker image:\ndocker pull grycap/ec3 And check that you can run a simple command:\n$ docker run grycap/ec3 list name state IP nodes ------------------------ For convenience we will create a directory to keep the deployment configuration and status together.\nmkdir ec3-test cd ec3-test You can list the available templates for clusters with the templates command:\n$ docker run grycap/ec3 templates name kind summary ---------------------------------------------------------------------------------------------------------------------- blcr component Tool for checkpointing applications. [...] sge main Install and configure a cluster SGE from distribution repositories. slurm main Install and configure a cluster using the grycap.slurm ansible role. slurm-repo main Install and configure a cluster SLURM from distribution repositories. [...] We will use the slurm template for configuring our cluster.\nSite details EC3 needs some information on the site that you are planning to use to deploy your cluster:\n authentication information network identifiers VM image identifiers  We will use egicli to discover all needed details, set your credentials (Check-in client id, client secret and refresh tokens) as shown in the authentication guide and start by listing the available sites:\n$ egicli endpoint list Site type URL ------------------ ------------------ ------------------------------------------------ IFCA-LCG2 org.openstack.nova https://api.cloud.ifca.es:5000/v3/ IN2P3-IRES org.openstack.nova https://sbgcloud.in2p3.fr:5000/v3 CETA-GRID org.openstack.nova https://controller.ceta-ciemat.es:5000/v3/ UA-BITP org.openstack.nova https://openstack.bitp.kiev.ua:5000/v3 RECAS-BARI org.openstack.nova https://cloud.recas.ba.infn.it:5000/v3 CLOUDIFIN org.openstack.nova https://cloud-ctrl.nipne.ro:443/v3 IISAS-GPUCloud org.openstack.nova https://keystone3.ui.savba.sk:5000/v3/ IISAS-FedCloud org.openstack.nova https://nova.ui.savba.sk:5000/v3/ UNIV-LILLE org.openstack.nova https://thor.univ-lille.fr:5000/v3 INFN-PADOVA-STACK org.openstack.nova https://egi-cloud.pd.infn.it:443/v3 CYFRONET-CLOUD org.openstack.nova https://panel.cloud.cyfronet.pl:5000/v3/ SCAI org.openstack.nova https://fc.scai.fraunhofer.de:5000/v3 CESNET-MCC org.openstack.nova https://identity.cloud.muni.cz/v3 INFN-CATANIA-STACK org.openstack.nova https://stack-server.ct.infn.it:35357/v3 CESGA org.openstack.nova https://fedcloud-osservices.egi.cesga.es:5000/v3 100IT org.openstack.nova https://cloud-egi.100percentit.com:5000/v3/ NCG-INGRID-PT org.openstack.nova https://stratus.ncg.ingrid.pt:5000/v3 fedcloud.srce.hr org.openstack.nova https://cloud.cro-ngi.hr:5000/v3/ Kharkov-KIPT-LCG2 org.openstack.nova https://cloud.kipt.kharkov.ua:5000/v3 We will use CESGA, which has https://fedcloud-osservices.egi.cesga.es:5000/v3 as URL. Get the available projects at the site:\n$ egicli endpoint projects --site CESGA id Name enabled site -------------------------------- ---------------- --------- ------ 3a8e9d966e644405bf19b536adf7743d vo.access.egi.eu True CESGA Using the project id and the site name, you can create the authorisation files needed for ec3:\negicli endpoint ec3 --site CESGA --project-id 3a8e9d966e644405bf19b536adf7743d This will generate an auth.dat file with your credentials to access the site and a templates/refresh.radl with a token refreshal mechanism to allow long running clusters to be managed on the infrastructure.\nLet\u0026rsquo;s get also a working OpenStack setup:\neval \u0026#34;$(egicli endpoint env --site CESGA --project-id 3a8e9d966e644405bf19b536adf7743d)\u0026#34; Now, get the available networks, we will need both a public and private network:\n$ openstack network list +--------------------------------------+----------------------+--------------------------------------+ | ID | Name | Subnets | +--------------------------------------+----------------------+--------------------------------------+ | 12ffb5f7-3e54-433f-86d0-8ffa43b52025 | net-vo.access.egi.eu | 754342b1-92df-4fc8-9499-2ee8b668141f | | 6174db12-932f-4ee3-bb3e-7a0ca070d8f2 | public00 | 6af8c4f3-8e2e-405d-adea-c0b374c5bd99 | +--------------------------------------+----------------------+--------------------------------------+ Then, get the list of images available:\n$ openstack image list +--------------------------------------+----------------------------------------------------------+--------+ | ID | Name | Status | +--------------------------------------+----------------------------------------------------------+--------+ | 9d22cb3b-e6a3-4467-801a-a68214338b22 | Image for CernVM3 [CentOS/6/QEMU-KVM] | active | | b03e8720-d88a-4939-b93d-23289b8eed6c | Image for CernVM4 [CentOS/7/QEMU-KVM] | active | | 06cd7256-de22-4e9d-a1cf-997b5c44d938 | Image for Chipster [Ubuntu/16.04/KVM] | active | | 8c4e2568-67a2-441a-b696-ac1b7c60de9c | Image for EGI CentOS 7 [CentOS/7/VirtualBox] | active | | abc5ebd8-f65c-4af9-8e54-a89e3b5587a3 | Image for EGI Docker [Ubuntu/18.04/VirtualBox] | active | | 22064e93-6af9-430b-94a1-e96473c5a72b | Image for EGI Ubuntu 16.04 LTS [Ubuntu/16.04/VirtualBox] | active | | d5040b3e-ef33-4959-bb88-5505e229f579 | Image for EGI Ubuntu 18.04 [Ubuntu/18.04/VirtualBox] | active | | 79fadf3f-6092-4bb7-ab78-9a322f0aad33 | cirros | active | +--------------------------------------+----------------------------------------------------------+--------+ For our example we will use the EGI CentOS 7 with id 8c4e2568-67a2-441a-b696-ac1b7c60de9c.\nFinally, with all this information we can create the images template for EC3 that specifies the site configuration for our deployment. Save this file as templates/centos.radl:\ndescription centos-cesga ( kind = \u0026#39;images\u0026#39; and short = \u0026#39;centos7-cesga\u0026#39; and content = \u0026#39;CentOS7 image at CESGA\u0026#39; ) network public ( provider_id = \u0026#39;public00\u0026#39; and outports contains \u0026#39;22/tcp\u0026#39; ) network private (provider_id = \u0026#39;net-vo.access.egi.eu\u0026#39;) system front ( cpu.arch = \u0026#39;x86_64\u0026#39; and cpu.count \u0026gt;= 2 and memory.size \u0026gt;= 2048 and disk.0.os.name = \u0026#39;linux\u0026#39; and disk.0.image.url = \u0026#39;ost://fedcloud-osservices.egi.cesga.es/8c4e2568-67a2-441a-b696-ac1b7c60de9c\u0026#39; and disk.0.os.credentials.username = \u0026#39;centos\u0026#39; ) system wn ( cpu.arch = \u0026#39;x86_64\u0026#39; and cpu.count \u0026gt;= 2 and memory.size \u0026gt;= 2048 and ec3_max_instances = 5 and # maximum number of worker nodes in the cluster disk.0.os.name = \u0026#39;linux\u0026#39; and disk.0.image.url = \u0026#39;ost://fedcloud-osservices.egi.cesga.es/8c4e2568-67a2-441a-b696-ac1b7c60de9c\u0026#39; and disk.0.os.credentials.username = \u0026#39;centos\u0026#39; ) Note we have used public00 as public network and opened port 22 to allow ssh access. The private network uses net-vo.access.egi.eu. We have two kind of VMs in almost every deployment: the front, that runs the batch system, and the wn, that will execute the jobs. In our example, both will use the same CentOS image, which is specified with the disk.0.image.url = 'ost://fedcloud-osservices.egi.cesga.es/8c4e2568-67a2-441a-b696-ac1b7c60de9c' line: ost refers to OpenStack, fedcloud-osservices.egi.cesga.es is the hostname of the URL obtained above with egicli endpoint list and 8c4e2568-67a2-441a-b696-ac1b7c60de9c is the id of the image in OpenStack. The size of the VM is also specified.\nLaunch cluster We are ready now to deploy the cluster with ec3 (this can take several minutes):\n$ docker run -it -v $PWD:/root/ -w /root grycap/ec3 launch mycluster slurm ubuntu refresh -a auth.dat Creating infrastructure Infrastructure successfully created with ID: 74fde7be-edee-11ea-a6e9-da8b0bbd7c73 Front-end configured with IP 193.144.46.234 Transferring infrastructure Front-end ready! We can check the status of the deployment:\n$ docker run -it -v $PWD:/root/ -w /root grycap/ec3 list name state IP nodes ---------------------------------------------- mycluster configured 193.144.46.234 0 And once configured, ssh to the front node. The is_cluster_ready command will report whether the cluster is fully configured or not:\n$ docker run -it -v $PWD:/root/ -w /root grycap/ec3 ssh mycluster Warning: Permanently added \u0026#39;193.144.46.234\u0026#39; (ECDSA) to the list of known hosts. Last login: Thu Sep 3 14:07:46 2020 from torito.i3m.upv.es $ bash cloudadm@slurmserver:~$ is_cluster_ready Cluster configured! cloudadm@slurmserver:~$ EC3 will deploy CLUES, a cluster management system that will power on/off nodes as needed depending on the load. Initially all the nodes will be off:\nnode state enabled time stable (cpu,mem) used (cpu,mem) total ----------------------------------------------------------------------------------------------- wn1 off enabled 00h03\u0026#39;55\u0026#34; 0,0.0 1,1073741824.0 wn2 off enabled 00h03\u0026#39;55\u0026#34; 0,0.0 1,1073741824.0 wn3 off enabled 00h03\u0026#39;55\u0026#34; 0,0.0 1,1073741824.0 wn4 off enabled 00h03\u0026#39;55\u0026#34; 0,0.0 1,1073741824.0 wn5 off enabled 00h03\u0026#39;55\u0026#34; 0,0.0 1,1073741824.0 SLURM will also report nodes as down:\nPARTITION AVAIL TIMELIMIT NODES STATE NODELIST debug* up infinite 5 down* wn[1-5] As we submit a first job, some nodes will be powered on to meet the request. You can also start them manually with clues poweron.\ncloudadm@slurmserver:~$ srun hostname srun: Required node not available (down, drained or reserved) srun: job 2 queued and waiting for resources srun: job 2 has been allocated resources wn1.localdomain cloudadm@slurmserver:~$ clues status node state enabled time stable (cpu,mem) used (cpu,mem) total ----------------------------------------------------------------------------------------------- wn1 idle enabled 00h07\u0026#39;45\u0026#34; 0,0.0 1,1073741824.0 wn2 off enabled 00h52\u0026#39;25\u0026#34; 0,0.0 1,1073741824.0 wn3 off enabled 00h52\u0026#39;25\u0026#34; 0,0.0 1,1073741824.0 wn4 off enabled 00h52\u0026#39;25\u0026#34; 0,0.0 1,1073741824.0 wn5 off enabled 00h52\u0026#39;25\u0026#34; 0,0.0 1,1073741824.0 cloudadm@slurmserver:~$sinfo PARTITION AVAIL TIMELIMIT NODES STATE NODELIST debug* up infinite 4 down* wn[2-5] debug* up infinite 1 idle wn1 Destroying the cluster Once you are done with the cluster and want to destroy it, you can use the destroy command. If your cluster was created more than one hour ago, your credentials to access the site will be expired and need to refreshed first with egicli endpoint ec3-refresh:\n$ egicli endpoint ec3-refresh # refresh your auth.dat $ docker run -it -v $PWD:/root/ -w /root grycap/ec3 list # list your clusters name state IP nodes ---------------------------------------------- mycluster configured 193.144.46.234 0 $ docker run -it -v $PWD:/root/ -w /root grycap/ec3 destroy mycluster -a auth.dat -y WARNING: you are going to delete the infrastructure (including frontend and nodes). Success deleting the cluster! ","excerpt":"You can find here documentation on how to deploy a sample SLURM cluster, which you can then adapt to …","ref":"/users/cloud-compute/ec3/basics/","title":"Introduction"},{"body":"IaaS providers are very welcome to join the EGI Federated Cloud as a Resource Centres (RC) and joining the Federated Cloud Task Force to contribute to the design, creation and implementation of the federation.\nResource Centers are free to use any Cloud Management Framework (OpenNebula, OpenStack, etc...) as long as they are able to integrate with the EGI Federation components as described in the Federated Cloud Architecture. At the moment this compliance is guaranteed for the following CMFs:\n OpenStack (with/without OCCI) OpenNebula with OCCI Synnefo with OCCI  The general minimal requirements are:\n Hardware requirements greatly depend on your cloud infrastructure, EGI components in general do lightweigth operations by interacting with your services APIs.  cloudkeeper requires enough disk space to download and convert images before uploading into your local catalogue. The number and size of images which will be downloaded depends on the communities you plan to support. For the piloting VO fedcloud.egi.eu, 100GB of disk should be enough.   Servers need to authenticate each other in the EGI Federated Cloud context using X.509 certificates. So a Resource Centre should be able to obtain server certificates for some services. User and research communities are called Virtual Organisations (VO). Resource Centres are expected to join:  ops and dteam VOs, used for operational purposes as per RC OLA a community-VO that supports EGI users (e.g. vo.access.egi.eu for piloting)   EGI provides packages for the following operating systems (others may work but we are not providing packages):  CentOS 7 (and in general RHEL-compatible) Ubuntu 16.04 (and in general Debian-based)    ","excerpt":"IaaS providers are very welcome to join the EGI Federated Cloud as a Resource Centres (RC) and …","ref":"/providers/cloud-compute/requirements/","title":"Requirements"},{"body":"Sign up You need to sign up for an account for accessing the EGI services. As part of this process you will be assigned a personal unique EGI ID which will be then used across all EGI tools and services. Follow the instructions below to get started:\n  Go to https://aai.egi.eu/signup. This will show you the identity provider discovery page: browse through the list of Identity Providers to find your Home Organisation, or, alternatively, type the name of your Home Organisation in the search box. Note that the names are localised based on the selected language.\n  Enter your login credentials to authenticate yourself with your Home Organisation\n  After successful authentication, you may be prompted by your Home Organisation to consent to the release of personal information to the EGI AAI Service Provider Proxy.\n  After successful authentication, you will be redirected to the EGI account registration form. On the introductory page, click Begin to start the registration process.\n  EGI requires some basic information from you, depending on the attributes released by your Identity Provider, you may need to provide the values of the missing attributes.\n  On the registration form, click Review Terms and Conditions (Acceptable Use Policy and Conditions of Use - EGI AUP)\n  If you agree to the Terms of Use, select the I Agree option.\nImportant You will not be able to agree to the terms until you review them.    Finally, click Submit to submit your request.\nImportant You will not be able to submit your request until you agree to the terms.    After submitting your request, Check-in will send you an email with a verification link. After you click that link, you\u0026rsquo;ll be taken to the request confirmation page.\nImportant If you do not find the email in your Inbox, please check your Spam or Junk folder for an email from \u0026ldquo;EGI AAI Notifications\u0026rdquo;. If you do find the email in these folders, mark the email as \u0026ldquo;safe\u0026rdquo; or \u0026ldquo;not spam\u0026rdquo; to ensure that you receive any future notifications about your EGI ID.    After reviewing your request, click Confirm and re-authenticate yourself using the Identity Provider you selected before.\n  In the case of the Sign Up registration, you need to wait for an EGI User Sponsor to approve your request to join the EGI User Community. Upon approval, EGI AAI will send you a notification email.\n  Note: After your registration has been completed, you can manage your profile through the EGI Account Registry portal.\nViewing user profile information The profile includes all the information related to the user. This information can be categorised as follows:\nBasic profile Includes the basic information about your profile:\n Name Identifiers Email addresses  VO/Group membership and roles Includes information about the Virtual Organisations and groups the user if member of and the roles assigned to the user within those Virtual Organisation.\nLinked identities Information about identites linked to your account. Check the guide for linking accounts for more information.\n","excerpt":"Sign up You need to sign up for an account for accessing the EGI services. As part of this process …","ref":"/users/check-in/signup/","title":"Sign up for an EGI Account"},{"body":"Request for information You can ask for more information about the services at: here\nOrdering EGI services You can order EGI services from:\n EGI marketplace, or EOSC marketplace  Payments Model The payment models of EGI services can be:\n Sponsored use for policy-based access Pay-as-you-go for market-based access  What happens after you place an order EGI user support team will handle your order within 5 working days.\nWe normally contact you to have a short virtual meeting in order to better understand your requirements:\n What is your research project background (science domain, partners countries, user bases, pay-for-use or not, etc.). These will help us identify better resources matching your needs. What is your requirements details (how much CPU cores, RAM per CPU, software services, how long do you need, etc.)  If we are able to support your case, there will be two options:\n  We will try to map you to an existing EGI community VO. Domain specific and regional VOs can be browsed at Operation Portal. If there is a suitable one, we will contact the VO managers to join you to the VO and grant you the access to the resources attached to that VO.\n  If there are no suitable VOs existing, we need to create a new VO for your community. The procedure is as follows:\n We will contact our provider and negotiate resources for you. If there are providers happy to support you, we will sign SLA with you A new VO will be created for your community    ","excerpt":"Request for information You can ask for more information about the services at: here\nOrdering EGI …","ref":"/users/","title":"Users"},{"body":"According to AARC-G002 the information about the groups a user is a member of is commonly used by Service Providers in order to authorise user access to protected resources.The entity responsible for disseminating this information is the EGI Check-in AAI proxy and the format used is that of a URN namespace, called eduPersonEntitlement, that is uniformly interpreted across infrastructures.\nThe general form of the eduPersonEntitlement string is:\n\u0026lt;NAMESPACE\u0026gt;:group:\u0026lt;VO\u0026gt;[:\u0026lt;GROUP\u0026gt;*][:role=\u0026lt;ROLE\u0026gt;]#\u0026lt;GROUP-AUTHORITY\u0026gt;\nAs a result, an eduPersonEntitlement string informing the Service Provider that the user has the role Associate in the vo.example.eu VO (modelled as a COU) is:\nurn:mace:egi.eu:group:vo.example.eu:role=associate#aai.egi.eu\nEntitlement Construction For the case of the CO Person with a profile/canvas, like the one provided above, we expect to get entitlements for all the entries listed under the tab Role Attributes. Additionally, we will get entitlements for all the General Purpose(GP) Groups enlisted under the tab Groups. These GP Groups have no prefix, neither CO: nor CO:COU, and no postfix, neither active nor all.\nVO(COU) For each entry in the table Role Attributes, that is in status Active or Grace Period, we create one eduPersonEntitlement for each different Role and for the Affiliation. For example, the CO Person from above is affiliated as Member to the VO vo.example.eu and has been assigned the role of an Associate. This will generate two entitlements as:\nurn:mace:egi.eu:group:vo.example.eu:role=associate#aai.egi.eu\nurn:mace:egi.eu:group:vo.example.eu:role=member#aai.egi.eu\nVO Groups (sub COUs) There are occasions where we need a VO to be organized in subgroups. For example vo.example.eu contains the sub-COU vo.example-sub.eu.\nThe CO Person is affiliated as member and with the Role of Support in the VO sub-group vo.example-sub.eu:\nIn such occasions the eduPersonEntitlement will have the following structure:\nurn:mace:egi.eu:group:vo.example.eu:vo.example-sub.eu:role=support#aai.egi.eu\nurn:mace:egi.eu:group:vo.example.eu:vo.examples-sub.eu:role=member#aai.egi.eu\n","excerpt":"According to AARC-G002 the information about the groups a user is a member of is commonly used by …","ref":"/users/check-in/vos/expressing-vo-information/","title":"VO group/role information"},{"body":"The GOCDB can be accessed at https://goc.egi.eu.\nTo access the web interface, users can:\n use EGI Check-in to access the GOCDB with an institutional account. use an X.509 digital certificate installed in the browser, delivered by one of the recognised EU-Grid-PMA Certification Authorities ;  Users can access the system as soon as they are authenticated however they will only be able to update information based on their roles. More information about roles and associated permission is available in the Users and roles section.\nAll roles applications need to be validated by parent roles or administrators. Once this is done, you can access/modify relevant information according to the role you have been granted. You can learn more on roles and user accounts by reading the #Users and roles section of this documentation.\nUsing institutional account via EGI Check-in In order to be able to access the GOCDB with their institutional account, users need to:\n Have their Identity Provider (IdP) federated in EGI Check-in (via eduGAIN or directly) ; Have created an EGI Check-in account ;  Important In the case the user cannot use an IdP compliant with REFEDS R\u0026amp;S and REFEDS Sirtfi, the user will have to request joining a specific group. Using a compliant IdP is the preferable solution.   User should ask to join the GOCDB user group ; The access request will be managed by the EGI Operations team.  Using an X.509 digital certificate Please note, GOCDB does not support single or double quotes in the certificate Distinguished Name (DN).\nThis DN is rejected by GOCDB because of the single quote:\n/C=UK/O=STFC/OU=SomeOrgUnit/CN=David Mc'Donald This is in accordance with RFC1778 which also disallows single quotes in all Relative Distinguished Name (RDN) components, and the OGF Certificate Authority Working Group (CAOPS) who strongly discourage any type of quote in a certificate DN as specified by their Grid Certificate Profile document.\n","excerpt":"The GOCDB can be accessed at https://goc.egi.eu.\nTo access the web interface, users can:\n use EGI …","ref":"/internal/configuration-database/access/","title":"Access"},{"body":"Authentication OpenID Connect is the main authentication protocol used on the EGI Cloud. It replaces the legacy VOMS-based authentication for all OpenStack providers.\nAuthentication to web based services (like the AppDB) will redirect you to the EGI Check-in authentication page. Just select your institution or social login and follow the regular authentication process.\nAccess to APIs or via Command Line Interfaces (CLI) requires the use of OAuth2.0 tokens and interaction with the OpenStack Keystone OS-FEDERATION API. The process for authentication is as follows:\n Obtain a valid OAuth2.0 access token from Check-in. Access tokens are short-lived credentials that can be obtained by recognised Check-in clients once a user has been authenticated. Interchange the Check-in access token for a valid unscoped Keystone token. Discover available projects from Keystone using the unscoped token. Use the unscoped Keystone token to get a scoped token for a valid project. Scoped tokens will allow the user to perform operations on the provider.  Authorisation Cloud Compute service is accessed through Virtual Organisations (VOs). Users that are members of a VO will have access to the providers supporting that VO: they will be able to manage VMs, block storage and object storage available to the VO. Resources (VMs and storage) are shared across all members of the VO, please do not interfere with the VMs of other users if you are not entitled to do so (specially do not delete them).\nSome users roles have special consideration in VOs:\n Users with VO Manager, VO Deputy or VO Expert Role have extra privileges in the AppDB for managing the Virtual Appliances to be available at every provider. Check the Virtual Machine Image Management documentation for more information.  Pilot VO The vo.access.egi.eu Virtual Organisation serves as a test ground for users to try the Cloud Compute service and to prototype and validate applications. It can be used for up to 6 month by any new user.\nWarning  After the 6-month long membership in the vo.access.egi.eu VO, you will need to move to a production VO, or establish a new VO. The resources are not guaranteed and may be removed without notice by providers. Back-up frequently to avoid losing your work!   For joining this VO, just place an order in the EGI Marketplace and once approved you will be able to interact with the infrastructure.\nOther VOs Pre-existing VOs of EGI can be also used on IaaS cloud providers. Consult with your VO manager or browse the existing VOs at the EGI Operations Portal.\nCheck-in and access tokens Access tokens can be obtained via several mechanisms, usually involving the use of a web server and a browser. Command line clients/APIs without access to a browser or interactive prompt for user authentication can use refresh tokens. A refresh token is a special token that is used to generate additional access tokens. This allows you to have short-lived access tokens without having to collect credentials every single time one expires. You can request this token alongside the access and/or ID tokens as part of a user\u0026rsquo;s initial authentication flow.\nIn the case of EGI Check-in, we have created a special client meant to obtain your personal refresh token and client credentials that will allow the obtention of access tokens as needed. You can access the FedCloud Check-in client and click on 'Authorise' to log in with your Check-in credentials to obtain:\n a client id a client secret a refresh token  Note them down so you can use them for the next steps.\nDiscovering projects in Keystone The access token will provide you access to a cloud provider, but you may have access to several different projects within that provider (a project can be considered equivalent to a VO allocation). In order to discover which projects are available you can do that using the Keystone API.\nYou can use the egicli to simplify the discovery of projects. First, define these variables in your environment:\n CHECKIN_CLIENT_ID: Your Check-in client id (get it from FedCloud Check-in client) CHECKIN_CLIENT_SECRET: Your Check-in client secret (get it from FedCloud Check-in client) CHECKIN_REFRESH_TOKEN: Your Check-in refresh token (get it from FedCloud Check-in client) EGI_SITE: Name of the site (get it from AppDB, or list it with the egicli endpoint list command)  And use them to get the list of projects:\n# Export OIDC env export CHECKIN_CLIENT_ID=\u0026lt;CLIENT_ID\u0026gt; export CHECKIN_CLIENT_SECRET=\u0026lt;CLIENT_SECRET\u0026gt; export CHECKIN_REFRESH_TOKEN=\u0026lt;REFRESH_TOKEN\u0026gt; # Retrieve list of projects from site export EGI_SITE=\u0026lt;NAME_OF_THE_SITE\u0026gt; egicli endpoint projects Using the OpenStack API Once you know which project to use, you can use your regular openstack cli commands for performing actual operations in the provider:\n# Export OIDC env export CHECKIN_CLIENT_ID=\u0026lt;CLIENT_ID\u0026gt; export CHECKIN_CLIENT_SECRET=\u0026lt;CLIENT_SECRET\u0026gt; export CHECKIN_REFRESH_TOKEN=\u0026lt;REFRESH_TOKEN\u0026gt; # EGI site export EGI_SITE=\u0026lt;NAME_OF_THE_SITE\u0026gt; export OS_PROJECT_ID=\u0026lt;PROJECT_ID\u0026gt; # get environment variables for openstack eval \u0026#34;$(egicli endpoint env)\u0026#34; openstack image list For 3rd party tools that can use token based authentication in OpenStack, use the following command (after setting the environment as shown above):\n# Export OIDC env export CHECKIN_CLIENT_ID=\u0026lt;CLIENT_ID\u0026gt; export CHECKIN_CLIENT_SECRET=\u0026lt;CLIENT_SECRET\u0026gt; export CHECKIN_REFRESH_TOKEN=\u0026lt;REFRESH_TOKEN\u0026gt; # EGI site export EGI_SITE=\u0026lt;NAME_OF_THE_SITE\u0026gt; eval \u0026#34;$(egicli endpoint token)\u0026#34; Legacy X.509 AAI Warning OpenID Connect is the preferred federated identity technology on EGI Cloud. Use of X.509 certificates should be limited to legacy applications.  VOMS uses X.509 proxies extended with VO information for authentication and authorisation on the providers. You can learn about X.509 certificates and VOMS in the Check-in documentation.\nVOMS configuration Valid configuration for fedcloud.egi.eu is available on the FedCloud client VM as generated by the fedcloud-ui installation script.\nVOMS client expects your certificate and private key to be available at $HOME/.globus/usercert.pem and $HOME/.globus/userkey.pem respectively.\nAccess the providers VOMS authentication differs from one provider to another depending on the technology used. There are 3 different cases handled automatically by the rOCCI-cli. For accessing native OpenStack sites there are two different plugins available for Keystone that are installed with a single library:\npip install openstack-voms-auth-type For Keystone-VOMS based installations (Keystone URL ending on /v2.0), just define the location of your proxy and v2voms as authorisation plugin:\nopenstack --os-auth-url https://\u0026lt;keystone-url\u0026gt;/v2.0 \\  --os-auth-type v2voms --os-x509-user-proxy /tmp/x509up_u1000 \\  token issue +---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | expires | 2019-02-04T12:41:25+0000 | | id | gAAAAABcWCTlMoz6Jx9IHF5hj-ZOn-CI17CfX81FTn7yy0ZJ54jkza7QNoQTRU5-KRJkphmes55bcoSaaBRnE3g2clFgY-MR2GVUJZRkCmj9TXsLZ-hVBWXQNENiX9XxUwnavj7KqDn4b9B1K22ijTrjdDVkcdpvMw | | user_id | 9310054c2b6f4fd28789ee08c2351221 | +---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------+ For those Keystone installations supporting only v3, specify v3voms as authorisation plugin, egi.eu as identity provider, mapped as protocol, and the location of your proxy:\nopenstack --os-auth-url https://\u0026lt;keystone url\u0026gt;/v3 \\  --os-auth-type v3voms --os-x509-user-proxy /tmp/x509up_u1000 \\  --os-identity-provider egi.eu --os-protocol mapped \\  token issue +---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | expires | 2019-02-04T12:45:32+0000 | | id | gAAAAABcWCXcXGUDpHUYnI1IDLW3MnEpDzivw_OPaau8DQDYxA7gK9XsmOqZh1pL5Uqqs8aM-tHowdJQnJURww2-UhmQVqk5PxbjdnvLeqtXPYURCLaSsbmhkQg6kB311c_ZA1jfgdT-pG6fZz3toeH66SEFX-H0bThSUy0KFLhcZVkrZIbYgTsAOIzFkTfLjOgTw_tNChS8 | | user_id | 50fa8516b2554daeae652619ba9ebf96 | +---------+---------------------------------------------------------------------------------------------------------------------------------------- ","excerpt":"Authentication OpenID Connect is the main authentication protocol used on the EGI Cloud. It replaces …","ref":"/users/cloud-compute/auth/","title":"Authentication and Authorisation"},{"body":"","excerpt":"","ref":"/providers/check-in/","title":"Check-in"},{"body":"Chipster is a user-friendly software for analysing high-throughput data such as NGS and microarrays and provided as part of EGI's AoD service.\nThe software contains over 400 analysis tools and a large collection of reference genomes.\nUsers can save and share automatic analysis workflows, and visualize data interactively using for example the built-in genome browser.\nEGI Chipster The Chipster testbed configured at CESGA offers:\n 8 vCPU cores, 32GB of RAM, 1TB of block storage in /data, Software and tools are in available under the /cvmfs/tools_* partition, Chipster (v3.16.3).  For accessing this testbed you need to be a member of the Applications on Demand.\nCreate/Review a temporary account You need to create a temporary account to access the Chipster server, by default this account is valid for one month.\nGo to Chipster entry in Science Software on Demand Portal and:\n Click on the \u0026quot;Show form\u0026quot;. If the account has expired, the Science Gateway will automatically generate a new password for you.  To activate the new account, click on the \u0026quot;Execute\u0026quot; button to trigger the creation/update of the temporary account in the Chipster testbed. This operation may takes a few minutes. You can monitor the account creation by clicking in the \u0026quot;Show\u0026quot; button.   Once your account is available, the web interface will show a link to access the Chipster server with the new credentials.  Acknowledgment Please provide appropriate acknowledgement of the use in scientific publications. You can use this The following acknowledgement text this purpose:\nThis work used the EGI Applications on Demand service, which is co-funded by the EOSC-hub project (grant number 777536)\n ","excerpt":"Chipster is a user-friendly software for analysing high-throughput data such as NGS and microarrays …","ref":"/users/applications-on-demand/chipster/","title":"Chipster"},{"body":"Overview The FTS3 service offers a command line client to ease the interaction with the service.\nPrerequisites The client software is available for RHEL 6 and 7 derivatives.\nPlease note that the RHEL 6 support is ending the 30/11/2020 and the implementation for RHEL 8 is on-going.\nUsers from other distributions should refer to the RESTFul API section.\nInstallation The CLI can be installed from the EPEL repositories with the following package:\nyum install fts-rest-cli -y Commands This section describes some of the commands that can be issues via the FTS CLI. As per the API, in order to authenticate to the FTS REST server you need an X.509 User certificate, please refer to this section\nfor more information.\nFull documentation about the FTS CLI is available at:\nhttps://fts3-docs.web.cern.ch/fts3-docs/fts-rest/docs/cli/index.html\nfts-rest-whoami This command can be used to check, as the name suggests, who are we for the server.\nUsage fts-rest-whoami [options] Options -h/--help : Show this help message and exit -v/--verbose : Verbose output. -s/--endpoint : Fts3 rest endpoint. -j/--json : Print the output in json format. --key : The user certificate private key. --cert : The user certificate. --capath : Use the specified directory to verify the peer --insecure : Do not validate the server certificate --access-token : Oauth2 access token (supported only by some endpoints, takes precedence) Example $ fts-rest-whoami -s https://fts3-public.cern.ch:8446 User DN: /DC=org/DC=terena/DC=tcs/C=NL/O=Stichting EGI/CN=Andrea Manzi VO: dteam VO id: 6b10f4e4-8fdc-5555-baa2-7d4850d4f406 Delegation id: 9ab8068853808c6b Base id: 01874efb-4735-4595-bc9c-591aef8240c9 fts-rest-delegate This command can be used to (re)delegate your credentials to the FTS3 server.\nUsage fts-rest-delegate [options] Options -h/--help : Show this help message and exit -v/--verbose : Verbose output. -s/--endpoint : Fts3 rest endpoint. -j/--json : Print the output in json format. --key : The user certificate private key. --cert : The user certificate. --capath : Use the specified directory to verify the peer --insecure : Do not validate the server certificate --access-token : Oauth2 access token (supported only by some endpoints, takes precedence) -f/--force : Force the delegation -H/--hours : Duration of the delegation in hours (default: 12) Example $ fts-rest-delegate -s https://fts3-public.cern.ch:8446 Delegation id: 9ab8068853808c6b fts-rest-transfer-submit This command can be used to submit new jobs to FTS3. It supports simple and bulk submissions. The bulk format is as follows:\n{ \u0026#34;files\u0026#34;: [ { \u0026#34;sources\u0026#34;: [ \u0026#34;gsiftp://source.host/file\u0026#34; ], \u0026#34;destinations\u0026#34;: [ \u0026#34;gsiftp://destination.host/file\u0026#34; ], \u0026#34;metadata\u0026#34;: \u0026#34;file-metadata\u0026#34;, \u0026#34;checksum\u0026#34;: \u0026#34;ADLER32:1234\u0026#34;, \u0026#34;filesize\u0026#34;: 1024 }, { \u0026#34;sources\u0026#34;: [ \u0026#34;gsiftp://source.host/file2\u0026#34; ], \u0026#34;destinations\u0026#34;: [ \u0026#34;gsiftp://destination.host/file2\u0026#34; ], \u0026#34;metadata\u0026#34;: \u0026#34;file2-metadata\u0026#34;, \u0026#34;checksum\u0026#34;: \u0026#34;ADLER32:4321\u0026#34;, \u0026#34;filesize\u0026#34;: 2048, \u0026#34;activity\u0026#34;: \u0026#34;default\u0026#34; } ] } Usage fts-rest-transfer-submit [options] SOURCE DESTINATION [CHECKSUM] Options -h/--help : Show this help message and exit -v/--verbose : Verbose output. -s/--endpoint : Fts3 rest endpoint. -j/--json : Print the output in json format. --key : The user certificate private key. --cert : The user certificate. --capath : Use the specified directory to verify the peer --insecure : Do not validate the server certificate --access-token : Oauth2 access token (supported only by some endpoints, takes precedence) -b/--blocking : Blocking mode. Wait until the operation completes. -i/--interval : Interval between two poll operations in blocking mode. -e/--expire : Expiration time of the delegation in minutes. --delegate-when-lifetime-lt : Delegate the proxy when the remote lifetime is less than this value (in minutes) -o/--overwrite : Overwrite files. -r/--reuse : Enable session reuse for the transfer job. --job-metadata : Transfer job metadata. --file-metadata : File metadata. --file-size : File size (in bytes) -g/--gparam : Gridftp parameters. -t/--dest-token : The destination space token or its description. -S/--source-token : The source space token or its description. -K/--compare-checksum : Deprecated: compare checksums between source and destination. -C/--checksum-mode : Compare checksums in source, target, both or none. --copy-pin-lifetime : Pin lifetime of the copy in seconds. --bring-online : Bring online timeout in seconds. --timeout : Transfer timeout in seconds. --fail-nearline : Fail the transfer is the file is nearline. --dry-run : Do not send anything, just print the json message. -f/--file : Name of configuration file --retry : Number of retries. If 0, the server default will be used. If negative, there will be no retries. -m/--multi-hop : Submit a multihop transfer. --cloud-credentials : Use cloud credentials for the job (i. E. Dropbox). --nostreams : Number of streams --ipv4 : Force ipv4 --ipv6 : Force ipv6 Example fts-rest-transfer-submit -s https://fts3-public.cern.ch:8446 \\  gsiftp://source.host/file gsiftp://destination.host/file Job successfully submitted. Job id: 7e02b4fa-d568-11ea-9c80-02163e018681 $ fts-rest-transfer-submit -s https://fts3-public.cern.ch:8446 -f test.json Job successfully submitted. Job id: 9a28d204-d568-11ea-9c80-02163e018681 fts-rest-transfer-status This command can be used to check the current status of a given job.\nUsage fts-rest-transfer-status [options] JOB_ID Options -h/--help : Show this help message and exit -v/--verbose : Verbose output. -s/--endpoint : Fts3 rest endpoint. -j/--json : Print the output in json format. --key : The user certificate private key. --cert : The user certificate. --capath : Use the specified directory to verify the peer --insecure : Do not validate the server certificate --access-token : Oauth2 access token (supported only by some endpoints, takes precedence) Example fts-rest-transfer-status -s https://fts3-public.cern.ch:8446 \\  7e02b4fa-d568-11ea-9c80-02163e018681 Request ID: 7e02b4fa-d568-11ea-9c80-02163e018681 Status: FAILED Client DN: /DC=org/DC=terena/DC=tcs/C=NL/O=Stichting EGI/CN=Andrea Manzi Reason: One or more files failed. Please have a look at the details for more information Submission time: 2020-08-03T09:05:36 Priority: 3 VO Name: dteam fts-rest-transfer-cancel This command can be used to cancel a running job. It returns the final state of the cancelled job. Please, mind that if the job is already in a final state (FINISHEDDIRTY, FINISHED, FAILED), this command will return this state. You can additionally cancel only a subset appending a comma-separated list of file ids.\nUsage fts-rest-transfer-cancel [options] Options -h/--help : Show this help message and exit -v/--verbose : Verbose output. -s/--endpoint : Fts3 rest endpoint. -j/--json : Print the output in json format. --key : The user certificate private key. --cert : The user certificate. --capath : Use the specified directory to verify the peer --insecure : Do not validate the server certificate --access-token : Oauth2 access token (supported only by some endpoints, takes precedence) Example fts-rest-transfer-cancel -s https://fts3-public.cern.ch:8446 9a28d204-d568-11ea-9c80-02163e018681 CANCELED ","excerpt":"Overview The FTS3 service offers a command line client to ease the interaction with the service. …","ref":"/users/data-transfer/clients/","title":"Clients"},{"body":" The EGI Glossary is currently available on the EGI Wiki.\n ","excerpt":" The EGI Glossary is currently available on the EGI Wiki.\n ","ref":"/about/concepts/","title":"Concepts"},{"body":"The EGI Docker VA is a ready-to-use Virtual Machine Image with docker and docker-compose pre-installed.\nYou can start that image as any other VA available from AppDB:\n  Go to the EGI Docker image entry in AppDB.\n  Check the identifiers of the endpoint, image and flavor you want to use at the provider.\n  Use a ssh key when, so you can log into the VM once it's instantiated.\n  Once up, just ssh in the VM and start using docker as usual.\n  Using docker from inside the VM You can log in with user ubuntu and your ssh key:\nssh -i \u0026lt;yourprivatekey\u0026gt; ubuntu@\u0026lt;your VM ip\u0026gt; Once in, you can run any docker command, e.g.:\nubuntu@fedcloud_vm:~$ sudo docker run hello-world Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world b901d36b6f2f: Pull complete 0a6ba66e537a: Pull complete Digest: sha256:8be990ef2aeb16dbcb9271ddfe2610fa6658d13f6dfb8bc72074cc1ca36966a7 Status: Downloaded newer image for hello-world:latest Hello from Docker. This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \u0026quot;hello-world\u0026quot; image from the Docker Hub. 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker Hub account: https://hub.docker.com For more examples and ideas, visit: https://docs.docker.com/userguide/ Docker-compose can be also used to execute applications with more than one container running together, follow this documentation to learn more.\n","excerpt":"The EGI Docker VA is a ready-to-use Virtual Machine Image with docker and docker-compose …","ref":"/users/cloud-container-compute/docker/","title":"Docker VM"},{"body":"Templates We will build a torque cluster on one of the EGI Cloud providers using EC3. Create a directory to store EC3 configuration and init it with egicli:\nmkdir -p torque cd torque egicli endpoint ec3 --site \u0026lt;your site\u0026gt; --project-id \u0026lt;project_id\u0026gt; We will use the following templates:\n torque (from ec3 default templates) nfs (from ec3 detault templates), ubuntu-1604 (user\u0026rsquo;s template), cluster_configure (user\u0026rsquo;s template)  You can find the content below (make sure that you adapt them to your needs):\ntemplates/ubuntu-1604.radl specifies the VM image to use in the deployment:\ndescription ubuntu-1604 ( kind = \u0026#39;images\u0026#39; and short = \u0026#39;Ubuntu 16.04\u0026#39; and content = \u0026#39;FEDCLOUD Image for EGI Ubuntu 16.04 LTS [Ubuntu/16.04/VirtualBox]\u0026#39; ) system front ( cpu.arch = \u0026#39;x86_64\u0026#39; and cpu.count \u0026gt;= 4 and memory.size \u0026gt;= 8196 and disk.0.os.name = \u0026#39;linux\u0026#39; and disk.0.image.url = \u0026#39;ost://\u0026lt;url\u0026gt;/\u0026lt;image_id\u0026gt;\u0026#39; and disk.0.os.credentials.username = \u0026#39;ubuntu\u0026#39; ) system wn ( cpu.arch = \u0026#39;x86_64\u0026#39; and cpu.count \u0026gt;= 2 and memory.size \u0026gt;= 2048m and ec3_max_instances = 10 and # maximum number of working nodes in the cluster disk.0.os.name = \u0026#39;linux\u0026#39; and disk.0.image.url = \u0026#39;ost://\u0026lt;url\u0026gt;/\u0026lt;image_id\u0026gt;\u0026#39; and disk.0.os.credentials.username = \u0026#39;ubuntu\u0026#39; ) templates/cluster_configure.radl customises the torque deployment to match our needs:\nconfigure front ( @begin --- - vars: - USERS: - { name: user01, password: \u0026lt;PASSWORD\u0026gt; } - { name: user02, password: \u0026lt;PASSWORD\u0026gt; } [..] tasks: - user: name: \u0026#34;{{ item.name }}\u0026#34; password: \u0026#34;{{ item.password }}\u0026#34; shell: /bin/bash append: yes state: present with_items: \u0026#34;{{ USERS }}\u0026#34; - name: Install missing dependences in Debian system apt: pkg={{ item }} state=present with_items: - build-essential - mpich - gcc - g++ - vim become: yes when: ansible_os_family == \u0026#34;Debian\u0026#34; - name: SSH without password include_role: name: grycap.ssh vars: ssh_type_of_node: front ssh_user: \u0026#34;{{ user.name }}\u0026#34; loop: \u0026#39;{{ USERS }}\u0026#39; loop_control: loop_var: user - name: Updating the /etc/hosts.allow file lineinfile: path: /etc/hosts.allow line: \u0026#39;sshd: XXX.XXX.XXX.*\u0026#39; become: yes - name: Updating the /etc/hosts.deny file lineinfile: path: /etc/hosts.deny line: \u0026#39;ALL: ALL\u0026#39; become: yes @end ) configure wn ( @begin --- - vars: - USERS: - { name: user01, password: \u0026lt;PASSWORD\u0026gt; } - { name: user02, password: \u0026lt;PASSWORD\u0026gt; } [..] tasks: - user: name: \u0026#34;{{ item.name }}\u0026#34; password: \u0026#34;{{ item.password }}\u0026#34; shell: /bin/bash append: yes state: present with_items: \u0026#34;{{ USERS }}\u0026#34; - name: Install missing dependences in Debian system apt: pkg={{ item }} state=present with_items: - build-essential - mpich - gcc - g++ - vim become: yes when: ansible_os_family == \u0026#34;Debian\u0026#34; - name: SSH without password include_role: name: grycap.ssh vars: ssh_type_of_node: wn ssh_user: \u0026#34;{{ user.name }}\u0026#34; loop: \u0026#39;{{ USERS }}\u0026#39; loop_control: loop_var: user - name: Updating the /etc/hosts.allow file lineinfile: path: /etc/hosts.allow line: \u0026#39;sshd: XXX.XXX.XXX.*\u0026#39; become: yes - name: Updating the /etc/hosts.deny file lineinfile: path: /etc/hosts.deny line: \u0026#39;ALL: ALL\u0026#39; become: yes @end ) Create the cluster Deploy the cluster using ec3 docker image:\n$ docker run -it -v $PWD:/root/ -w /root \\  grycap/ec3 launch torque_cluster \\  torque nfs ubuntu-1604 refresh cluster_configure \\  -a auth.dat Creating infrastructure Infrastructure successfully created with ID: 529c62ec-343e-11e9-8b1d-300000000002 Front-end state: launching Front-end state: pending Front-end state: running IP: 212.189.145.XXX Front-end configured with IP 212.189.145.XXX Transferring infrastructure Front-end ready! To access the cluster, use the command:\n$ docker run -ti -v $PWD:/root/ -w /root grycap/ec3 ssh torque_cluster Warning: Permanently added \u0026#39;212.189.145.140\u0026#39; (ECDSA) to the list of known hosts. Welcome to Ubuntu 14.04.5 LTS (GNU/Linux 3.13.0-164-generic x86_64) * Documentation: https://help.ubuntu.com/ Last login: Tue Feb 19 13:04:45 2019 from servproject.i3m.upv.es Configuration of the cluster Enable Password-based authentication Change settings in /etc/ssh/sshd_config\n# Change to no to disable tunnelled clear text passwords PasswordAuthentication yes and restart the ssh daemon:\nsudo service ssh restart Configure the number of processors of the cluster $ cat /var/spool/torque/server_priv/nodes wn1 np=XX wn2 np=XX [...] To obtain the number of CPU/cores (np) in Linux, use the command:\n$ lscpu | grep -i CPU CPU op-mode(s): 32-bit, 64-bit CPU(s): 16 On-line CPU(s) list: 0-15 CPU family: 6 Model name: Intel(R) Xeon(R) CPU E5520 @ 2.27GHz CPU MHz: 2266.858 NUMA node0 CPU(s): 0-3,8-11 NUMA node1 CPU(s): 4-7,12-15 Test the cluster Create a simple test script:\n$ cat test.sh #!/bin/bash #PBS -N job #PBS -q batch #cd $PBS_O_WORKDIR/ hostname -f sleep 5 Submit to the batch queue:\nqsub -l nodes=2 test.sh Destroy the cluster To destroy the running cluster, use the command:\n$ docker run -it -v $PWD:/root/ -w /root grycap/ec3 destroy torque_cluster WARNING: you are going to delete the infrastructure (including frontend and nodes). Continue [y/N]? y Success deleting the cluster! ","excerpt":"Templates We will build a torque cluster on one of the EGI Cloud providers using EC3. Create a …","ref":"/users/cloud-compute/ec3/htc/","title":"HTC"},{"body":"Notebooks running on EGI can access other existing computing and storage services from EGI or other e-Infrastructures. For data services, check data section of the documentation\nEGI services: access tokens Most services integrated with EGI Check-in can handle valid access tokens for authorising users. These are short-lived (normally less than 1-hour) and need to be renewed for longer usage. EGI Notebooks provides a ready to use access token that can be accessed from your notebooks and is automatically refreshed so you can always have a valid one.\nThe token is available at /var/run/secrets/egi.eu/access_token and you can use it for example to access cloud providers of the EGI cloud. See the following sample code where a list of VMs is obtained for CESGA:\nfrom keystoneauth1.identity import v3 from keystoneauth1 import session from novaclient import client with open(\u0026#34;/var/run/secrets/egi.eu/access_token\u0026#34;) as f: access_token = f.read() auth = v3.OidcAccessToken(auth_url=\u0026#34;https://fedcloud-osservices.egi.cesga.es:5000/v3\u0026#34;, identity_provider=\u0026#34;egi.eu\u0026#34;, protocol=\u0026#34;openid\u0026#34;, project_id=\u0026#34;3a8e9d966e644405bf19b536adf7743d\u0026#34;, access_token=access_token) sess = session.Session(auth=auth) nova = client.Client(session=sess, version=2) nova.servers.list() A valid ID token is also available at /var/run/secrets/egi.eu/id_token.\nD4Science If you are using a Notebooks instance integrated with D4Science, you can easily invoke DataMiner or any other D4Science functionality as the service will provide the GCUBE_TOKEN environment variable with a valid token.\nThis code will print the list of DataMiner methods available within your VRE:\nimport os from owslib.wps import WebProcessingService # init http header parameter and base folders for gCube REST API gcube_vre_token_header = {\u0026#39;gcube-token\u0026#39;: os.environ[\u0026#34;GCUBE_TOKEN\u0026#34;]} # init WPS access for DataMiner algorithms dataminer_url = \u0026#39;http://dataminer-prototypes.d4science.org/wps/WebProcessingService\u0026#39; wps = WebProcessingService(dataminer_url, headers=gcube_vre_token_header) for process in wps.processes: print(\u0026#39;- Name: \u0026#39;, process.title) DataMiner algorithms can be invoked also from Notebooks, this code shows a sample:\nfrom owslib.wps import ComplexDataInput, monitorExecution # define processid and inputs processid = \u0026#39;org.gcube.dataanalysis.wps.statisticalmanager.synchserver.mappedclasses.transducerers.WOFOST_CLOUD_V0_2_1\u0026#39; inputs = [ (\u0026#39;ClassToRun\u0026#39;, \u0026#39;nl.wur.wofostsystem.App\u0026#39;), (\u0026#39;FileInput\u0026#39;, ComplexDataInput( \u0026#39;https://data.d4science.org/shub/E_eVhZTzBWWktOaVJxQjJkdTUxR3FHaTFFdE9BTDYrZkZxQnFWcGMyaVVJbXptejdDOEFpSVNmam82RllkRUJ6cA==\u0026#39;, mimeType=\u0026#34;text/xml\u0026#34;) ) ] # execute the process execution = wps.execute(processid, inputs) monitorExecution(execution, sleepSecs=5, download=True) print(execution.status) Note that inputs that point to a URL should be specified using the ComplextDataInput class as shown above.\nOther 3rd party services We are open for integration with other services that may be relevant for your research. Please contact support _at_ egi.eu with your request so we can investigate the best way to support your needs.\n","excerpt":"Notebooks running on EGI can access other existing computing and storage services from EGI or other …","ref":"/users/notebooks/integration/","title":"Integration with other services"},{"body":"There are several container management tools available, on the EGI Cloud we use Kubernetes as the default platform for our service. This guide explains how to get a running scalable Kubernetes deployment for your applications with EC3.\nGetting started Before getting your kubernetes cluster deployed, you need to get access to the Cloud Compute service, check the Authentication and Authorisation guide for more information. You should also get egicli installed to get EC3 templates needed to start deployment.\nYour kubernetes deployment needs to be performed at an specific provider (site) and project. Discover them using egicli as described in the EC3 tutorial.\nEC3 Templates EC3 relies on a set of templates that will determine what will be deployed on the infrastructure. egicli helps you to get an initial set of templates for your kubernetes deployment:\n$ mkdir k8s $ cd k8s $ egicli endpoint ec3 --site \u0026lt;your site\u0026gt; --project-id \u0026lt;project_id\u0026gt; You will also need a base image template for the deployment. Please refer to the EC3 tutorial to create such file. Below you can see an example for IFCA-LCG2 site with project related to vo.access.egi.eu:\ndescription ubuntu-ifca ( kind = 'images' and short = 'ubuntu18-ifca' and content = 'Ubuntu 18 image at IFCA-LCG2' ) network public ( provider_id = 'external' and outports contains '22/tcp' ) network private (provider_id = 'provider-2008') system front ( cpu.arch = 'x86_64' and cpu.count \u0026gt;= 2 and memory.size \u0026gt;= 2048 and disk.0.os.name = 'linux' and disk.0.image.url = 'ost://api.cloud.ifca.es/723171cb-53b2-4881-ae37-a7400ce0665b' and disk.0.os.credentials.username = 'cloudadm' ) system wn ( cpu.arch = 'x86_64' and cpu.count \u0026gt;= 2 and memory.size \u0026gt;= 2048 and ec3_max_instances = 5 and # maximum number of working nodes in the cluster disk.0.os.name = 'linux' and disk.0.image.url = 'ost://api.cloud.ifca.es/723171cb-53b2-4881-ae37-a7400ce0665b' and disk.0.os.credentials.username = 'cloudadm' ) Now you are ready to deploy the cluster using launch command of ec3 with:\n  the name of the deployment, k8s in this case\n  a list of templates: kubernetes for configuring kubernetes, ubuntu for specifying the image and site details, refresh to enable credential refresh and elasticity\n  the credentials to access the site with -a auth.dat\n  $ docker run -it -v $PWD:/root/ -w /root grycap/ec3 launch k8s kubernetes ubuntu refresh -a auth.dat Creating infrastructure Infrastructure successfully created with ID: b9577c34-f818-11ea-a644-2e0fc3c063db Front-end configured with IP 193.144.46.249 Transferring infrastructure Front-end ready! Your kubernetes deployment is now ready, log in with the ssh command of ec3:\n$ docker run -it -v $PWD:/root/ -w /root grycap/ec3 ssh k8s Warning: Permanently added \u0026#39;193.144.46.249\u0026#39; (ECDSA) to the list of known hosts. Welcome to Ubuntu 18.04.4 LTS (GNU/Linux 4.15.0-109-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage * Kubernetes 1.19 is out! Get it in one command with: sudo snap install microk8s --channel=1.19 --classic https://microk8s.io/ has docs and details. * Canonical Livepatch is available for installation. - Reduce system reboots and improve kernel security. Activate at: https://ubuntu.com/livepatch Last login: Wed Sep 16 14:35:35 2020 from 158.42.104.204 $ bash cloudadm@kubeserver:~$ You can interact with the kubernetes cluster with the kubectl command:\ncloudadm@kubeserver:~$ sudo kubectl get nodes NAME STATUS ROLES AGE VERSION kubeserver.localdomain Ready master 23h v1.18.3 The cluster will only have one node (the master) and will start new nodes as you create pods. Alternatively you can poweron nodes manually:\ncloudadm@kubeserver:~$ clues status node state enabled time stable (cpu,mem) used (cpu,mem) total ----------------------------------------------------------------------------------------------- wn1.localdomain off enabled 00h32\u0026#39;22\u0026#34; 0,0 1,1073741824 wn2.localdomain off enabled 00h32\u0026#39;22\u0026#34; 0,0 1,1073741824 wn3.localdomain off enabled 00h32\u0026#39;22\u0026#34; 0,0 1,1073741824 wn4.localdomain off enabled 00h32\u0026#39;22\u0026#34; 0,0 1,1073741824 wn5.localdomain off enabled 00h32\u0026#39;22\u0026#34; 0,0 1,1073741824 cloudadm@kubeserver:~$clues poweron wn1.localdomain node wn1.localdomain powered on cloudadm@kubeserver:~$sudo kubectl get nodes NAME STATUS ROLES AGE VERSION kubeserver.localdomain Ready master 24h v1.18.3 wn1.localdomain Ready \u0026lt;none\u0026gt; 6m49s v1.18.3 Exposing services outside the cluster Kubernetes uses services for exposing an applications via the network. The services can rely on Load Balancers supported at the underlying cloud provider, which is not always feasible on the EGI Cloud providers. As an alternative solution we use an ingress controller which allows us to expose services using rules based on host names.\nHelm allows you to quickly install the nginx based ingress. Add the helm repos:\ncloudadm@kubeserver:~$ sudo helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx cloudadm@kubeserver:~$ sudo helm repo add stable https://kubernetes-charts.storage.googleapis.com/ cloudadm@kubeserver:~$ sudo helm repo update Create a configuration file (ingress.yaml), get the externalIP using ip addr:\ncontroller:tolerations:- effect:NoSchedulekey:node-role.kubernetes.io/masterservice:type:NodePortexternalIPs:- 192.168.10.3defaultBackend:tolerations:- effect:NoSchedulekey:node-role.kubernetes.io/masterand install:\ncloudadm@kubeserver:~$ sudo helm install ingress -n kube-system -f ingress.yaml ingress-nginx/ingress-nginx Now you are ready to expose your services using a valid hostname. Use the EGI Cloud Dynamic DNS service for getting hostnames if you need. Assign as IP the public IP of the master node. Once you have a hostname assigned to the master IP, the ingress will be able to reply to requests already:\n$ curl ingress.test.fedcloud.eu \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;404 Not Found\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;center\u0026gt;\u0026lt;h1\u0026gt;404 Not Found\u0026lt;/h1\u0026gt;\u0026lt;/center\u0026gt; \u0026lt;hr\u0026gt;\u0026lt;center\u0026gt;nginx/1.19.2\u0026lt;/center\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; The following example yaml creates a service and exposes at that ingress.test.fedcloud.eu host:\napiVersion:apps/v1kind:Deploymentmetadata:name:nginx-deploymentspec:selector:matchLabels:app:nginxreplicas:1template:metadata:labels:app:nginxspec:containers:- name:nginximage:nginx:1.14.2ports:- containerPort:80---apiVersion:v1kind:Servicemetadata:name:my-nginxlabels:app:nginxspec:ports:- port:80protocol:TCPselector:app:nginx---apiVersion:networking.k8s.io/v1beta1kind:Ingressmetadata:name:ingress-testspec:rules:- host:ingress.test.fedcloud.euhttp:paths:- pathType:Prefixpath:\u0026#34;/\u0026#34;backend:serviceName:my-nginxservicePort:80Now the ingress will redirect request to the NGINX pod that we have just created:\n$ curl ingress.test.fedcloud.eu \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to nginx!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;If you see this page, the nginx web server is successfully installed and working. Further configuration is required.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;For online documentation and support please refer to \u0026lt;a href=\u0026#34;http://nginx.org/\u0026#34;\u0026gt;nginx.org\u0026lt;/a\u0026gt;.\u0026lt;br/\u0026gt; Commercial support is available at \u0026lt;a href=\u0026#34;http://nginx.com/\u0026#34;\u0026gt;nginx.com\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;em\u0026gt;Thank you for using nginx.\u0026lt;/em\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Volumes Volumes on these deployments can be supported with NFS volume driver. You can either manually configure the server on one of the nodes or use EC3 to deploy it and configure it for you. Create a templates/nfs.radl to do so:\ndescription nfs ( kind = 'component' and short = 'Tool to configure shared directories inside a network.' and content = 'Network File System (NFS) client allows you to access shared directories from Linux client.' ) system front ( ec3_templates contains 'nfs' and disk.0.applications contains (name = 'ansible.modules.grycap.nfs') ) configure front ( @begin - tasks: - name: Create /volume for supporting NFS file: path: /volumes state: directory mode: '0777' - roles: - role: grycap.nfs nfs_mode: 'front' nfs_exports: - path: \u0026quot;/volumes\u0026quot; export: \u0026quot;wn*.localdomain(rw,async,no_root_squash,no_subtree_check,insecure) kubeserver.localdomain(rw,async,no_root_squash,no_subtree_check,insecure)\u0026quot; @end ) system wn (ec3_templates contains 'nfs') configure wn ( @begin - tasks: - name: Install NFS common apt: name: nfs-common state: present @end ) if you have a running cluster, you can add the NFS support by reconfiguring the cluster:\n$ docker run -it -v $PWD:/root/ -w /root grycap/ec3 reconfigure k8s -a auth.dat -t nfs Reconfiguring infrastructure Front-end configured with IP 193.144.46.249 Transferring infrastructure Front-end ready! And then install the NFS driver in kubernetes with helm:\ncloudadm@kubeserver:~$ sudo helm install nfs-provisioner stable/nfs-client-provisioner \\  --namespace kube-system \\  --set nfs.server=192.168.10.9 \\  --set storageClass.defaultClass=true \\  --set nfs.path=/volumes \\  --set tolerations[0].effect=NoSchedule,tolerations[0].key=node-role.kubernetes.io/master Now you are ready to create a PVC and attach it to a pod, see this example:\n---apiVersion:v1kind:PersistentVolumeClaimmetadata:name:test-pvcspec:storageClassName:nfs-clientaccessModes:- ReadWriteOnceresources:requests:storage:3Gi---apiVersion:v1kind:Podmetadata:name:pvc-podnamespace:defaultspec:restartPolicy:Nevervolumes:- name:volpersistentVolumeClaim:claimName:test-pvccontainers:- name:testimage:\u0026#34;busybox\u0026#34;command:[\u0026#34;sleep\u0026#34;,\u0026#34;1d\u0026#34;]volumeMounts:- name:volmountPath:/volumeOnce you apply the yaml, you will see the new PVC gets bounded to a PV created in NFS:\ncloudadm@kubeserver:~$ sudo kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE test-pvc Bound pvc-39f970de-eaad-44d7-b49f-90dc9de54a14 3Gi RWO nfs-client 9m46s Destroying the cluster Once you don\u0026rsquo;t need the cluster anymore, you can undeploy with the destroy command of EC3:\n$ egicli endpoint ec3-refresh # refresh your credentials to interact with the cluster $ docker run -it -v $PWD:/root/ -w /root grycap/ec3 destroy k8s -y -a auth.dat WARNING: you are going to delete the infrastructure (including frontend and nodes). Success deleting the cluster! ","excerpt":"There are several container management tools available, on the EGI Cloud we use Kubernetes as the …","ref":"/users/cloud-container-compute/k8s/","title":"Kubernetes"},{"body":"Identity linking allows you to access EGI resources with your existing personal EGI ID, using any of the login credentials you have linked to your account. You can use any of your organisational or social login credentials for this purpose. To link a new organisational or social identity to your EGI account:\n  Enter the following URL in a browser: https://aai.egi.eu/registry\n  Click Login and authenticate using any of the login credentials already linked to your EGI account\n  Navigate to My EGI User Community Account page in one of the following ways:\n hover over your display name next to the gear icon on the top right corner of the page; or, alternatively, select EGI User Community from the list of available Collaborations and then click My EGI User Community Account from the People menu    Under the Organisational Identities section of your profile page, click Link New Identity.\n  On the introductory page for Identity Linking, click Begin\n  You will need to sign in using the login credentials from the institutional/social identity provider you want to link to your account.\nWarning It is very important to escape the identity provider selection, cached in the discovery page, before picking the new one.    After successful authentication, the new Identity Provider will be available under the Organizational Identities tab and you\u0026rsquo;ll be able to access EGI resources with your existing personal EGI ID using the login credentials of the identity provider you selected in Step 6.\n  Linking your certificate to your EGI Account Certificate linking allows you to add the subject DN of your certificate to your existing personal EGI ID. For this you need to import your certificate to your browser.\nTo link a subject DN to your EGI account:\n  Enter the following URL in a browser: https://aai.egi.eu/registry\n  Click Login and authenticate using any of the login credentials already linked to your EGI account\n  Navigate to My EGI User Community Account page in one of the following ways:\n hover over your display name next to the gear icon on the top right corner of the page; or, alternatively, select EGI User Community from the list of available Collaborations and then click My EGI User Community Account from the People menu    Under the Organisational Identities section of your profile page, click Link New Identity.\n  On the introductory page for Identity Linking, click Begin\n  Continuously, you will need to sign in using the IGTF Certificate Proxy.\nWarning It is very important to escape the identity provider selection, cached in the discovery page, before picking the new one.    Then select the certificate you want to link to your account from the popup window.\n  After successful authentication you will be redirected back to your EGI Account. Also, you\u0026rsquo;ll be able to access EGI resources with your existing personal EGI ID using IGTF Certificate Proxy and your certificate.\n  To verify that the subject DN is added to your EGI account scroll down to Organisational Identities and click on view button in the row where the source is https://edugain-proxy.igtf.net/simplesaml/saml2/idp/metadata.php.\n  Then scroll down to Certificates and you should see the subject DN of your certificate.\n  ","excerpt":"Identity linking allows you to access EGI resources with your existing personal EGI ID, using any of …","ref":"/users/check-in/linking/","title":"Linking identities"},{"body":"This documentation covers how to install and configure a OneData OneProvider in order to join a new or existing DataHub space. In particular 2 types of installations are available, depending if the provider wants to support the space with an an empty storage or if existing data are willing to be exposed via the OneProvider.\nRequirements for production installation  Oneprovider  RAM: 32GB CPU: 8 vCPU Disk: 50GB SSD To be adjusted for the dataset and usage scenario   For high IOPS  High performance backend storage (CEPH) Low latency network    Installation and attach empty storage to the EGI DataHub The installation of a new OneProvider is performed using the an installation script used onedatify which will setup the components using Docker and Docker-compose\nThe simple installation script can be generated from the EGI DataHub web interface.\nFirst you need to login to the EGI DataHub and from the Data menu you either select an existing space or create a new one.\nYou can then select on the space menu the Providers section and click on the Add Support button on the top right corner\nYou should then select on the page the tab: Deploy your own provider and there you will have just to copy the command having already the correct parameters for the OneZone to use (datahub.egi.eu) and the space to join.\nRun the command on the host Paste the copied command in the terminal on the OneProvider machine (as superuser).\nIf necessary, the Onedatify script will ask for permission to install all necessary dependencies including Docker and Docker Compose.\nAfter the dependency installation is complete, the script will ask several questions and suggest default setting for each one:\nThe progress can be monitored on a separate terminal using the following command:\nonedatify logs\nAfter the deployment is complete, the following message will be shown, with connection details for administration panel for the Oneprovider instance:\nThe WebUI Admin portal at port 9443 can be used to administer the OneProvider installation.\nInstallation and expose existing data to the EGI DataHub The installation of a new OneProvider to expose existing data sets to an EGI DataHub space is similar to the installation with an empty storage.\nWhen adding support to an existing or new space you should select from the EGI DataHub GUI the tab : Expose Existing dat set and there you will have just to copy the command having already the correct parameters for the OneZone to use (datahub.egi.eu) and the space to join.\nRun the command on the host Paste the copied command in the terminal on the OneProvider machine (as superuser) and follow the instructions as for the case of an empty storage.\nThe only difference is that at the end of the installation and configuration process the existing files will be automatically imported to the OneProvider.\nYou can monitor the import activity from the WebUI Admin panel at port 9443\n","excerpt":"This documentation covers how to install and configure a OneData OneProvider in order to join a new …","ref":"/providers/datahub/oneprovider/","title":"DataHub OneProvider"},{"body":"This manual provides information on how to set up a Resource Centre providing cloud resources in the EGI infrastructure. Integration with FedCloud requires a working OpenStack installation as a pre-requirement (see http://docs.openstack.org/ for details). Support for OpenStack is provided for the following versions:\n OpenStack Mitaka -- LTS under Ubuntu 16.04 (otherwise EOL) OpenStack Ocata OpenStack Pike OpenStack Queens (note that support for Keystone-VOMS is not available, only necessary for legacy VOs)  Support for other versions is not guaranteed and they are not recommended in production as they are EOL'd. See http://releases.openstack.org/ for more details on the OpenStack releases.\nEGI expects the following OpenStack services to be available and accessible from outside your site:\n Keystone Nova Cinder Glance Neutron Swift (if providing Object Storage)  FedCloud components are distributed through CMD (Cloud Middleware Distribution) or docker container images available in dockerhub. These docker containers come pre-packaged and ready to use in the EGI FedCloud Appliance so you do not need to install any extra components on your site but just run a VM and configure it approprietely to interact with your services.\nThe integration is performed by a set of EGI components that interact with the OpenStack services APIs:\n Authentication of EGI users into your system is performed by configuring the native OpenID Connect support of Keystone. Support for legacy VOs using VOMS requires the installation of the Keystone-VOMS Authorization plugin to allow users with a valid VOMS proxy to obtain tokens to access your OpenStack deployment. cASO collects accounting data from OpenStack and uses SSM to send the records to the central accounting database on the EGI Accounting service (APEL) cloud-info-provider registers the RC configuration and description through the EGI Information System to facilitate service discovery cloudkeeper (and cloudkeeper-os) synchronises with EGI AppDB so new or updated images can be provided by the RC to user communities (VO).  Not all EGI components need to share the same credentials. They are individually configured, you can use different credentials and permissions if desired.\nOptionally, ooi (OpenStack OCCI Interface) translates between OpenStack API and OCCI.\nInstallation options EGI distributes the integration components as:\n A Virtual Appliance (VA) that uses Docker containers to bundle all of the components in a single VM and just needs minor configuration to get started RPM and DEB Packages in the CMD distribution  FedCloud Virtual Appliance The EGI FedCloud Appliance is available at AppDB as an OVA file. You can easily extract the VMDK disk by untaring and optionally converting it to your preferred format with qemu-img:\n# get image and extract VMDK $ curl $(curl \u0026#34;https://appdb.egi.eu/store/vm/image/fc90d1aa-b0ae-46a0-b457-96f6f7a7d446:7875/json?strict\u0026#34; | jq -r .url) | \\  tar x \u0026#34;*.vmdk\u0026#34; # convert to qcow2 $ qemu-img convert -O qcow2 FedCloud-Appliance.Ubuntu.*.vmdk fedcloud-appliance.qcow2 The appliance running at your OpenStack must:\n Be accessible via public IP with port 2170 open for external connections. Have a host certificate to send the accounting information to the accounting repository. DN of the host certificate must be registered in GOCDB with service type eu.egi.cloud.accounting. The host certificate and key in PEM format are expected in /etc/grid-security/hostcert.pem and /etc/grid-security/hostkey.pem respectively. Have enough disk space for handling the VM image replication (~ 100GB for fedcloud.egi.eu VO). By default these are stored at /image_data. You can mount a volume at that location.  CMD Packages The CMD-OS repository provides packages that have gone through a quality assurance process for the supported distributions. Follow the the instructions for seting up the repos to install the packages.\nOpen Ports The following services must be accessible to allow access to an OpenStack-based FedCloud site (default ports listed below, can be adjusted to your installation)\n   Port Application Note     5000/TCP OpenStack/Keystone Authentication to your OpenStack.   8776/TCP OpenStack/cinder Block Storage management.   8774/TCP OpenStack/nova VM management.   9696/TCP OpenStack/neutron Network management.   9292/TCP OpenStack/glance VM Image management.   2170/TCP BDII/LDAP EGI Service Discovery/Information System.    Permissions This is an overview of the expected account permissions used in an OpenStack site, these accounts can be merged as needed for your deployment:\n   Component Permission     cloud-info Member of all projects supporting EGI VOs   accounting Member of all projects and able to list users (allowed to identity:list_users in keystone)   cloud-keeper Permission to manage the images for all the projects supporting EGI VOs   Other users Automatically created by Keystone and permission set as configured in the mappings    EGI AAI OpenID Connect Support The integration of OpenStack service providers into the EGI Check-in is a two-step process:\n Test integration with the development instance of EGI Check-in. This will allow you to check complete the complete functionality of the system without affecting the production Check-in service. Once the integration is working correctly, register your provider with the production instance of EGI Check-in to allow members of the EGI User Community to access your service.  Registration into Check-in development instance Before your service can use the EGI Check-in OIDC Provider for user login, you must set up a client at https://aai-dev.egi.eu/oidc/manage/#admin/clients in order to obtain OAuth 2.0 credentials and register one or more redirect URIs.\nMake sure that you fill in the following options:\n  Main tab:\n  Set redirect URL to https://\u0026lt;your keystone endpoint\u0026gt;/v3/auth/OS-FEDERATION/websso/openid/redirect. Recent versions of OpenStack may deploy Keystone at /identity/, be sure to include that in the \u0026lt;your keystone endpoint\u0026gt; part of the URL if needed.     Access tab:\n  Enable openid, profile, email, eduperson_entitlement and in the Scope field Enable authorization code in the Grant Types field Enable Allow calls to the Introspection Endpoint? in Introspection field     Once done, you will get a client id and client secret. Save them for the following steps\nKeystone setup Pre-requisites  Keystone must run as a WSGI application behind an HTTP server (Apache is used in this documentation, but any server should be possible if it has OpenID connect/OAuth2.0 support). Keystone project has deprecated eventlet, so you should be already running Keystone in such way. Keystone must be run with SSL You need to install mod_auth_openidc for adding support for OpenID Connect to Apache.  IGTF CAs EGI monitoring checks that your Keystone accepts clients with certificates from the IGTF CAs. Please ensure that your server is configured with the correct Certificate and Revocation path:\n For Apache HTTPd  HTTPd is able to use CAs and CRLs contained in a directory:\n  SSLCACertificatePath /etc/grid-security/certificates SSLCARevocationPath /etc/grid-security/certificates  For haproxy  CA and CRLS have to be bundled into one file.\nClient verification should be set as optional otherwise accepted CAs won't be presented to the EGI monitoring:\n# crt: concatenated cert, key and CA # ca-file: all IGTF CAs, concatenated as one file # crl-file: all IGTF CRLs, concatenated as one file # verify: enable optional X.509 client authentication bind XXX.XXX.XXX.XXX:443 ssl crt /etc/haproxy/certs/host-cert-with-key-and-ca.pem ca-file /etc/haproxy/certs/igtf-cas-bundle.pem crl-file /etc/haproxy/certs/igtf-crls-bundle.pem verify optional  For nginx  CA and CRLS have to be bundled into one file.\nClient verification should be set as optional otherwise accepted CAs won't be presented to the EGI monitoring:\nssl_client_certificate /etc/ssl/certs/igtf-cas-bundle.pem; ssl_crl /etc/ssl/certs/igtf-crls-bundle.pem; ssl_verify_client optional;  Managing IGTF CAs and CRLs  IGTF CAs can be obtained from UMD, you can find repo files for your distribution at http://repository.egi.eu/sw/production/cas/1/current/\nIGTF CAs and CRLs can be bundled using the examples command hereafter.\nPlease update CAs bundle after IGTF updates, and CRLs bundle after each CRLs update made by fetch-crl:\ncat /etc/grid-security/certificates/*.pem \u0026gt; /etc/haproxy/certs/igtf-cas-bundle.pem cat /etc/grid-security/certificates/*.r0 \u0026gt; /etc/haproxy/certs/igtf-crls-bundle.pem # Some CRLs files are not ending with a new line # Ensuring that CRLs markers are separated by a line feed perl -pe \u0026#39;s/----------/-----\\n-----/\u0026#39; -i /etc/haproxy/certs/igtf-crls-bundle.pem    Apache Configuration Include this configuration on the Apache config for the virtual host of your Keystone service, using the client id and secret obtained above:\nOIDCResponseType \u0026#34;code\u0026#34; OIDCClaimPrefix \u0026#34;OIDC-\u0026#34; OIDCClaimDelimiter ; OIDCScope \u0026#34;openid profile email eduperson_entitlement\u0026#34; OIDCProviderMetadataURL https://aai-dev.egi.eu/oidc/.well-known/openid-configuration OIDCClientID \u0026lt;client id\u0026gt; OIDCClientSecret \u0026lt;client secret\u0026gt; OIDCCryptoPassphrase \u0026lt;some crypto pass phrase\u0026gt; OIDCRedirectURI https://\u0026lt;your keystone endpoint\u0026gt;/v3/auth/OS-FEDERATION/websso/openid/redirect # OAuth for CLI access OIDCOAuthIntrospectionEndpoint https://aai-dev.egi.eu/oidc/introspect OIDCOAuthClientID \u0026lt;client id\u0026gt; OIDCOAuthClientSecret \u0026lt;client secret\u0026gt; # Increase Shm cache size for supporting long entitlements OIDCCacheShmEntrySizeMax 65536 \u0026lt;Location ~ \u0026#34;/v3/auth/OS-FEDERATION/websso/openid\u0026#34;\u0026gt; AuthType openid-connect Require valid-user \u0026lt;/Location\u0026gt; \u0026lt;Location ~ \u0026#34;/v3/OS-FEDERATION/identity_providers/egi.eu/protocols/openid/auth\u0026#34;\u0026gt; Authtype oauth20 Require valid-user \u0026lt;/Location\u0026gt; If you have multiple keystone hosts, configure an alternative caching mechanism as per https://github.com/zmartzone/mod_auth_openidc/wiki/Caching\nFor example, using memcache\nOIDCCacheType memcache OIDCMemCacheServers \u0026#34;memcache1 memcache2 memcache3\u0026#34; Be sure to enable the mod_auth_oidc module in Apache, in Ubuntu:\nsudo a2enmod auth_openidc  Note If running Keystone behind a proxy, make sure to correctly set the X-Forwarded-Proto and X-Forwarded-Port request headers, e.g. for haproxy:\nhttp-request set-header X-Forwarded-Proto https if { ssl_fc } http-request set-header X-Forwarded-Proto http if !{ ssl_fc } http-request set-header X-Forwarded-Port %[dst_port]   Keystone Configuration Configure your keystone.conf to include in the [auth] section openid in the list of authentication methods:\n[auth] # This may change in your installation # add openid to the list of the methods you support methods = password, token, openid Add a [openid] section as follows:\n[openid] # this is the attribute in the Keystone environment that will define the # identity provider remote_id_attribute = HTTP_OIDC_ISS Add your horizon host as trusted dashboard to the [federation] section:\n[federation] trusted_dashboard = https://\u0026lt;your horizon\u0026gt;/dashboard/auth/websso/ Finally copy the default template for managing the tokens in horizon to /etc/keystone/sso_callback_template.html. This template can be found in keystone git repo at https://github.com/openstack/keystone/blob/master/etc/sso_callback_template.html\ncurl -L https://raw.githubusercontent.com/openstack/keystone/master/etc/sso_callback_template.html \\  \u0026gt; /etc/keystone/sso_callback_template.html Now restart your Apache (and Keystone if running in uwsgi) so you can configure the Keystone Federation support.\nKeystone Federation Support First, create a new egi.eu identity provider with remote id https://aai-dev.egi.eu/oidc/:\n$ openstack identity provider create --remote-id https://aai-dev.egi.eu/oidc/ egi.eu +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | None | | domain_id | 1cac7817dafb4740a249cc9ca6b14ea5 | | enabled | True | | id | egi.eu | | remote_ids | https://aai-dev.egi.eu/oidc/ | +-------------+----------------------------------+ Create a group for users coming from EGI Check-in, usual configuration is to have one group per VO you want to support.\n$ openstack group create ops +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | | | domain_id | default | | id | 89cf5b6708354094942d9d16f0f29f8f | | name | ops | +-------------+----------------------------------+ Add that group to the desired local project:\nopenstack role add member --group ops --project ops Define a mapping of users from EGI Check-in to the group just created and restrict with the OIDC-eduperson_entitlement the VOs you want to support for that group. Substitute the group id and the allowed entitlements for the adequate values for your deployment:\n$ cat mapping.egi.json [ { \u0026#34;local\u0026#34;: [ { \u0026#34;user\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;{0}\u0026#34; }, \u0026#34;group\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;89cf5b6708354094942d9d16f0f29f8f\u0026#34; } } ], \u0026#34;remote\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;HTTP_OIDC_SUB\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;HTTP_OIDC_ISS\u0026#34;, \u0026#34;any_one_of\u0026#34;: [ \u0026#34;https://aai-dev.egi.eu/oidc/\u0026#34; ] }, { \u0026#34;type\u0026#34;: \u0026#34;OIDC-eduperson_entitlement\u0026#34;, \u0026#34;regex\u0026#34;: true, \u0026#34;any_one_of\u0026#34;: [ \u0026#34;^urn:mace:egi.eu:group:ops:role=vm_operator#aai.egi.eu$\u0026#34; ] } ] } ] More recent versions of Keystone allow for more elaborated mapping, but this configuration should work for Mitaka and onwards\nCreate the mapping in Keystone:\n$ openstack mapping create --rules mapping.egi.json egi-mapping +-------+----------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +-------+----------------------------------------------------------------------------------------------------------------------------------+ | id | egi-mapping | | rules | [{u\u0026#39;remote\u0026#39;: [{u\u0026#39;type\u0026#39;: u\u0026#39;HTTP_OIDC_SUB\u0026#39;}, {u\u0026#39;type\u0026#39;: u\u0026#39;HTTP_OIDC_ISS\u0026#39;, u\u0026#39;any_one_of\u0026#39;: [u\u0026#39;https://aai-dev.egi.eu/oidc/\u0026#39;]}, | | | {u\u0026#39;regex\u0026#39;: True, u\u0026#39;type\u0026#39;: u\u0026#39;OIDC-eduperson_entitlement\u0026#39;, u\u0026#39;any_one_of\u0026#39;: [u\u0026#39;^urn:mace:egi.eu:.*:ops:vm_operator@egi.eu$\u0026#39;]}], | | | u\u0026#39;local\u0026#39;: [{u\u0026#39;group\u0026#39;: {u\u0026#39;id\u0026#39;: u\u0026#39;89cf5b6708354094942d9d16f0f29f8f\u0026#39;}, u\u0026#39;user\u0026#39;: {u\u0026#39;name\u0026#39;: u\u0026#39;{0}\u0026#39;}}]}] | +-------+----------------------------------------------------------------------------------------------------------------------------------+ Finally, create the federated protocol with the identity provider and mapping created before:\n$ openstack federation protocol create \\  --identity-provider egi.eu \\  --mapping egi-mapping openid +-------------------+-------------+ | Field | Value | +-------------------+-------------+ | id | openid | | identity_provider | egi.eu | | mapping | egi-mapping | +-------------------+-------------+ Keystone is now ready to accept EGI Check-in credentials.\nHorizon Configuration Edit your local_settings.py to include the following values:\n# Enables keystone web single-sign-on if set to True. WEBSSO_ENABLED = True # Allow users to choose between local Keystone credentials or login # with EGI Check-in WEBSSO_CHOICES = ( (\u0026#34;credentials\u0026#34;, _(\u0026#34;Keystone Credentials\u0026#34;)), (\u0026#34;openid\u0026#34;, _(\u0026#34;EGI Check-in\u0026#34;)), ) Once horizon is restarted you will be able to choose \u0026quot;EGI Check-in\u0026quot; for login.\nCLI Access The OpenStack Client has built-in support for using OpenID Connect Access Tokens to authenticate. You first need to get a valid token from EGI Check-in (e.g. from https://aai-dev.egi.eu/fedcloud/) and then use it in a command like:\n$ openstack --os-auth-url https://\u0026lt;your keystone endpoint\u0026gt;/v3 \\  --os-auth-type v3oidcaccesstoken --os-protocol openid \\  --os-identity-provider egi.eu \\  --os-access-token \u0026lt;your access token\u0026gt; \\  token issue +---------+---------------------------------------------------------------------------------------+ | Field | Value | +---------+---------------------------------------------------------------------------------------+ | expires | 2017-05-23T11:24:31+0000 | | id | gAAAAABZJA3fbKX....nEMAPi-IsFOCkU9QWGTISYElzYJsI3z0SJGs7QsTJv4aJQq0JDJUBz6uE85SqXDj3 | | user_id | 020864ea9415413f9d706f6b473dbeba | +---------+---------------------------------------------------------------------------------------+ Additional VOs Configuration can include as many mappings as needed in the json file. Users will be members of all the groups matching the remote part of the mapping. For example this file has 2 mappings, one for members of ops and another for members of fedcloud.egi.eu:\n[ { \u0026#34;local\u0026#34;: [ { \u0026#34;user\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;{0}\u0026#34; }, \u0026#34;group\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;66df3a7a0c6248cba8b729de7b042639\u0026#34; } } ], \u0026#34;remote\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;HTTP_OIDC_SUB\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;HTTP_OIDC_ISS\u0026#34;, \u0026#34;any_one_of\u0026#34;: [\u0026#34;https://aai-dev.egi.eu/oidc/\u0026#34;] }, { \u0026#34;type\u0026#34;: \u0026#34;OIDC-eduperson_entitlement\u0026#34;, \u0026#34;regex\u0026#34;: true, \u0026#34;any_one_of\u0026#34;: [ \u0026#34;^urn:mace:egi.eu:group:ops:role=vm_operator#aai.egi.eu$\u0026#34; ] } ] }, { \u0026#34;local\u0026#34;: [ { \u0026#34;user\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;{0}\u0026#34; }, \u0026#34;group\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;e1c04284718f4e19bb0516e5534a24e8\u0026#34; } } ], \u0026#34;remote\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;HTTP_OIDC_SUB\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;HTTP_OIDC_ISS\u0026#34;, \u0026#34;any_one_of\u0026#34;: [\u0026#34;https://aai-dev.egi.eu/oidc/\u0026#34;] }, { \u0026#34;type\u0026#34;: \u0026#34;OIDC-eduperson_entitlement\u0026#34;, \u0026#34;regex\u0026#34;: true, \u0026#34;any_one_of\u0026#34;: [ \u0026#34;^urn:mace:egi.eu:group:fedcloud.egi.eu:role=vm_operator#aai.egi.eu$\u0026#34; ] } ] } ] Moving to EGI Check-in production instance Once tests in the development instance of Check-in are successful, you can move to the production instance. You should open a GGUS ticket for the request. Besides you will need to update your configuration as follows:\n  Update the remote-id of the identity provider:\nopenstack identity provider set --remote-id https://aai.egi.eu/oidc/ egi.eu   Update the HTTP_OIDC_ISS filter in your mappings, e.g.:\nsed -i \u0026#39;s/aai-dev.egi.eu/aai.egi.eu/\u0026#39; mapping.egi.json openstack mapping set --rules mapping.egi.json egi-mapping   Update Apache configuration to use [aai.egi.eu]{.title-ref} instead of `aai-dev.egi.eu`:\nOIDCProviderMetadataURL https://aai.egi.eu/oidc/.well-known/openid-configuration OIDCOAuthIntrospectionEndpoint https://aai.egi.eu/oidc/introspect   Changes in the production settings If you want to make any changes to the client configuration of the production instance, first make the changes in the Check-in development environment and then open a GGUS ticket to sync the changes to production.  VOMS Support VOMS with FEDERATION-OS (Keystone API v3) Deprecated! Configure VOMS with FEDERATION-OS if your site needs to support a legacy VO relying on VOMS for authorisation, check Keystone-VOMS below for older OpenStack versions.  VOMS authentication requires Keystone to be run as a WSGI application behind an Apache server with gridsite and SSL support. GridSite is a set of extensions to the Apache 2.x webserver, which support Grid security based on X.509 certificates.\nPackages for gridsite can be obtained from CMD-OS-1. Follow the CMD-OS-1 guidelines for getting the packages for your distribution.\nFirst install the gridsite, fetch-crl and ca-policy-egi-core for your distribution, ensuring that gridsite is at least version 2.3.2. For Ubuntu 16.04:\napt-get install gridsite fetch-crl ca-policy-egi-core Configure Apache to use gridsite module (this may differ in your distribution):\na2enmod zgridsite Include these lines on your Apache config for the virtual host of your Keystone service:\n# Use the IGTF trust anchors for CAs and CRLs SSLCACertificatePath /etc/grid-security/certificates/ SSLCARevocationPath /etc/grid-security/certificates/ # Verify clients if they send their certificate SSLVerifyClient optional SSLVerifyDepth 10 SSLOptions +StdEnvVars +ExportCertData # Adapt this URL if needed for your deployment \u0026lt;Location /v3/OS-FEDERATION/identity_providers/egi.eu/protocols/mapped/auth\u0026gt; # populate ENV variables GridSiteEnvs on # turn off directory listings GridSiteIndexes off # accept GSI proxies from clients GridSiteGSIProxyLimit 4 # disable GridSite method extensions GridSiteMethods \u0026#34;\u0026#34; Require all granted Options -MultiViews \u0026lt;/Location\u0026gt; Make sure that mapped authentication method exists in your keystone.conf in the [auth] section:\n[auth] # This may change in your installation, # add mapped to the list of the methods you support methods = password, token, openid, mapped Create an egi.eu identity provider and any needed groups as described in Keystone Federation Support (do not forget to add roles to the new group). Use those groups to create appropriate mappings to the VOs you intend to support. You can use the GRST_VOMS_FQANS to match to the VOMS FQAN that you want to create the mapping for. The following is an example for the fedcloud.egi.eu VO:\n$ openstack group create fedcloud.egi.eu +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | | | domain_id | default | | id | fbccb5f81f9741fd8b84736cc10c1d34 | | name | fedcloud.egi.eu | +-------------+----------------------------------+ $ cat mapping.voms.json [ { \u0026#34;local\u0026#34;: [ { \u0026#34;user\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;{0}\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;ephemeral\u0026#34; }, \u0026#34;group\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;fbccb5f81f9741fd8b84736cc10c1d34\u0026#34; } } ], \u0026#34;remote\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;GRST_CONN_AURI_0\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;GRST_VOMS_FQANS\u0026#34;, \u0026#34;any_one_of\u0026#34;: [ \u0026#34;^/fedcloud.egi.eu/.*\u0026#34; ], \u0026#34;regex\u0026#34;: true } ] } ] $ openstack mapping create --rules mapping.voms.json voms +-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | id | voms | | rules | [{u\u0026#39;remote\u0026#39;: [{u\u0026#39;type\u0026#39;: u\u0026#39;GRST_CONN_AURI_0\u0026#39;}, {u\u0026#39;regex\u0026#39;: True, u\u0026#39;type\u0026#39;: u\u0026#39;GRST_VOMS_FQANS\u0026#39;, u\u0026#39;any_one_of\u0026#39;: [u\u0026#39;^/fedcloud.egi.eu/.*\u0026#39;]}], u\u0026#39;local\u0026#39;: [{u\u0026#39;group\u0026#39;: {u\u0026#39;id\u0026#39;: u\u0026#39;7d9a21050cef48889f23eb9d5f7fef51\u0026#39;}, u\u0026#39;user\u0026#39;: {u\u0026#39;type\u0026#39;: u\u0026#39;ephemeral\u0026#39;, u\u0026#39;name\u0026#39;: u\u0026#39;{0}\u0026#39;}}]}] | +-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ Finally add the mapped protocol to your egi.eu identity provider with the mapping you have created:\n$ openstack federation protocol create \\  --identity-provider egi.eu --mapping voms mapped +-------------------+--------+ | Field | Value | +-------------------+--------+ | id | mapped | | identity_provider | egi.eu | | mapping | voms | +-------------------+--------+ For every VO you support you should configure the corresponding .lsc files at /etc/grid-security/vomsdir/\u0026lt;vo name\u0026gt;/. Those files depend on each VO, check the Operations Portal for details. You can find below the fedcloud.egi.eu configuration:\n$ cat /etc/grid-security/vomsdir/fedcloud.egi.eu/voms1.grid.cesnet.cz.lsc /DC=cz/DC=cesnet-ca/O=CESNET/CN=voms1.grid.cesnet.cz /DC=cz/DC=cesnet-ca/O=CESNET CA/CN=CESNET CA 3 $ cat /etc/grid-security/vomsdir/fedcloud.egi.eu/voms2.grid.cesnet.cz.lsc /DC=cz/DC=cesnet-ca/O=CESNET/CN=voms2.grid.cesnet.cz /DC=cz/DC=cesnet-ca/O=CESNET CA/CN=CESNET CA 3 You can test easily test the authentication is working using curl with your proxy:\n$ curl -s --cert /tmp/x509up_u1000 \\  https://\u0026lt;your keystone host\u0026gt;/v3/OS-FEDERATION/identity_providers/egi.eu/protocols/mapped/auth | \\  python -mjson.tool { \u0026#34;token\u0026#34;: { \u0026#34;audit_ids\u0026#34;: [ \u0026#34;wxB8VZeHSji0D57Z86PSTA\u0026#34; ], \u0026#34;expires_at\u0026#34;: \u0026#34;2018-08-24T12:40:41.000000Z\u0026#34;, \u0026#34;issued_at\u0026#34;: \u0026#34;2018-08-24T11:40:41.000000Z\u0026#34;, \u0026#34;methods\u0026#34;: [ \u0026#34;mapped\u0026#34; ], \u0026#34;user\u0026#34;: { \u0026#34;OS-FEDERATION\u0026#34;: { \u0026#34;groups\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;fbccb5f81f9741fd8b84736cc10c1d34\u0026#34; } ], \u0026#34;identity_provider\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;egi.eu\u0026#34; }, \u0026#34;protocol\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;mapped\u0026#34; } }, \u0026#34;domain\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;Federated\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Federated\u0026#34; }, \u0026#34;id\u0026#34;: \u0026#34;ea6520b3ad34400ba07115f7a3987a6b\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;dn:/DC=org/DC=terena/DC=tcs/C=NL/O=EGI/OU=UCST/CN=Enol+Fernandez\u0026#34; } } } Keystone-VOMS (Keystone API v2) Deprecated! VOMS Support using Keystone-VOMS is no longer supported from OpenStack Queens onwards. You should use VOMS with FEDERATION-OS (Keystone API v3) or OpenID Connect Support instead.  Support for authenticating users with X.509 certificates with VOMS extensions is achieved with Keystone-VOMS extension. Documentation is available at https://keystone-voms.readthedocs.io/\nNotes:\n  You need a host certificate from a recognised CA for your keystone server.\n  Take into account that using keystone-voms plugin will enforce the use of https for your Keystone service, you will need to update your URLs in the configuration of your services if your current installation is not using https:\n you will probably need to include your CA to your system's CA bundle to avoid certificate validation issues: Check the Federated Cloud OpenStack Client guide on how to do it. replace http with https in auth_[protocol|uri|url] and auth_[host|uri|url] in the nova, cinder, glance and neutron config files (/etc/nova/nova.conf, /etc/nova/api-paste.ini, /etc/neutron/neutron.conf, /etc/neutron/api-paste.ini, /etc/neutron/metadata_agent.ini, /etc/cinder/cinder.conf, /etc/cinder/api-paste.ini, /etc/glance/glance-api.conf, /etc/glance/glance-registry.conf, /etc/glance/glance-cache.conf) and any other service that needs to check keystone tokens. Update the URLs of the services directly in the database:  mysql\u0026gt; use keystone; mysql\u0026gt; update endpoint set url=\u0026#34;https://\u0026lt;keystone-host\u0026gt;:5000/v2.0\u0026#34; where url=\u0026#34;http://\u0026lt;keystone-host\u0026gt;:5000/v2.0\u0026#34;; mysql\u0026gt; update endpoint set url=\u0026#34;https://\u0026lt;keystone-host\u0026gt;:35357/v2.0\u0026#34; where url=\u0026#34;http://\u0026lt;keystone-host\u0026gt;:35357/v2.0\u0026#34;;   Most sites should enable the autocreate_users option in the [voms] section of Keystone-VOMS configuration. This will enable new users to be automatically created in your local keystone the first time they login into your site.\n  if (and only if) you need to configure the Per-User Subproxy (PUSP) feature, please follow the specific guide.\n  EGI Accounting There are two different processes handling the accounting integration:\n cASO, which connects to the OpenStack deployment to get the usage information, and, ssmsend, which sends that usage information to the central EGI accounting repository.  They should be run by cron periodically, settings below run cASO every hour and ssmsend every six hours.\nUsing the VM Appliance cASO configuration is stored at /etc/caso/caso.conf. Most default values should be ok, but you must set:\n  site_name (line 12), with the name of your site as defined in GOCDB.\n  projects (line 20), with the list of projects you want to extract accounting from.\n  credentials to access the accounting data (lines 28-47, more options also available). Check the cASO documentation for the expected permissions of the user configured here.\n  The mapping from EGI VOs to your local projects /etc/caso/voms.json, following this format: :\n{ \u0026#34;vo name\u0026#34;: { \u0026#34;projects\u0026#34;: [ \u0026#34;project A that accounts for the vo\u0026#34;, \u0026#34;project B that accounts for the VO\u0026#34; ] }, \u0026#34;another vo\u0026#34;: { \u0026#34;projects\u0026#34;: [\u0026#34;project C that accounts for the VO\u0026#34;] } }   cASO will write records to /var/spool/apel from where ssmsend will take them.\nSSM configuration is available at /etc/apel. Defaults should be ok for most cases. The cron file uses /etc/grid-security for the CAs and the host certificate and private keys (/etc/grid-security/hostcert.pem and /etc/grid-security/hostkey.pem).\nRunning the services Both caso and ssmsend are run via the root user crontab. For convenience there are two scripts /usr/local/bin/caso-extract.sh and /usr/local/bin/ssm-send.sh that run the docker container with the proper volumes.\nEGI Information System Information discovery provides a real-time view about the actual images and flavors available at the OpenStack for the federation users. It has two components:\n Resource-Level BDII: which queries the OpenStack deployment to get the information to publish Site-Level BDII: gathers information from several resource-level BDIIs and makes it publicly available for the EGI information system.  Using the VM Appliance Resource-level BDII This is provided by container egifedcloud/cloudbdii. You need to configure:\n /etc/cloud-info-provider/openstack.rc, with the credentials to query your OpenStack. The user configured just needs to be able to access the lists of images and flavors. /etc/cloud-info-provider/openstack.yaml, this file includes the static information of your deployment. Make sure to set the SITE-NAME as defined in GOCDB.  Site-level BDII The egifedcloud/sitebdii container runs this process. Configuration files:\n /etc/sitebdii/glite-info-site-defaults.conf. Set here the name of your site (as defined in GOCDB) and the public hostname where the appliance will be available. /etc/sitebdii/site.cfg. Include here basic information on your site.  Running the services There is a bdii.service unit for systemd available in the appliance. This leverages docker-compose for running the containers. You can start the service with:\nsystemctl start bdii Check the status with:\nsystemctl status bdii And stop with:\nsystemctl stop bdii You should be able to get the BDII information with an LDAP client, e.g.:\nldapsearch -x -p 2170 -h \u0026lt;yourVM.hostname.domain.com\u0026gt; -b o=glue EGI VM Image Management VM Images are replicated using [cloudkeeper]{.title-ref}, which has two components:\n fronted (cloudkeeper-core) dealing the with image lists and downloading the needed images, run periodically with cron backend (cloudkeeper-os) dealing with your glance catalogue, running permanently.  Using the VM Appliance Every 4 hours, the appliance will perform the following actions:\n download the configured lists in /etc/cloudkeeper/image-lists.conf and verify its signature check any changes in the lists and download new images synchronise this information to the configured glance endpoint  First you need to configure and start the backend. Edit /etc/cloudkeeper-os/cloudkeeper-os.conf and add the authentication parameters from line 117 to 136.\nThen add as many image lists (one per line) as you would like to subscribe to /etc/cloudkeeper/image-lists.conf. Use URLs with your AppDB token for authentication, check the following guides for getting such token and URLs:\n how to access to VO-wide image lists, and how to subscribe to a private image list.  Running the services cloudkeeper-os should run permanently, there is a cloudkeeper-os.service for systemd in the appliance. Manage as usual:\nsystemctl \u0026lt;start|stop|status\u0026gt; cloudkeeper-os cloudkeeper core is run every 4 hours with a cron script.\nPost-installation After the installation of all the needed components, it is recommended to set the following policies on Nova to avoid users accessing other users resources:\nsed -i \u0026#39;s|\u0026#34;admin_or_owner\u0026#34;: \u0026#34;is_admin:True or project_id:%(project_id)s\u0026#34;,|\u0026#34;admin_or_owner\u0026#34;: \u0026#34;is_admin:True or project_id:%(project_id)s\u0026#34;,\\n \u0026#34;admin_or_user\u0026#34;: \u0026#34;is_admin:True or user_id:%(user_id)s\u0026#34;,|g\u0026#39; /etc/nova/policy.json sed -i \u0026#39;s|\u0026#34;default\u0026#34;: \u0026#34;rule:admin_or_owner\u0026#34;,|\u0026#34;default\u0026#34;: \u0026#34;rule:admin_or_user\u0026#34;,|g\u0026#39; /etc/nova/policy.json sed -i \u0026#39;s|\u0026#34;compute:get_all\u0026#34;: \u0026#34;\u0026#34;,|\u0026#34;compute:get\u0026#34;: \u0026#34;rule:admin_or_owner\u0026#34;,\\n \u0026#34;compute:get_all\u0026#34;: \u0026#34;\u0026#34;,|g\u0026#39; /etc/nova/policy.json Upgrading the OpenStack Appliance From 2017.08.09 to 2018.05.07 Configuration changes:\n This upgrade moves the voms.json file to the respective caso and cloudkeeper-os directories under /etc/ No other changes in configuration are needed  From 20160403 to 2017.08.09 There are several major changes between these versions, namely:\n atrope has been deprecated and cloudkeeper is used instead. The configuration cannot be reused directly and the new services need to be configured as described above caso is upgraded to version 1.1.1, the configuration file has some incompatible changes. A new bdii.service is available for managing the process is available.  ","excerpt":"This manual provides information on how to set up a Resource Centre providing cloud resources in the …","ref":"/providers/cloud-compute/openstack/","title":"OpenStack"},{"body":"In this section you can find the common operational activities related to keep the service available to our users.\nInitial set-up Notebooks VO The resources used for the Notebooks deployments are managed with the vo.notebooks.egi.eu VO. Operators of the service should join the VO, check the entry at the operations portal and at AppDB.\nClients installation In order to manage the resources you will need these tools installed on your client machine:\n egicli for discovering sites and managing tokens, terraform to create the VMs at the providers, ansible to configure the VMs and install kubernetes at the providers, terraform-inventory to get the list of hosts to use from terraform.  Get the configuration repo All the configuration of the notebooks is stored at a git repo available in keybase. You'll need to be part of the opslife team in keybase to access. Start by cloning the repo:\n$ git clone keybase://team/opslife/egi-notebooks Kubernetes We use terraform and ansible to build the cluster at one of the EGI Cloud providers. If you are building the cluster for the first time, create a new directory on your local git repository from the template, add it to the repo, and get terraform ready:\n$ cp -a template \u0026lt;new provider\u0026gt; $ git add \u0026lt;new provider\u0026gt; $ cd \u0026lt;new provider\u0026gt;/terraform $ terraform init Using the egicli you can get the list of projects and their ids for a given site:\n$ egicli endpoint projects --site CESGA id Name enabled site -------------------------------- ------------------- --------- ------ 3a8e9d966e644405bf19b536adf7743d vo.access.egi.eu True CESGA 916506ac136741c28e4326975eef0bff vo.emso-eric.eu True CESGA b1d2ef2cc2284c57bcde21cf4ab141e3 vo.nextgeoss.eu True CESGA eb7ff20e603d471cb731bdb83a95a2b5 fedcloud.egi.eu True CESGA fcaf23d103c1485694e7494a59ee5f09 vo.notebooks.egi.eu True CESGA And with the project ID, you can obtain all the environment variables needed to interact with the OpenStack APIs of the site:\n$ eval \u0026quot;$(egicli endpoint env --site CESGA --project-id fcaf23d103c1485694e7494a59ee5f09)\u0026quot; Now you are ready to use the openstack or terraform at the site. The token obtained is valid for 1 hour, you can refresh it at any time with:\n$ eval \u0026quot;$(egicli endpoint token --site CESGA --project-id fcaf23d103c1485694e7494a59ee5f09)\u0026quot; First get the network IDs and pool to use for the site:\n$ openstack network list +--------------------------------------+-------------------------+--------------------------------------+ | ID | Name | Subnets | +--------------------------------------+-------------------------+--------------------------------------+ | 1aaf20b6-47a1-47ef-972e-7b36872f678f | net-vo.notebooks.egi.eu | 6465a327-c261-4391-a0f5-d503cc2d43d3 | | 6174db12-932f-4ee3-bb3e-7a0ca070d8f2 | public00 | 6af8c4f3-8e2e-405d-adea-c0b374c5bd99 | +--------------------------------------+-------------------------+--------------------------------------+ In this case we will use public00 as the pool for public IPs and 1aaf20b6-47a1-47ef-972e-7b36872f678f as the network ID. Check with the provider which is the right network to use. Use these values in the terraform.tfvars file:\nip_pool = \u0026quot;public00\u0026quot; net_id = \u0026quot;1aaf20b6-47a1-47ef-972e-7b36872f678f\u0026quot; You may want to check the right flavors for your VMs and adapt other variables in terraform.tfvars. To get a list of flavors you can use:\n$ openstack flavor list +--------------------------------------+----------------+-------+------+-----------+-------+-----------+ | ID | Name | RAM | Disk | Ephemeral | VCPUs | Is Public | +--------------------------------------+----------------+-------+------+-----------+-------+-----------+ | 26d14547-96f2-4751-a686-f89a9f7cd9cc | cor4mem8hd40 | 8192 | 40 | 0 | 4 | True | | 42eb9c81-e556-4b63-bc19-4c9fb735e344 | cor2mem2hd20 | 2048 | 20 | 0 | 2 | True | | 4787d9fc-3923-4fc9-b770-30966fc3baee | cor4mem4hd40 | 4096 | 40 | 0 | 4 | True | | 58586b06-7b9d-47af-b9d0-e16d49497d09 | cor24mem62hd60 | 63488 | 60 | 0 | 24 | True | | 635c739a-692f-4890-b8fd-d50963bff00e | cor1mem1hd10 | 1024 | 10 | 0 | 1 | True | | 6ba0080d-d71c-4aff-b6f9-b5a9484097f8 | small | 512 | 2 | 0 | 1 | True | | 6e514065-9013-4ce1-908a-0dcc173125e4 | cor2mem4hd20 | 4096 | 20 | 0 | 2 | True | | 85f66ce6-0b66-4889-a0bf-df8dc23ee540 | cor1mem2hd10 | 2048 | 10 | 0 | 1 | True | | c4aa496b-4684-4a86-bd7f-3a67c04b1fa6 | cor24mem50hd50 | 51200 | 50 | 0 | 24 | True | | edac68c3-50ea-42c2-ae1d-76b8beb306b5 | test-bigHD | 4096 | 237 | 0 | 2 | True | +--------------------------------------+----------------+-------+------+-----------+-------+-----------+ Finally ensure your public ssh key is also listed in the cloud-init.yaml file and then you are ready to deploy the cluster with:\n$ terraform apply Your VMs are up and running, it's time to get kubernetes configured and running with ansible.\nThe following ansible role needs to be installed first:\n$ ansible-galaxy install grycap.kubernetes and then:\n$ cd .. # you should be now in \u0026lt;new provider\u0026gt; $ ANSIBLE_TRANSFORM_INVALID_GROUP_CHARS=silently TF_STATE=./terraform \\ ansible-playbook --inventory-file=$(which terraform-inventory) \\ playbooks/k8s.yaml Interacting with the cluster As the master will be on a private IP, you won't be able to directly interact with it, but you can still ssh into the VM using the ingress node as a gateway host (you can get the different hosts with TF_STATE=./terraform terraform-inventory --inventory)\n$ ssh -o ProxyCommand=\u0026quot;ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -W %h:%p -q egi@\u0026lt;ingress ip\u0026gt;\u0026quot; \\ -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null egi@\u0026lt;master ip\u0026gt; egi@k8s-master:~$ kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-master Ready master 33m v1.15.7 k8s-nfs Ready \u0026lt;none\u0026gt; 16m v1.15.7 k8s-w-ingress Ready \u0026lt;none\u0026gt; 16m v1.15.7 egi@k8s-master:~$ helm list NAME REVISION UPDATED STATUS CHART APP VERSION NAMESPACE certs-man 2 Wed Jan 8 15:56:58 2020 DEPLOYED cert-manager-v0.11.0 v0.11.0 cert-manager cluster-ingress 3 Wed Jan 8 15:56:53 2020 DEPLOYED nginx-ingress-1.7.0 0.24.1 kube-system nfs-provisioner 3 Wed Jan 8 15:56:43 2020 DEPLOYED nfs-client-provisioner-1.2.8 3.1.0 kube-system Modifying/Destroying the cluster You should be able to change the number of workers in the cluster and re-apply terraform to start them and then execute the playbook to get them added to the cluster.\nAny changes in the master, NFS or ingress VMs should be done carfully as those will probably break the configuration of the kubernetes cluster and of any application running on top.\nDestroying the cluster can be done with a single command:\n$ terraform destroy Notebooks deployments Once the k8s cluster is up and running, you can deploy a notebooks instance. For each deployment you should create a file in the deployments directory following the template provided:\n$ cp deployments/hub.yaml.template deployments/hub.yaml Each deployment will need a domain name pointing to your ingress host, you can create one at the FedCloud dynamic DNS service.\nThen you will need to create an OpenID Connect client for EGI Check-in to authorise users into the new deployment. You can create a client by going to the Check-in demo OIDC clients management. Use the following as redirect URL: https://\u0026lt;your host domain name\u0026gt;/hub/oauth_callback.\nIn the Access tab, add offline_access to the list of scopes. Save the client and take note of the client ID and client secret for later.\nFinally you will also need 3 different random strings generated with openssl rand -hex 32 that will be used as secrets in the file describing the deployment.\nGo and edit the deployment description file to add this information (search for # FIXME NEEDS INPUT in the file to quickly get there)\nFor deploying the notebooks instance we will also use ansible:\n$ ANSIBLE_TRANSFORM_INVALID_GROUP_CHARS=silently TF_STATE=./terraform ansible-playbook \\ --inventory-file=$(which terraform-inventory) playbooks/notebooks.yaml The first deployment trial may fail due to a timeout caused by the downloading of the container images needed. You can retry after a while to re-deploy.\nIn the master you can check the status of your deployment (the name of the deployment will be the same as the name of your local deployment file):\n$ helm status hub LAST DEPLOYED: Thu Jan 9 08:14:49 2020 NAMESPACE: hub STATUS: DEPLOYED RESOURCES: ==\u0026gt; v1/ServiceAccount NAME SECRETS AGE hub 1 6m46s user-scheduler 1 3m34s ==\u0026gt; v1/Service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE hub ClusterIP 10.100.77.129 \u0026lt;none\u0026gt; 8081/TCP 6m46s proxy-public NodePort 10.107.127.44 \u0026lt;none\u0026gt; 443:32083/TCP,80:30581/TCP 6m45s proxy-api ClusterIP 10.103.195.6 \u0026lt;none\u0026gt; 8001/TCP 6m45s ==\u0026gt; v1/ConfigMap NAME DATA AGE hub-config 4 6m47s user-scheduler 1 3m35s ==\u0026gt; v1/PersistentVolumeClaim NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE hub-db-dir Pending managed-nfs-storage 6m46s ==\u0026gt; v1/ClusterRole NAME AGE hub-user-scheduler-complementary 3m34s ==\u0026gt; v1/ClusterRoleBinding NAME AGE hub-user-scheduler-base 3m34s hub-user-scheduler-complementary 3m34s ==\u0026gt; v1/RoleBinding NAME AGE hub 6m46s ==\u0026gt; v1/Pod(related) NAME READY STATUS RESTARTS AGE continuous-image-puller-flf5t 1/1 Running 0 3m34s continuous-image-puller-scr49 1/1 Running 0 3m34s hub-569596fc54-vjbms 0/1 Pending 0 3m30s proxy-79fb6d57c5-nj8n2 1/1 Running 0 2m22s user-scheduler-9685d654b-9zt5d 1/1 Running 0 3m30s user-scheduler-9685d654b-k8v9p 1/1 Running 0 3m30s ==\u0026gt; v1/Secret NAME TYPE DATA AGE hub-secret Opaque 3 6m47s ==\u0026gt; v1/DaemonSet NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE continuous-image-puller 2 2 2 2 2 \u0026lt;none\u0026gt; 3m34s ==\u0026gt; v1/Deployment NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE hub 1 1 1 0 6m45s proxy 1 1 1 1 6m45s user-scheduler 2 2 2 2 3m32s ==\u0026gt; v1/StatefulSet NAME DESIRED CURRENT AGE user-placeholder 0 0 6m44s ==\u0026gt; v1beta1/Ingress NAME HOSTS ADDRESS PORTS AGE jupyterhub notebooktest.fedcloud-tf.fedcloud.eu 80, 443 6m44s ==\u0026gt; v1beta1/PodDisruptionBudget NAME MIN AVAILABLE MAX UNAVAILABLE ALLOWED DISRUPTIONS AGE hub 1 N/A 0 6m48s proxy 1 N/A 0 6m48s user-placeholder 0 N/A 0 6m48s user-scheduler 1 N/A 1 6m47s ==\u0026gt; v1/Role NAME AGE hub 6m46s NOTES: Thank you for installing JupyterHub! Your release is named hub and installed into the namespace hub. You can find if the hub and proxy is ready by doing: kubectl --namespace=hub get pod and watching for both those pods to be in status 'Running'. You can find the public IP of the JupyterHub by doing: kubectl --namespace=hub get svc proxy-public It might take a few minutes for it to appear! Note that this is still an alpha release! If you have questions, feel free to 1. Read the guide at https://z2jh.jupyter.org 2. Chat with us at https://gitter.im/jupyterhub/jupyterhub 3. File issues at https://github.com/jupyterhub/zero-to-jupyterhub-k8s/issues Updating a deployment Just edit the deployment description file and run ansible again. The helm will be upgraded at the cluster.\n","excerpt":"In this section you can find the common operational activities related to keep the service available …","ref":"/providers/notebooks/operations/","title":"Service Operations"},{"body":"This section contains documentation aiming at Service Providers. See the users section for User-centric documentation.\n","excerpt":"This section contains documentation aiming at Service Providers. See the users section for …","ref":"/providers/","title":"Service Providers"},{"body":"This page contains information about connecting services to Check-in in order to allow user login through Check-in and to receive users\u0026rsquo; attributes.\nServices eligible for integration EGI Operations, as owner of the Check-in service, must approve every request for integration of new services with the AAI proxy. The approval (or non-approval) will be based on some pre-requisites, the relevance of the service for the EGI community and the available resources to support the integration. The pre-requisites are described in the following sections.\nEGI at any time can prevent a service provider to access the Check-in service\nServices federated in EGI All the services that are operated by Resource Providers federated in EGI federation and that abide to the RC OLA, and consequently to the relevant security policies of EGI, can be SP for the EGI Check-in service. Fulfilling all the relevant EGI policies makes the service eligible in receiving attributes released by the Check-in proxy.\nServices not federated in EGI A service not part of the EGI federation can be integrated as a SP in the Check-in AAI Proxy if the organisation providing the service complies with the EGI security requirements relevant to the service providers.\nTo assert compliance, the organisation needs to fill in the registration form for SPs. A PDF scan of a printed and signed copy should be sent to operations_at_egi.eu.\nBy accepting the policies a service provider assures that they will operate the service in good faith, without deliberately exposing the user to security risks, without claiming intellectual property on the data owned by the user, and protecting sensitive data generated by the interaction of the user with the service.\nThe policies that the service provider will have to accept are available in this page EGI Policies and procedures page and specifically are:\n e-Infrastructure Security Policy Service Operations Security Policy Traceability and Logging Policy Security Incident Response Policy Policy on the Processing of Personal Data  Service Provider integration workflow To integrate your Service Provider with the EGI Check-in service, you need to open a GGUS ticket indicating your request. The responsible support unit is Check-in (AAI) Support. The integration follows a two-step process:\n Register your Service Provider and test integration with the demo instance of EGI Check-in. The demo instance allows for testing authentication and authorisation without affecting the production Check-in service. Note that while the demo instance has identical functionality to the production instance, no information is shared between the two systems.  You can also test new features of Check-in that are not available in production yet, by registering your Service Provider and testing integration with the development instance of Check-in. As with the demo instance, the development instance allows for testing authentication and authorisation without affecting the production Check-in service. NB: the list of supported Identity Providers in the development instance is limited. Therefore, we recommend using the EGI SSO or any of the social identity providers to test the login workflow when using the development instance.   Register your Service Provider with the production instance of EGI Check-in to allow members of the EGI User Community to access your service. This requires that your service meets all the eligibility criteria and that integration has been thoroughly tested during Step 1.  The most important URLs for each environment are listed in the table below but more information can be found in the protocol-specific sections that follow.\n   Protocol Development environment Demo environment Production environment     SAML https://aai-dev.egi.eu/proxy/saml2/idp/metadata.php https://aai-demo.egi.eu/proxy/saml2/idp/metadata.php https://aai.egi.eu/proxy/saml2/idp/metadata.php   OpenID Connect https://aai-dev.egi.eu/oidc/.well-known/openid-configuration https://aai-demo.egi.eu/oidc/.well-known/openid-configuration https://aai.egi.eu/oidc/.well-known/openid-configuration    SAML Service Provider To enable federated access to a web-based application, you can connect to the EGI Check-in IdP as a SAML Service Provider (SP). Users of the application will be redirected to Check-in in order to log in, and Check-in can authenticate them using any of the supported backend authentication mechanisms, such as institutional IdPs registered with eduGAIN or Social Providers. Once the user is authenticated, EGI Check-in will return a SAML assertion to the application containing information about the authenticated user.\nMetadata registration SAML authentication relies on the use of metadata. Both parties (you as a SP and the EGI Check-in IdP) need to exchange metadata in order to know and trust each other. The metadata include information such as the location of the service endpoints that need to be invoked, as well as the certificates that will be used to sign SAML messages. The format of the exchanged metadata should be based on the XML-based SAML 2.0 specification. Usually, you will not need to manually create such an XML document, as this is automatically generated by all major SAML 2.0 SP software solutions (e.g., Shibboleth, SimpleSAMLphp, and mod_auth_mellon). It is important that you serve your metadata over HTTPS using a browser-friendly SSL certificate, i.e. issued by a trusted certificate authority.\nYou can get the metadata of the EGI Check-in IdP Proxy on a dedicated URL that depends on the integration environment being used:\n   Development environment Demo environment Production environment     https://aai-dev.egi.eu/proxy/saml2/idp/metadata.php https://aai-demo.egi.eu/proxy/saml2/idp/metadata.php https://aai.egi.eu/proxy/saml2/idp/metadata.php    Metadata Metadata provided by your SP should contain a descriptive name of the service that your SP represents in at least English. It is recommended to also provide the name in other languages which are commonly used in the geographic scope of the deployment. The name should be placed in the \u0026lt;md:ServiceName\u0026gt; in the \u0026lt;md:AttributeConsumingService\u0026gt; container.\nIt is recommended that the \u0026lt;md:IDPSSODescriptor\u0026gt; element included in your SP metadata contains both an AuthnRequestsSigned and an WantAssertionsSigned attribute set to true.\nYour SP metadata should also contain contact information for support and for a technical contact. The \u0026lt;md:EntityDescriptor\u0026gt; element should contain both a \u0026lt;md:ContactPerson\u0026gt; element with a contactType of \u0026quot;support\u0026quot; and a \u0026lt;md:ContactPerson\u0026gt; element with a contactType of \u0026quot;technical\u0026quot;. The \u0026lt;md:ContactPerson\u0026gt; elements should contain at least one \u0026lt;md:EmailAddress\u0026gt;. The support address may be used for generic support questions about the service, while the technical contact may be contacted regarding technical interoperability problems. The technical contact must be responsible for the technical operation of the service represented by your SP.\nAttributes The EGI Check-in IdP is guaranteed to release a minimal subset of the REFEDS R\u0026amp;S attribute bundle to connected Service Providers without administrative involvement, subject to user consent. The following attributes constitute a minimal subset of the R\u0026amp;S attribute bundle:\n Persistent, non-reassignable, non-targeted, opaque, globally unique EGI user ID (eduPersonUniqueId); this is always scoped @egi.eu Email address (mail) Display name (displayName) OR (givenName AND sn)  A more extensive list of all the attributes that may be made available to Service Providers is included in the User Attribute section.\nAttribute-based authorisation EGI Check-in provides information about the authenticated user that may be used by Service Providers in order to control user access to resources. This information is provided by the EGI Check-in IdP in the SAML attribute assertion. The table below lists the SAML attributes that are relevant for user authorisation:\n   Description SAML Attribute     VO/group membership/roles of the authenticated user eduPersonEntitlement   Level of Assurance (LoA) eduPersonAssurance    References  Shibboleth SP Configuration SimpleSAMLphp Service Provider QuickStart Simple SAML 2.0 service provider with mod_auth_mellon Apache module  OpenID Connect Service Provider Service Providers can be integrated with EGI Check-in using OpenID Connect (OIDC) as an alternative to the SAML2 protocol. To allow this, the EGI Check-in IdP provides an OpenID Connect (OAuth2) API based on MITREid Connect, which has been certified by the OpenID Foundation. Interconnection with the EGI Check-in OIDC Provider allows users to sign in using any of the supported backend authentication mechanisms, such as institutional IdPs registered with eduGAIN or Social Providers. Once the user has signed in, EGI Check-in can return OIDC Claims containing information about the authenticated user.\nClient registration Before your service can use the EGI Check-in OIDC Provider for user login, you must set up a client at https://aai-dev.egi.eu/oidc/manage/#admin/clients in order to obtain OAuth 2.0 credentials and register one or more redirect URIs.\nObtaining OAuth 2.0 credentials You need OAuth 2.0 credentials, including a client ID and client secret, to authenticate users through the EGI Check-in OIDC Provider.\nYou can specify the client ID and secret when creating/editing your client or let the New Client page generate the values for you (recommended).\nTo find the ID and secret of your client, do the following:\n Select your client from the Clients page. Look for the Client ID in the Main tab. Select the Display/edit client secret: option from the Credentials tab.  Setting one or more Redirection URIs The Redirection URI(s) that you set when creating/editing your client determine where the EGI Check-in OIDC Provider sends responses to your authentication requests. Note that the Redirection URI MUST use the https scheme; the use of http Redirection URIs is only allowed in the development environment.\nTo find the Redirection URI(s) for your client, do the following:\n Open the Clients page Find the redirect URIs for your client listed under the Information column of the overview table or Edit the particular client and look for the Redirect URI(s) in the Main tab.  Setting additional information about the client It is strongly suggested that you add a short description and a logo for the client. Lastly, you need to set the email addresses of one or more contacts.\nClaims The EGI Check-in UserInfo Endpoint is an OAuth 2.0 Protected Resource that returns specific information about the authenticated End-User as Claim Values. To obtain the requested Claims about the End-User, the Client makes a request to the UserInfo Endpoint using an Access Token obtained through OpenID Connect Authentication. The scopes associated with the Access Token used to access the EGI Check-in UserInfo Endpoint will determine what Claims will be released. These Claims are represented by a JSON object that contains a collection of name and value pairs for the Claims.\nThe following scope values can be used to request Claims from the EGI Check-in UserInfo Endpoint:\n   Scope Claims     openid sub   profile namegiven_namefamily_namepreferred_username   email emailemail_verifiedvoperson_verified_email   refeds_edu acreduperson_assuranceeduperson_scoped_affiliationeduperson_entitlement   eduperson_scoped_affiliation eduperson_scoped_affiliation   eduperson_entitlement eduperson_entitlement    A more extensive list of all the attributes that may be made available to Service Providers is included in the User Attribute section.\nGrant Types Check-in supports the following OpenID Connect/OAuth2 grant types:\n Authorization Code: used by Web Apps executing on a server. Implicit: used by JavaScript-centric apps (Single Page Applications) executing on the user's browser. Token Exchange: used by clients to request and obtain security tokens in support of delegated access to resources. Device Code: used by devices that lack a browser to perform a user-agent based OAuth flow.  Endpoints The most important OIDC/OAuth2 endpoints are listed below:\n   Endpoint Development environment Demo environment Production environment     Provider configuration https://aai-dev.egi.eu/oidc/.well-known/openid-configuration https://aai-demo.egi.eu/oidc/.well-known/openid-configuration https://aai.egi.eu/oidc/.well-known/openid-configuration   Client registration https://aai-dev.egi.eu/oidc Contact EGI Check-in support for registering your client Contact EGI Check-in support for registering your client   Authorisation https://aai-dev.egi.eu/oidc/authorize https://aai-demo.egi.eu/oidc/authorize https://aai.egi.eu/oidc/authorize   Token https://aai-dev.egi.eu/oidc/token https://aai-demo.egi.eu/oidc/token https://aai.egi.eu/oidc/token   JSON Web Key(jwt) https://aai-dev.egi.eu/oidc/jwk https://aai-demo.egi.eu/oidc/jwk https://aai.egi.eu/oidc/jwk   User Info https://aai-dev.egi.eu/oidc/userinfo https://aai-demo.egi.eu/oidc/userinfo https://aai.egi.eu/oidc/userinfo   Introspection https://aai-dev.egi.eu/oidc/introspect https://aai-demo.egi.eu/oidc/introspect https://aai.egi.eu/oidc/introspect    Authorization Endpoint The Authorization Endpoint performs Authentication of the End-User. This is done by sending the User Agent to the Authorization Server's Authorization Endpoint for Authentication and Authorization, using request parameters defined by OAuth 2.0 and additional parameters and parameter values defined by OpenID Connect.\nThe request parameters of the Authorization endpoint are:\n client_id: id of the client that ask for authentication to the Authorization Server. redirect_uri: URI to which the response will be sent. scope: A list of attributes that the application requires. state: Opaque value used to maintain state between the request and the callback. response_type: value that determines the authorization processing flow to be used.   For Authorization Code grant set response_type=code. This way the response will include an authorization code. For Implicit grant set response_type=token. This way the response will include both an Access Token and an ID Token.  Token Endpoint To obtain an Access Token, an ID Token, and optionally a Refresh Token, the Client sends a Token Request to the Token Endpoint.\nDepending on the grant type, the following parameters are required:\nAuthorization Code    Parameter Presence Values     grant_type Required authorization_code   code Required The value of the code in the response from authorization endpoint.   redirect_uri Required URI to which the response will be sent (must be the same as the request to authorization endpoint)    Refresh request The following request allows obtaining an access token from a refresh token using the grant_type value refresh_token:\n   Parameter Presence Values     client_id Required The identifier of the client.   client_secret Required The secret value of the client.   grant_type Required refresh_token   refresh_token Required The value of the refresh token   scope Required This parameter should contain openid at least    Example request curl -X POST -u \u0026#34;${client_id}\u0026#34;:\u0026#34;${client_secret}\u0026#34; \\  -d \u0026#34;client_id={myClientID}\u0026#34; \\  -d \u0026#34;client_secret={myClientSecret}\u0026#34; \\  -d \u0026#34;grant_type=refresh_token\u0026#34; \\  -d \u0026#34;refresh_token=${myRefreshToken}\u0026#34; \\  -d \u0026#34;scope=openid%20email%20profile\u0026#34; \\  \u0026#34;https://aai-dev.egi.eu/oidc/token\u0026#34; | python -m json.tool; Example response { \u0026#34;access_token\u0026#34;: \u0026#34;eyJraWQiOiJvaWRjIiwiYWx...\u0026#34;, \u0026#34;expires_in\u0026#34;: 3599, \u0026#34;id_token\u0026#34;: \u0026#34;eyJraWQiOiJvaWRjIiwiYW...\u0026#34;, \u0026#34;refresh_token\u0026#34;: \u0026#34;eyJhbGciOiJub25...\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;openid profile email\u0026#34;, \u0026#34;token_type\u0026#34;: \u0026#34;Bearer\u0026#34; } Token Exchange To get a token from client B using a token issued for client A, the parameters of the request are:\n   Parameter Presence Values     grant_type Required urn:ietf:params:oauth:grant-type:token-exchange   audience Optional Define the logical name of the service that the token will be used for   subject_token Required The value of the access token   subject_token_type Required urn:ietf:params:oauth:token-type:access_token (because this feature accepts access tokens only)   scope Optional Define one or more scopes that are contained in the original token; otherwise all scopes will be selected    Example request curl -X POST -u \u0026#34;${client_B_id}\u0026#34;:\u0026#34;${client_B_secret}\u0026#34; \\  -d \u0026#34;grant_type=urn:ietf:params:oauth:grant-type:token-exchange\u0026#34; \\  -d \u0026#34;audience=tokenExchange\u0026#34; \\  -d \u0026#34;subject_token=${access_token_A}\u0026#34; \\  -d \u0026#34;subject_token_type=urn:ietf:params:oauth:token-type:access_token\u0026#34; \\  -d \u0026#34;scope=openid%20profile%20offline_access\u0026#34; \\  \u0026#34;http://aai.egi.eu/oidc/token\u0026#34; | python -m json.tool; Example response { \u0026#34;access_token\u0026#34;: \u0026#34;eyJraWQiOiJvaWRjIiwiYWxnIjoiUl...\u0026#34;, \u0026#34;expires_in\u0026#34;: 3599, \u0026#34;id_token\u0026#34;: \u0026#34;eyJraWQiOiJvaWRjIiwiYWxnIjoiUl...\u0026#34;, \u0026#34;refresh_token\u0026#34;: \u0026#34;eyJhbGciOiJub25lIn0.eyJleHAiO...\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;openid profile offline_access\u0026#34;, \u0026#34;token_type\u0026#34;: \u0026#34;Bearer\u0026#34; } Device Code The device code flow enables OAuth clients on (input-constrained) devices to obtain user authorization for accessing protected resources without using an on-device user-agent, provided that they have an Internet connection.\n  Device Authorization Request\nThe client initiates the authorization flow by requesting a set of verification codes from the authorization server by making an HTTP \u0026ldquo;POST\u0026rdquo; request to the device authorization endpoint. The client constructs the request with the following parameters:\n     Parameter Presence Values     client_id Required The identifier of the client   scope Optional Define one or more scopes that are contained in the original token; otherwise all scopes will be selected    Example request curl -X POST \u0026#34;https://aai-dev.egi.eu/oidc/devicecode\u0026#34; \\  -H \u0026#34;Content-Type: application/x-www-form-urlencoded\u0026#34; \\  -d \u0026#34;client_id={myClientID}\u0026#34; \\  -d \u0026#34;\u0026amp;scope=openid%20email%20profile\u0026#34; | python -m json.tool Example response { \u0026#34;device_code\u0026#34;: \u0026#34;c4341bd6-5e82-4f9c-9f6f-5842409d48db\u0026#34;, \u0026#34;expires_in\u0026#34;: 600, \u0026#34;user_code\u0026#34;: \u0026#34;IEJSJB\u0026#34;, \u0026#34;verification_uri\u0026#34;: \u0026#34;https://aai-dev.egi.eu/oidc/device)\u0026#34; }   User Interaction\nAfter receiving a successful Authorization Response, the client displays or otherwise communicates the user_code and the verification_uri to the end user and instructs them to visit the URI in a user agent on a secondary device (for example, in a browser on their mobile phone), and enter the user code.\n  Device Access Token Request\nAfter displaying instructions to the user, the client makes an Access Token Request to the token endpoint. The request contains the following parameters:\n     Parameter Presence Values     grant_type Required urn:ietf:params:oauth:grant-type:device_code   device_code Required The device verification code, device_code from the Device Authorization Response   client_id Required The identifier of the client    client_secret Required The secret value of the client   scope Optional Define one or more scopes that are contained in the original token; otherwise all scopes will be selected    Example request curl -X POST \u0026#34;https://aai-dev.egi.eu/oidc/token\u0026#34; \\  -H \u0026#34;Content-Type: application/x-www-form-urlencoded\u0026#34; \\  -d \u0026#34;grant_type=urn%3Aietf%3Aparams%3Aoauth%3Agrant-type%3Adevice_code\u0026#34; \\  -d \u0026#34;\u0026amp;device_code={myDeviceCode}\u0026#34; \\  -d \u0026#34;\u0026amp;client_id={myClientID}\u0026#34; \\  -d \u0026#34;\u0026amp;client_secret={myClientSecret}\u0026#34; \\  -d \u0026#34;\u0026amp;scope=openid%20profile\u0026#34; | python -m json.tool Example response { \u0026#34;access_token\u0026#34;: \u0026#34;eyJraWQiOiJyc2ExIiwiYWxnIjoiUlMyNTYifQ.eyJzdWIiOiJhZG1pbiIs...\u0026#34;, \u0026#34;expires_in\u0026#34;: 3599, \u0026#34;id_token\u0026#34;: \u0026#34;eyJraWQiOiJyc2ExIiwiYWxnIjoiUlMyNTYifQ.eyJzdWIiOiI5MDM0Mi...\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;openid profile\u0026#34;, \u0026#34;token_type\u0026#34;: \u0026#34;Bearer\u0026#34; } Claims-based authorisation EGI Check-in provides information about the authenticated user that may be used by Service Providers in order to control user access to resources. This information is provided by the EGI Check-in OIDC Provider in the form of OIDC claims. The table below lists the claims that are relevant for user authorisation:\n   Description OIDC Claim     VO/group membership/roles of the authenticated user edu_person_entitlements   Level of Assurance (LoA) acr    Example OIDC Client In this guide we will demonstrate how to install and configure a simple OIDC client.\nInstall simple-oidc-client This guide assumes the Apache HTTP server has been installed and the document root is /var/www/html\nMove to the apache document root and download and extract simple-oidc-client.zip.\nConfigure Client Go to this link and login https://aai-dev.egi.eu/oidc/\nThen create a new client or edit your existing client. In main tab enter a Client name and in the Redirect URI(s) insert your simple-oidc-client URL (e.g. https://example.com/simple-oidc-client/popup.html). This URL must link to popup.html which is located in simple-oidc-client directory.\nNext, move to access tab and pick the scopes your service needs. Then, in Grant types check authorization code and implicit. In Response Types check code and token id_token.\nThen, click save and copy your Client ID.\nConfigure simple-oidc-client Now that we have everything we need, we can configure our login settings. Go to your terminal and open configuration.js with your favorite text editor. ex.\nvi simple-oidc-client/configuration.js Let\u0026rsquo;s go quickly through the settings:\n title is the title on the navigation bar. authority is the base URL of our IdentityServer instance. This will allow oidc-client to query the metadata endpoint so it can validate the tokens. client_id is the id of the client we want to use when hitting the authorization endpoint. popup_redirect_uri is the redirect URL used when using the signinPopup method. If you prefer not having a popup and redirecting the user in the main window, you can use the redirect_uri property and the signinRedirect method. post_logout_redirect_uri is the redirect URL used when using the signoutRedirect method. response_type defines in our case that we only expect an identity token back. scope defines the scopes the application asks for. debug displays user data. filterProtocolClaims indicates to oidc-client if it has to filter some OIDC protocol claims from the response: nonce, at_hash, iat, nbf, exp, aud, iss and idp.  You must change the followings options based on your client configuration:\n authority (issuer) client_id scope  An example configuration follows:\nvar settings = { title: \u0026#34;Simple OIDC Client\u0026#34;, authority: \u0026#34;https://aai-dev.egi.eu/oidc\u0026#34;, client_id: \u0026#34;client\u0026#34;, popup_redirect_uri: \u0026#34;https://example.com/simple-oidc-client/popup.html\u0026#34;, post_logout_redirect_uri: \u0026#34;https://example.com/simple-oidc-client/index.html\u0026#34;, response_type: \u0026#34;token id_token\u0026#34;, scope: \u0026#34;openid profile email\u0026#34; /* add offline_access to obtain a refresh token*/, debug: false, filterProtocolClaims: false, }; Integrating Science Gateways with RCauth for obtaining (proxy) certificates In order for Science Gateways (VO portals) to obtain RFC proxy certificates derived from personal end-entity certificates, an EGI Science Gateway can make use of the IGTF-approved IOTA-type RCauth.eu online CA. The actual integration goes via an intermediary service, called a Master Portal. EGI is running two Master Portal instances, one development, one production instance.\n   Endpoint Development environment Production environment     Provider configuration https://masterportal-pilot.aai.egi.eu/mp-oa2-server/.well-known/openid-configuration https://aai.egi.eu/mp-oa2-server/.well-known/openid-configuration   Client registration https://masterportal-pilot.aai.egi.eu/mp-oa2-server/register https://aai.egi.eu/mp-oa2-server/register   Authorisation https://masterportal-pilot.aai.egi.eu/mp-oa2-server/authorize https://aai.egi.eu/mp-oa2-server/authorize   Token https://masterportal-pilot.aai.egi.eu/mp-oa2-server/token https://aai.egi.eu/mp-oa2-server/token   JSON Web Key(jwt) https://masterportal-pilot.aai.egi.eu/mp-oa2-server/certs https://aai.egi.eu/mp-oa2-server/certs   User Info https://masterportal-pilot.aai.egi.eu/mp-oa2-server/userinfo https://aai-demo.egi.eu/oidc/userinfo    Registering a client at the Master Portal In order to register a new client for your VO portal go to:\n EGI Development instance: https://masterportal-pilot.aai.egi.eu/mp-oa2-server/register EGI Production instance: https://aai.egi.eu/mp-oa2-server/register  Note Make sure to store the client_id and client_secret in a secure place  In order to get the client approved, send an email to the adminstrator of the EGI Master Portal using EGI Check-in support.\nDetailed information For further and detailed instructions on the integration flow, see the generic RCAuth.eu MasterPortal VOPortal integration guide\nSSH key authentication for proxy retrieval The EGI MasterPortal also allows users to authenticate using SSH key pair, in order to retrieve proxy certificates from the MasterPortal. Users need to first upload the public key via a self-service portal, https://aai.egi.eu/sshkeys/. About once a week they need to follow a web-flow to ensure a long-lived proxy certificate is present in MasterPortal, e.g. by going to https://aai.egi.eu/vo-portal/. They can then obtain a proxy certificate by doing\nssh proxy@ssh.aai.egi.eu and storing the output in /tmp/x509up_u$(id -u)\nGeneric information for users on how to do this can be found at Instructions for end-users on how to use the SSH key authN for proxy retrieval. Alternatively VO portals could implement such functionality themselves by using the API described at the Master Portal sshkey endpoint description.\nUser attributes This section defines the attributes that can be made available to services connected to Check-in.\n1. EGI ID    attribute name EGI ID     description An identifier for the user, unique among all EGI accounts and never reused   SAML Attribute(s) 1.3.6.1.4.1.5923.1.1.1.13 (eduPersonUniqueId)   OIDC scope openid   OIDC claim(s) sub   OIDC claim location ID tokenUserinfo endpointIntrospection endpoint   origin Check-in assigns this attribute on user registration   changes No   multiplicity No   availability Always   example ef72285491ffe53c39b75bdcef46689f5d26ddfa00312365cc4fb5ce97e9ca87@egi.eu   notes Use EGI ID within your application as the unique-identifier key for the user   status Stable    2. Display Name    attribute name Display Name     description The user\u0026rsquo;s full name, in a displayable form   SAML Attribute(s) urn:oid:2.16.840.1.113730.3.1.241 (displayName)   OIDC scope profile   OIDC claim(s) name   OIDC claim location Userinfo endpoint   origin Provided by user\u0026rsquo;s Identity Provider   changes Yes   multiplicity Single-valued   availability Always   example John Doe   notes -   status Stable    3. Given Name    attribute name Given Name     description The user\u0026rsquo;s first name   SAML Attribute(s) urn:oid:2.5.4.42 (givenName)   OIDC scope profile   OIDC claim(s) given_name   OIDC claim location Userinfo endpoint   origin Provided by user\u0026rsquo;s Identity Provider   changes Yes   multiplicity Single-valued   availability Always   example John   notes -   status Stable    4. Family Name    attribute name Family Name     description The user\u0026rsquo;s last name   SAML Attribute(s) urn:oid:2.5.4.4 (sn)   OIDC scope profile   OIDC claim(s) family_name   OIDC claim location Userinfo endpoint   origin Provided by user\u0026rsquo;s Identity Provider   changes Yes   multiplicity Single-valued   availability Always   example Doe   notes -   status Stable    5. Username    attribute name Username     description The username by which the user wishes to be referred to   SAML Attribute(s) urn:oid:0.9.2342.19200300.100.1.1 (uid)   OIDC scope profile   OIDC claim(s) preferred_username   OIDC claim location ID tokenUserinfo endpointIntrospection endpoint   origin Check-in assigns this attribute on user registration   changes No   multiplicity Single-valued   availability Always   example jdoe   notes The Service Provider MUST NOT rely upon this value being unique   status Stable    6. Email Address    attribute name Email Address     description The user\u0026rsquo;s email address   SAML Attribute(s) urn:oid:0.9.2342.19200300.100.1.3 (mail)   OIDC scope email   OIDC claim(s) email   OIDC claim location Userinfo endpointIntrospection endpoint   origin Provided by user\u0026rsquo;s Identity Provider   changes Yes   multiplicity Single-valued   availability Always   example john.doe@example.org   notes This MAY NOT be unique and is NOT suitable for use as a primary key   status Stable    7. Verified email flag    attribute name Verified email flag     description True if the user\u0026rsquo;s email address has been verified; otherwise false   SAML Attribute(s) See Verified email list   OIDC scope email   OIDC claim(s) email_verified   OIDC claim location Userinfo endpointIntrospection endpoint   origin Check-in assigns this attribute on user registration   changes Yes   multiplicity Single-valued   availability Always   example true   notes This claim is available only in OpenID Connect   status Experimental    8. Verified email list    attribute name Verified email list     description A list of user\u0026rsquo;s email addresses that have been verified   SAML Attribute(s) urn:oid:1.3.6.1.4.1.25178.4.1.14 (voPersonVerifiedEmail)   OIDC scope email   OIDC claim(s) voperson_verified_email   OIDC claim location Userinfo endpointIntrospection endpoint   origin Check-in or the user\u0026rsquo;s Identity Provider   changes Yes   multiplicity Multi-valued   availability Not always   example _john.doe@example.org__jdoe@example.com_   notes -   status Experimental    9. Affiliation    attribute name Affiliation     description The user\u0026rsquo;s affiliation within a particular security domain (scope)   SAML Attribute(s) urn:oid:1.3.6.1.4.1.5923.1.1.1.9 (eduPersonScopedAffiliation)   OIDC scope eduperson_scoped_affiliation   OIDC claim(s) eduperson_scoped_affiliation   OIDC claim location Userinfo endpointIntrospection endpoint   origin Check-in assigns this attribute on user registration   changes Yes   multiplicity Multi-valued   availability Always   example member@example.org   notes Service Providers are encouraged to validate the scope of this attribute   status Stable    10. Entitlements    attribute name Entitlements     description The user\u0026rsquo;s entitlements expressed as group/VO membership/role information   SAML Attribute(s) urn:oid:1.3.6.1.4.1.5923.1.1.1.7 (eduPersonEntitlement)   OIDC scope eduperson_entitlement   OIDC claim(s) eduperson_entitlement   OIDC claim location Userinfo endpointIntrospection endpoint   origin Group memberships are managed by group administrators   changes Yes   multiplicity Multi-valued   availability Not always   example urn:mace:egi.eu:group:vo.test.egi.eu:role=member#aai.egi.eu   notes -   status Stable    11. Assurance    attribute name Assurance     description Assurance of the identity of the user   SAML Attribute(s) urn:oid:1.3.6.1.4.1.5923.1.1.1.11 (eduPersonAssurance)   OIDC scope eduperson_assurance   OIDC claim(s) eduperson_assurance   OIDC claim location Userinfo endpointIntrospection endpoint   origin Check-in assigns this attribute on user registration   changes Yes   multiplicity Multi-valued   availability Not always   example [https://aai.egi.eu/LoA#Low]   notes -   status Stable    User authorisation The following information about the authenticated user can be provided by EGI Check-in in order to control user access to resources:\n VO/group membership and role information about the authenticated user Level of Assurance (LoA)  VO/group membership and role information Background VO/group membership and role information is encoded in entitlements (eduPersonEntitlement attribute values in SAML or edu_person_entitlements claim in OIDC). These entitlements are typically used to indicate access rights to protected resources. Entitlements are multi-valued, with each value formatted as a URN.\nSyntax An entitlement value expressing group membership and role information has the following syntax (components enclosed in square brackets are OPTIONAL):\nurn:mace:egi.eu:group:\u0026lt;GROUP\u0026gt;[:\u0026lt;SUBGROUP\u0026gt;*]][:role=\u0026lt;ROLE\u0026gt;]#\u0026lt;GROUP-AUTHORITY\u0026gt;where:\n \u0026lt;GROUP\u0026gt; is the name of a VO, research collaboration or a top level arbitrary group. \u0026lt;GROUP\u0026gt; names are unique within the urn:mace:egi.eu:group namespace; zero or more \u0026lt;SUBGROUP\u0026gt; components represent the hierarchy of subgroups in the \u0026lt;GROUP\u0026gt;; specifying sub-groups is optional the optional \u0026lt;ROLE\u0026gt; component is scoped to the rightmost (sub)group; if no group information is specified, the role applies to the VO \u0026lt;GROUP-AUTHORITY\u0026gt; is a non-empty string that indicates the authoritative source for the entitlement value. For example, it can be the FQDN of the group management system that is responsible for the identified group membership information  Example:\nurn:mace:egi.eu:group:fedcloud.egi.eu:role=vm_operator#aai.egi.euOld Syntax (will be deprecated in a next release) An entitlement value expressing group membership and role information has the following syntax (components enclosed in square brackets are OPTIONAL):\nurn:mace:egi.eu:\u0026lt;GROUP-AUTHORITY\u0026gt;:[\u0026lt;GROUP\u0026gt;[:\u0026lt;SUBGROUP\u0026gt;:…]]:\u0026lt;ROLE\u0026gt;@\u0026lt;VO\u0026gt;Example:\nurn:mace:egi.eu:aai.egi.eu:vm_operator@fedcloud.egi.euLevel of Assurance Based on the authentication method selected by the user, the EGI proxy assigns a Level of Assurance (LoA), which is conveyed to the SP through both the eduPersonAssurance attribute and the Authentication Context Class (AuthnContextClassRef) of the SAML authentication response. EGI AAI currently distinguishes between three LoA levels, similarly to the eID Assurance Framework (eIDAF). Each level is represented by a URI as follows:\n Low: Authentication through a social identity provider or other low identity assurance provider: https://aai.egi.eu/LoA#Low Substantial: Password/X.509 authentication at the user's home IdP: https://aai.egi.eu/LoA#Substantial High: Substantial + multi-factor authn (not yet supported, TBD): https://aai.egi.eu/LoA#High  Some EGI SPs have been configured to provide limited access (or not to accept at all) credentials with the Low LoA.\nNote: When logging in through the EGI SSO IdP, the LoA is determined based on the selected authentication mechanism as follows:\n Username/password credentials → Low X.509 certification → Substantial  ","excerpt":"This page contains information about connecting services to Check-in in order to allow user login …","ref":"/providers/check-in/sp/","title":"Service Providers"},{"body":"An overview of the use cases and possible deployment scenarios of the EGI DataHub.\nTransparent data access  Clients use one ore more providers to access data Data can be accessed over multiple protocols  Federation of service providers  Heterogeneous backend storage Common interfaces (Web, REST, POSIX, CDMI) Common AAI with Check-in Discovery of Datasets in the EGI DataHub  Smart caching  Site A hosts data and computing resources Site B hosts only data Site X uses data from A and B without pre-staging Pre-staging can also be done using APIs Data is accessed locally \u0026ldquo;à la\u0026rdquo; POSIX with FUSE  Publication of datasets  PID minting Publishing, discovery and access to datasets  Integrating DataHub and EGI Notebooks ","excerpt":"An overview of the use cases and possible deployment scenarios of the EGI DataHub.\nTransparent data …","ref":"/users/datahub/usecases/","title":"Use Cases"},{"body":"Overview The WebFTS interface offers end users a way to graphically execute and monitor file transfer between storages using different protocols. You can check CERN WebFTS documentation and FAQ for more details.\nCredential Delegation In order to move files between storage endpoints, named also Storage Elements (SE), the authentication is done using an X.509 certificate which needs to be installed on the browser. The Integration with EGI Check-in is under development and will be available at a later date in the production instance.\nA pop-up window appears when you choose the \u0026ldquo;My jobs\u0026rdquo; or \u0026ldquo;Submit a transfer\u0026rdquo; tabs. There, you will need to paste the private RSA key of your certificate. The private key WILL NOT BE TRANSMITTED ANYWHERE. It is only used locally (within the user\u0026rsquo;s browser) to generate the proxies needed to have access to the FTS services.\nTo obtain the private key, you can run in the console:\nopenssl pkcs12 -in yourCert.p12 -nocerts -nodes | openssl rsa This command requires openssl.\nIf you need a delegation with VOMS credentials (required to access some types of Storage Elements), you will need to introduce the name of the virtual organization (VO) you belong to.\nFrom the right button where the remaining time for the current delegation is shown, you can remove the current delegation and delegate again (the delegation window will appear).\nSubmit a transfer Open the \u0026ldquo;Submit a transfer\u0026rdquo; tab and Load origin and destination storage elements as endpoints. If one endpoint URL is not known, there is an autocompletion once 3 characters have been typed. You should also specify the protocol, the address of the endpoint and the path. (Ex: gsiftp://lxfsra10a01.cern.ch/dpm/cern.ch/home/).\nBrowse the content and select all the files you want to transfer. CTRL and SHIFT keys can be used for selecting multiple entries at once.\nIf you need to filter the list of files and folders, you can use the available filters: name, size and date. Once you have loaded both endpoints and selected the files, the transfer buttons will be enabled. Click the button with the correct direction. A success or error message will appear above the endpoints\u0026rsquo; containers.\nYou can now check the status of you transfer in the \u0026ldquo;My jobs\u0026rdquo; tab.\nListing your transfers Open the \u0026ldquo;My jobs\u0026rdquo; tab. If you have done any transfers recently, they will appear there. If you click on an individual transfer, you can see its state and any errors.\nYou can resubmit transfer jobs, but you would need to delegate your credentials if you did not do it before. You can do this at any state by clicking the \u0026ldquo;Resubmit\u0026rdquo; button.\nThe transfer states are: YELLOW if still running, GREEN if successfully completed and RED if something went wrong.\nThe transfers that are not completed have a \u0026ldquo;Cancel\u0026rdquo; button on the left of the \u0026ldquo;Resubmit\u0026rdquo; button. Clicking this button will cancel that transfer.\n","excerpt":"Overview The WebFTS interface offers end users a way to graphically execute and monitor file …","ref":"/users/data-transfer/webfts/","title":"WebFTS"},{"body":"Overview The EGI Data Transfer service offers API both for Users and Admins, in this section we are focusing on the User API. Two APIs are available to users:\n RESTFul API Python Easy Bindings  In both cases users need a way to be authenticated and authorised and this is explained in the next section.\nAuthentication \u0026amp; Authorisation Warning Users have to authenticate using a X.509 User certificate. The integration with EGI Check-in in order to authenticate via OIDC tokens\nis under development and will be later made available in production endpoints.  During the authentication phase, credentials are delegated to the FTS service, which will contact the storages to steer the data transfers on behalf of the users.\nThe FTS service supports both plain X.509 proxies than VOMS X.509 proxies extended with VO information for authentication and authorisation.\nLearn about VOMS configuration and proxy creation.\nRESTFul API The User RESTFul APIs can be used to submit transfers jobs (collections of single transfers), monitor and cancel existing transfers. Please check the CERN documentation for the full API details. Here we will provide some examples usage using the Curl client.\nChecking how the server sees the identity of the user curl --capath /etc/grid-security/certificates -E $X509_USER_PROXY \\  --cacert $X509_USER_PROXY https://fts3-public.cern.ch:8446/whoami { \u0026#34;dn\u0026#34;: [ \u0026#34;/DC=org/DC=terena/DC=tcs/C=NL/O=Stichting EGI/CN=Andrea Manzi\u0026#34;, \u0026#34;/DC=org/DC=terena/DC=tcs/C=NL/O=Stichting EGI/CN=Andrea Manzi/CN=proxy\u0026#34; ], \u0026#34;vos_id\u0026#34;: [ \u0026#34;6b10f4e4-8fdc-5555-baa2-7d4850d4f406\u0026#34; ], \u0026#34;roles\u0026#34;: [], \u0026#34;delegation_id\u0026#34;: \u0026#34;9ab8068853808c6b\u0026#34;, \u0026#34;user_dn\u0026#34;: \u0026#34;/DC=org/DC=terena/DC=tcs/C=NL/O=Stichting EGI/CN=Andrea Manzi\u0026#34;, \u0026#34;level\u0026#34;: { \u0026#34;transfer\u0026#34;: \u0026#34;vo\u0026#34; }, \u0026#34;is_root\u0026#34;: false, \u0026#34;base_id\u0026#34;: \u0026#34;01874efb-4735-4595-bc9c-591aef8240c9\u0026#34;, \u0026#34;vos\u0026#34;: [ \u0026#34;dteam\u0026#34; ], \u0026#34;voms_cred\u0026#34;: [ \u0026#34;/dteam/Role=NULL/Capability=NULL\u0026#34; ], \u0026#34;method\u0026#34;: \u0026#34;certificate\u0026#34; } Getting a list of jobs running Filtered by VO\ncurl --capath /etc/grid-security/certificates -E $X509_USER_PROXY \\  --cacert $X509_USER_PROXY https://fts3-public.cern.ch:8446/jobs?vo_name=dteam [ { \u0026#34;cred_id\u0026#34;: \u0026#34;1426115d1660de4d\u0026#34;, \u0026#34;user_dn\u0026#34;: \u0026#34;/DC=ch/DC=cern/OU=Organic Units/OU=Users/CN=ftssuite/CN=737188/CN=Robot: fts3 testsuite\u0026#34;, \u0026#34;job_type\u0026#34;: \u0026#34;N\u0026#34;, \u0026#34;retry\u0026#34;: -1, \u0026#34;job_id\u0026#34;: \u0026#34;94560e74-7ca3-11e9-97dd-02163e00d613\u0026#34;, \u0026#34;cancel_job\u0026#34;: false, \u0026#34;job_state\u0026#34;: \u0026#34;FINISHED\u0026#34;, \u0026#34;submit_host\u0026#34;: \u0026#34;fts604.cern.ch\u0026#34;, \u0026#34;priority\u0026#34;: 3, \u0026#34;source_space_token\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;max_time_in_queue\u0026#34;: null, \u0026#34;job_metadata\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;test_bring_online\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;fts3-tests\u0026#34; }, \u0026#34;source_se\u0026#34;: \u0026#34;mock://somewhere.uk\u0026#34;, \u0026#34;bring_online\u0026#34;: 120, \u0026#34;reason\u0026#34;: null, \u0026#34;space_token\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;submit_time\u0026#34;: \u0026#34;2019-05-22T15:09:22\u0026#34;, \u0026#34;retry_delay\u0026#34;: 0, \u0026#34;dest_se\u0026#34;: \u0026#34;mock://somewhere.uk\u0026#34;, \u0026#34;internal_job_params\u0026#34;: \u0026#34;nostreams:1\u0026#34;, \u0026#34;overwrite_flag\u0026#34;: false, \u0026#34;copy_pin_lifetime\u0026#34;: -1, \u0026#34;verify_checksum\u0026#34;: \u0026#34;n\u0026#34;, \u0026#34;job_finished\u0026#34;: null, \u0026#34;vo_name\u0026#34;: \u0026#34;dteam\u0026#34; } ] Cancelling a job curl --capath /etc/grid-security/certificates -E $X509_USER_PROXY \\  --cacert $X509_USER_PROXY \\  -X DELETE \\  https://fts3-pilot.cern.ch:8446/jobs/a40b82b7-1132-459f-a641-f8b49137a713 Getting expiration time of delegated credentials curl --capath /etc/grid-security/certificates -E $X509_USER_PROXY \\  --cacert $X509_USER_PROXY \\  https://fts3-public.cern.ch:8446/delegation/9ab8068853808c6b { \u0026#34;voms_attrs\u0026#34;: [ \u0026#34;/dteam/Role=NULL/Capability=NULL\u0026#34; ], \u0026#34;termination_time\u0026#34;: \u0026#34;2020-07-31T22:50:28\u0026#34; } Python Bindings The Python bindings for FTS can be installed from the EPEL package repository (EL6 and EL7 packages are available) with Python 2.7 being supported.\nyum install python-fts -y For using the bindings, you need to import fts3.rest.client.easy, although for convenience it can be renamed as something else:\nimport fts3.rest.client.easy as fts3 In the following code snippets, an import as above is assumed.\nIn order to be able to do any operation, information about the state of the user credentials and remote endpoint needs to be kept. That\u0026rsquo;s the purpose of a Context.\ncontext = fts3.Context(endpoint, ucert, ukey, verify=True) The endpoint to use corresponds to the FTS instance REST server and it must have the following format:\nhttps://\\\u0026lt;host\u0026gt;:\\\u0026lt;port\u0026gt;\nfor instance https://fts3-public.cern.ch:8446\nIf you are using a proxy certificate, you can either specify only user_certificate, or point both parameters to the proxy. user_certificate and user_key can be safely omitted, and the program will use the values defined in the environment variables X509_USER_PROXY or X509_USER_CERT + X509_USER_KEY.\nIf verify is False, the server certificate will not be verified.\nHere are some examples about creating a context, submitting a job with a single transfer and getting the job status:\n# pretty print the json outputs \u0026gt;\u0026gt;\u0026gt; import pprint \u0026gt;\u0026gt;\u0026gt; pp = pprint.PrettyPrinter(indent=4) # creating the context \u0026gt;\u0026gt;\u0026gt; context = fts3.Context(\u0026#34;https://fts3-public.cern.ch:8446\u0026#34;) # printing the whoami info \u0026gt;\u0026gt;\u0026gt; pp.pprint (fts3.whoami(context)) { u\u0026#39;base_id\u0026#39;: u\u0026#39;01874efb-4735-4595-bc9c-591aef8240c9\u0026#39;, u\u0026#39;delegation_id\u0026#39;: u\u0026#39;9ab8068853808c6b\u0026#39;, u\u0026#39;dn\u0026#39;: [ u\u0026#39;/DC=org/DC=terena/DC=tcs/C=NL/O=Stichting EGI/CN=Andrea Manzi\u0026#39;, u\u0026#39;/DC=org/DC=terena/DC=tcs/C=NL/O=Stichting EGI/CN=Andrea Manzi/CN=proxy\u0026#39;], u\u0026#39;is_root\u0026#39;: False, u\u0026#39;level\u0026#39;: { u\u0026#39;transfer\u0026#39;: u\u0026#39;vo\u0026#39;}, u\u0026#39;method\u0026#39;: u\u0026#39;certificate\u0026#39;, u\u0026#39;roles\u0026#39;: [], u\u0026#39;user_dn\u0026#39;: u\u0026#39;/DC=org/DC=terena/DC=tcs/C=NL/O=Stichting EGI/CN=Andrea Manzi\u0026#39;, u\u0026#39;voms_cred\u0026#39;: [u\u0026#39;/dteam/Role=NULL/Capability=NULL\u0026#39;], u\u0026#39;vos\u0026#39;: [u\u0026#39;dteam\u0026#39;], u\u0026#39;vos_id\u0026#39;: [u\u0026#39;6b10f4e4-8fdc-5555-baa2-7d4850d4f406\u0026#39;]} # creating a new transfer and submiting a job \u0026gt;\u0026gt;\u0026gt; transfer = fts3.new_transfer( ... \u0026#39;gsiftp://source/path\u0026#39;, \u0026#39;gsiftp://destination/path\u0026#39;, ... checksum=\u0026#39;ADLER32:1234\u0026#39;, filesize=1024, ... metadata=\u0026#39;Submission example\u0026#39; ... ) \u0026gt;\u0026gt;\u0026gt; job = fts3.new_job([transfer]) \u0026gt;\u0026gt;\u0026gt; job_id = fts3.submit(context, job) \u0026gt;\u0026gt;\u0026gt; print job_id b6191212-d347-11ea-8a47-fa163e45cbc4 # get the job status \u0026gt;\u0026gt;\u0026gt; pp.pprint(fts3.get_job_status(context, job_id)) { u\u0026#39;bring_online\u0026#39;: -1, u\u0026#39;cancel_job\u0026#39;: False, u\u0026#39;copy_pin_lifetime\u0026#39;: -1, u\u0026#39;cred_id\u0026#39;: u\u0026#39;9ab8068853808c6b\u0026#39;, u\u0026#39;dest_se\u0026#39;: u\u0026#39;gsiftp://destination\u0026#39;, u\u0026#39;http_status\u0026#39;: u\u0026#39;200 Ok\u0026#39;, u\u0026#39;internal_job_params\u0026#39;: u\u0026#39;nostreams:1\u0026#39;, u\u0026#39;job_finished\u0026#39;: u\u0026#39;2020-07-31T16:05:55\u0026#39;, u\u0026#39;job_id\u0026#39;: u\u0026#39;b6191212-d347-11ea-8a47-fa163e45cbc4\u0026#39;, u\u0026#39;job_metadata\u0026#39;: None, u\u0026#39;job_state\u0026#39;: u\u0026#39;FAILED\u0026#39;, u\u0026#39;job_type\u0026#39;: u\u0026#39;N\u0026#39;, u\u0026#39;max_time_in_queue\u0026#39;: None, u\u0026#39;overwrite_flag\u0026#39;: False, u\u0026#39;priority\u0026#39;: 3, u\u0026#39;reason\u0026#39;: u\u0026#39;One or more files failed. Please have a look at the details for more information\u0026#39;, u\u0026#39;retry\u0026#39;: -1, u\u0026#39;retry_delay\u0026#39;: 0, u\u0026#39;source_se\u0026#39;: u\u0026#39;gsiftp://source\u0026#39;, u\u0026#39;source_space_token\u0026#39;: u\u0026#39;\u0026#39;, u\u0026#39;space_token\u0026#39;: u\u0026#39;\u0026#39;, u\u0026#39;submit_host\u0026#39;: u\u0026#39;fts-public-03.cern.ch\u0026#39;, u\u0026#39;submit_time\u0026#39;: u\u0026#39;2020-07-31T16:05:54\u0026#39;, u\u0026#39;user_dn\u0026#39;: u\u0026#39;/DC=org/DC=terena/DC=tcs/C=NL/O=Stichting EGI/CN=Andrea Manzi\u0026#39;, u\u0026#39;verify_checksum\u0026#39;: u\u0026#39;t\u0026#39;, u\u0026#39;vo_name\u0026#39;: u\u0026#39;dteam\u0026#39;} Full documentation is also available.\n","excerpt":"Overview The EGI Data Transfer service offers API both for Users and Admins, in this section we are …","ref":"/users/data-transfer/api/","title":"API"},{"body":"Most if not all operations can be performed using the Onedata API.\nThe official documentation is at https://onedata.org/#/home/api.\nImportant In order to be able to access the Onedata APIs, an access token is required. See below for instructions on how to generate one.  Getting an API access token Tokens have to be generated from the EGI DataHub (Onezone) interface as documented in Generating tokens for using Oneclient or APIs or using a command line call as documented hereafter.\nBear in mind that a single API token can be used with both Onezone, Oneprovider and other Onedata APIs.\nIt\u0026rsquo;s possible to retrieve the CLIENT_ID, CLIENT_SECRET and REFRESH_TOKEN using a special OIDC client connected to Check-in. See Check-in documentation for more information.\nCLIENT_ID=\u0026lt;CLIENT_ID\u0026gt; CLIENT_SECRET=\u0026lt;CLIENT_SECRET\u0026gt; REFRESH_TOKEN=\u0026lt;REFRESH_TOKEN\u0026gt; # Retrieving an OIDC token from Check-in curl -X POST -u \u0026#34;$CLIENT_ID\u0026#34;:\u0026#34;$CLIENT_SECRET\u0026#34; \\  -d \u0026#34;client_id=$CLIENT_ID\u0026amp;$CLIENT_SECRET\u0026amp;grant_type=refresh_token\u0026amp;refresh_token=$REDRESH_TOKEN\u0026amp;scope=openid%20email%20profile\u0026#34; \\  \u0026#39;https://aai.egi.eu/oidc/token\u0026#39; | python -m json.tool; # Token is in the `access_token` field of the response The following variables should be set:\n OIDC_TOKEN: OpenID Connect Access token. ONEZONE_HOST: name or IP of the Onezone host (to use Onezone API). ONEPROVIDER_HOST: name or IP of the Oneprovider host (to use Oneprovider API).  ONEZONE_HOST=https://datahub.egi.eu OIDC_TOKEN=\u0026lt;OIDC_ACCESS_TOKEN\u0026gt; curl -H \u0026#34;X-Auth-Token: egi:$OIDC_TOKEN\u0026#34; -X POST \\  -H \u0026#39;Content-type: application/json\u0026#39; -d \u0026#39;{}\u0026#39; \\  \u0026#34;$ONEZONE_HOST/api/v3/onezone/user/client_tokens\u0026#34; Testing the API with the REST client A docker container with clients acting as wrappers around the API calls is available: onedata/rest-cli. It's very convenient for discovering and testing the Onezone and Oneprovider API.\ndocker run -it onedata/rest-cli # Exporting env for Onezone API export ONEZONE_HOST=https://datahub.egi.eu export ONEZONE_API_KEY=\u0026lt;ACCESS_TOKEN\u0026gt; # Checking current user onezone-rest-cli getCurrentUSer | jq \u0026#39;.\u0026#39; # Listing all accessible spaces onezone-rest-cli listEffectiveUserSpaces | jq \u0026#39;.\u0026#39; docker run -it onedata/rest-cli # Exporting env for Oneprovider API export ONEPROVIDER_HOST=https://plg-cyfronet-01.datahub.egi.eu export ONEPROVIDER_API_KEY=\u0026lt;ACCESS_TOKEN\u0026gt; # Listing all spaces supported by the Oneprovider oneprovider-rest-cli getAllSpaces | jq \u0026#39;.\u0026#39; # Listing content of a space oneprovider-rest-cli listFiles path=\u0026#39;EGI Foundation/\u0026#39; oneprovider-rest-cli listFiles path=\u0026#39;EGI Foundation/CS3_dataset\u0026#39; Printing the raw REST calls of a wrapped command Raw REST calls (used with curl) can be printed using the --dry-run switch.\ndocker run -it onedata/rest-cli export ONEZONE_HOST=https://datahub.egi.eu export ONEZONE_API_KEY=\u0026lt;ACCESS_TOKEN\u0026gt; # Listing all accessible spaces onezone-rest-cli listEffectiveUserSpaces | jq \u0026#39;.\u0026#39; # Printing the curl command without running it onezone-rest-cli listEffectiveUserSpaces --dry-run Working with PID / Handle It\u0026rsquo;s possible to mint a Permanent Identifier (PID) for a space or a subdirectory of a space using a handle service (like Handle.net) that is registered in the Onezone (EGI DataHub).\nOnce done, accessing the PID using its URL will redirect to the Onedata share allowing to retrieve the files.\nPrerequisites: access to a Handle service registered in the Onezone. See the Handle Service API documentation for documentation on registering a new Handle service or ask a Onezone administrator to authorize you to use an existing Handle service already registered in the Onezone.\nThe following variables should be set:\n API_ACCESS_TOKEN: Onedata API access token ONEZONE_HOST: name or IP of the Onezone host (to use Onezone API). ONEPROVIDER_HOST: name or IP of the Oneprovider host (to use Oneprovider API)  # Getting the IDs of the available Handle Services curl -sS --tlsv1.2 -H \u0026#34;X-Auth-Token: $API_ACCESS_TOKEN\u0026#34; \\  \u0026#34;$ONEZONE_HOST/api/v3/onezone/user/handle_services\u0026#34; HANDLE_SERVICE=\u0026lt;HANDLE_SERVICE_ID\u0026gt; # Getting details about a specific Handle service curl -sS --tlsv1.2 -H \u0026#34;X-Auth-Token: $API_ACCESS_TOKEN\u0026#34; \\  \u0026#34;$ONEZONE_HOST/api/v3/onezone/user/handle_services/$HANDLE_SERVICE\u0026#34; # Listing all spaces curl -sS --tlsv1.2 -H \u0026#34;X-Auth-Token: $API_ACCESS_TOKEN\u0026#34; \\  \u0026#34;$ONEZONE_HOST/api/v3/onezone/user/effective_spaces/\u0026#34; | jq \u0026#39;.\u0026#39; # Displaying details of a space curl -sS --tlsv1.2 -H \u0026#34;X-Auth-Token: $API_ACCESS_TOKEN\u0026#34; \\  \u0026#34;$ONEZONE_HOST/api/v3/onezone/spaces/$SPACE_ID\u0026#34; | jq \u0026#39;.\u0026#39; # Listing content of a space curl -sS --tlsv1.2 -H \u0026#34;X-Auth-Token: $API_ACCESS_TOKEN\u0026#34; \\  \u0026#34;$ONEPROVIDER_HOST/api/v3/oneprovider/files/EGI%20Foundation/\u0026#34; | jq \u0026#39;.\u0026#39; # Creating a share of a subdirectory of a space DIR_ID_TO_SHARE=\u0026lt;DIR_ID\u0026gt; curl -sS --tlsv1.2 -H \u0026#34;X-Auth-Token: $API_ACCESS_TOKEN\u0026#34; \\  -X POST -H \u0026#39;Content-Type: application/json\u0026#39; \\  -d \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;input\u0026#34;}\u0026#39; \u0026#34;$ONEPROVIDER_HOST/api/v3/oneprovider/shares-id/$DIR_ID_TO_SHARE\u0026#34; | jq \u0026#39;.\u0026#39; # Displaying the share SHARE_ID=\u0026lt;SHARED_ID\u0026gt; curl -sS --tlsv1.2 -H \u0026#34;X-Auth-Token: $API_ACCESS_TOKEN\u0026#34; \\  \u0026#34;$ONEZONE_HOST/api/v3/onezone/shares/$SHARE_ID\u0026#34; | jq \u0026#39;.\u0026#39; # Registering a handle # Proper Dublin Core metadata is required # It can be created using https://nsteffel.github.io/dublin_core_generator/generator_nq.html cat metadata.xml # Escape double quotes and drop line return METADATA=$(cat metadata.xml | sed \u0026#39;s/\u0026#34;/\\\\\u0026#34;/g\u0026#39; | tr \u0026#39;\\n\u0026#39; \u0026#39; \u0026#39;) # On handle creation the created handles is provided in the Location header curl -D - --tlsv1.2 -H \u0026#34;X-Auth-Token: $API_ACCESS_TOKEN\u0026#34; \\  -H \u0026#34;Content-type: application/json\u0026#34; -X POST \\  -d \u0026#39;{\u0026#34;handleServiceId\u0026#34;: \u0026#34;\u0026#39;\u0026#34;$HANDLE_SERVICE_ID\u0026#34;\u0026#39;\u0026#34;, \u0026#34;resourceType\u0026#34;: \u0026#34;Share\u0026#34;, \u0026#34;resourceId\u0026#34;: \u0026#34;\u0026#39;\u0026#34;$SHARE_ID\u0026#34;\u0026#39;\u0026#34;, \u0026#34;metadata\u0026#34;: \u0026#34;\u0026#39;\u0026#34;$METADATA\u0026#34;\u0026#39;\u0026#34;}\u0026#39; \\  \u0026#34;$ONEZONE_HOST/api/v3/onezone/user/handles\u0026#34; # Listing handles curl --tlsv1.2 -H \u0026#34;X-Auth-Token: $API_ACCESS_TOKEN\u0026#34; \\  \u0026#34;$ONEZONE_HOST/api/v3/onezone/user/handles\u0026#34; # Displaying a handle HANDLE_ID=\u0026lt;HANDLE_ID\u0026gt; curl --tlsv1.2 -H \u0026#34;X-Auth-Token: $API_ACCESS_TOKEN\u0026#34; \\  \u0026#34;$ONEZONE_HOST/api/v3/onezone/user/handles/$HANDLE_ID\u0026#34; ","excerpt":"Most if not all operations can be performed using the Onedata API.\nThe official documentation is at …","ref":"/users/datahub/api/","title":"API"},{"body":"","excerpt":"","ref":"/users/check-in/","title":"Check-in"},{"body":"This documentation covers how to join the EGI Cloud federation as a provider. If you are interested in joining please first contact EGI operations team at operations@egi.eu, expressing interest and providing few details about:\n  the projects you may be involved in as cloud provider\n  the user communities you want to support (AKA Virtual Organisations, VO). You can also support the \u0026lsquo;long-tail of science\u0026rsquo; through the access.egi.eu VO.\n  the technologies (Cloud Management Framework) you want to provide.\n  details on the current status of your deployment (to be installed or already installed, already used or not, how it is used, who uses the services,\u0026hellip;)\n  Integration of cloud stacks into EGI FedCloud follows a well-defined path, with certain steps which need to be taken, depending on the cloud stack in question. By integration here, we refer to the proper interoperation with EGI infrastructure services such as accounting, monitoring, authentication and authorisation, etc. These configurations make your site discoverable and usable by the communities you wish to support, and allow EGI to support you in operational and technical matters.\nIntegration of these services implies specific configuration actions which you need to take on your site. These aim to be unintrusive and are mostly to facilitate access to your site by the communities you wish to support, without interfering with normal operations. This can be summarised essentially as :\n Network configuration Permissions configuration AAI configuration Accounting configuration Information system integration VM and appliance repository configuration  If at any time you experience technical difficulties or need support, please open a ticket or discuss the matter with us on the forum\nYou can follow find integration guides for your cloud management in this documentation.\n","excerpt":"This documentation covers how to join the EGI Cloud federation as a provider. If you are interested …","ref":"/providers/cloud-compute/","title":"Cloud Compute"},{"body":" This documentation about the Configuration Database is a work in progress, more documentation is currently available at https://wiki.egi.eu/wiki/GOCDB.\n The Grid Configuration Database (also know as the GOCDB) contains general information about the sites participating to the production infrastructure.\nIt\u0026rsquo;s used by all the actors (end-users, site managers, NGI mangers, support teams, VO managers), by other tools and by third party middleware to discover information about the infrastructure topology.\n","excerpt":"This documentation about the Configuration Database is a work in progress, more documentation is …","ref":"/internal/configuration-database/","title":"Configuration Database"},{"body":"Thank you for taking the time to contribute to this project. The maintainers greatly appreciate the interest of contributors and rely on continued engagement with the community to ensure that this project remains useful. We would like to take steps to put contributors in the best possible position to have their contributions accepted. Please take a few moments to read this short guide on how to contribute; bear in mind that contributions regarding how to best contribute are also welcome.\nStyle guide A summary of the style guide is available at style guide. Be sure to follow it when proposing changes.  Feedback and Questions If you wish to discuss anything related to the project, please open a GitHub issue or start a topic on the EGI Community Forum. The maintainers will sometimes move issues off from GitHub to the community forum if it is thought that longer, more open-ended discussion would be beneficial, including a wider community scope.\nContribution Process All contributions have to go through a review process, and contributions can be made in two ways:\n for simple contribution you can contribute from your browser by clicking the pencil Edit this file icon shown at the top of a page that you are viewing (See GitHub documentation). You will be guided through the required steps. Be sure to quickly save your changes quickly as the repository may be updated by someone else in the meantime. for more complex contributions and when you want to preview and test changes locally you should fork the repository as documented below in the Using git and GitHub page.  Contributing via a Pull Request Note If you need to discuss your change beforehand, like for adding a new section of if you have any doubts, you can ask the maintainers it by creating a GitHub issue.  Before proposing a contribution via the so-called Pull Request (PR), ideally there is an open issue describing the need for your contribution (refer to this issue number when you submit the Pull Request). We have a 3 steps process for contributions.\n Fork the project if you have not, and commit changes to a git branch. Documentation on building the documentation locally is available in the README.md Create a GitHub Pull Request for your change, following the instructions in the Pull Request template. Perform a Code Review with the maintainers on the Pull Request.  Pull Request Requirements  If the PR is not finalised mark it as draft using the GitHub web interface, so that it\u0026rsquo;s clear it\u0026rsquo;s not yet ready to be reviewed. Explain your contribution in plain language. To assist the maintainers in understanding and appreciating your pull request, please use the template to explain why you are making this contribution, rather than just what the contribution entails.  Code Review Process Code review takes place in GitHub pull requests. See this article if you\u0026rsquo;re not familiar with GitHub Pull Requests.\nOnce you open a pull request, automated checks will verify the style and syntax of your changes and maintainers will review your code using the built-in code review process in GitHub Pull Requests.\nThe process at this point is as follows:\n Automated syntax and formatting checks are run using GitHub Actions, successful checks are a hard requirement, but maintainers will help you addressing reported issues. A maintainer will review your code and merge it if no changes are necessary. Your change will be merged into the repository\u0026rsquo;s master branch. If a maintainer has feedback or questions on your changes then they will set request changes in the review and provide an explanation.  Release cycle The documentation is using a rolling release model, all changes merged to the master branch are directly deployed in the live production environment.\nMaster branch is always available. Tagged versions may be created as needed following Semantic Versioning as far as applicable.\nCommunity EGI benefits from a strong community of developers and system administrators, and vice-versa. If you have any questions or if you would like to get involved in the wider EGI community you can check out:\n EGI Community Forum EGI website  This file has been modified from the Chef Cookbook Contributing Guide.\n","excerpt":"Thank you for taking the time to contribute to this project. The maintainers greatly appreciate the …","ref":"/about/contributing/","title":"Contributing"},{"body":"Here you can find documentation about the EGI DataHub for service providers\n","excerpt":"Here you can find documentation about the EGI DataHub for service providers","ref":"/providers/datahub/","title":"DataHub"},{"body":"The following guide is intended for researchers who want to use ECAS, a complete environment enabling data analysis experiments, in the EGI cloud.\nECAS (ENES Climate Analytics Service) is part of the EOSC-hub service catalog and aims to:\n provide server-based computation, avoid data transfer, and improve reusability of data and workflows.  It relies on Ophidia, a data analytics framework for eScience, which provides declarative, server-side, and parallel data analysis, jointly with an internal storage model able to efficiently deal with multidimensional data and a hierarchical data organization to manage large data volumes (\u0026ldquo;datacubes\u0026rdquo;), and on JupyterHub, to give users access to ready-to-use computational environments and resources.\nThanks to the Elastic Cloud Compute Cluster (EC3) platform, operated by the Polytechnic University of Valencia (UPV), researchers will be able to rely on the EGI Cloud Compute service to scale up to larger simulations without being worried about the complexity of the underlying infrastructure.\nThis guide will show how to:\n deploy an ECAS elastic cluster of VMs in order to automatically install and configure the whole ECAS environment services, i.e. JupyterHub, PyOphidia, several Python libraries such as numpy, matplotlib and Basemap; perform data intensive analysis using the Ophidia HPDA framework; access the ECAS JupyterHub interface to create and share documents containing live code, equations, visualizations and explanatory text.  Deploy an ECAS cluster with EC3 In the latest release of the EC3 platform, tailored to support the EGI Applications on Demand (AoD) service, a new Ansible receipt is now available for researchers interested to deploy ECAS cluster on the EGI Infrastuctrure. Additional details on how to configure and deploy an ECAS cluster on EGI resources are provided in the next sections.\nECAS in now available in the latest release of the EC3 platform supporting the EGI Applications on Demand (AoD). The next sections provide details on how to configure and deploy an ECAS cluster on EGI resources.\nConfigure and deploy the cluster To configure and deploy a Virtual Elastic Cluster using EC3, access the EC3 platform front page and click on the \u0026quot;Deploy your cluster\u0026quot; link as shown in the figure below:\nA wizard will guide you through the cluster configuration process. Specifically, the general wizard steps include:\n LRMS selection: choose ECAS from the list of LRMSs (Local Resource Management System) that can be automatically installed and configured by EC3.   Endpoint: the endpoints of the providers where to deploy the ECAS elastic cluster. The endpoints serving the vo.access.egi.eu VO are dynamically retrieved from the EGI Application DataBase using REST APIs.   Operating System: choose EGI CentOS7 as cluster OS.   Instance details, in terms of CPU and RAM to allocate for the front-end and the working nodes.   Cluster\u0026rsquo;s size and name: the name of the cluster and the maximum number of nodes of the cluster, without including the front-end. This value indicates the maximum number of working nodes that the cluster can scale to. Initially, the cluster is created with the front-end and only one working node: the other working nodes will be powered on on-demand.   Resume and Launch: a summary of the chosen cluster configuration. To start the deployment process, click the Submit button.  When the front-end node of the cluster has been successfully deployed, you will be notified with the credentials to access via SSH.\nThe cluster details are available by clicking on the \u0026quot;Manage your deployed clusters\u0026quot; link on the front page:\nNote The configuration of the cluster may take some time. Please wait for its completion before starting to start using the cluster.  Accessing the cluster To access the front-end of the cluster:\n download the SSH private key provided by the EC3 portal; change its permissions to 600; access via SSH providing the key as identity file for public key authentication.  [fabrizio@MBP EC3]$ ssh -i key.pem cloudadm@134.158.151.218 Last login: Mon Nov 18 11:37:29 2019 from torito.i3m.upv.es [cloudadm@oph-server ~]$ sudo su - [root@oph-server ~]# Both the front-end and the working node are configured by Ansible. This process usually takes some time. You can monitor the status of the cluster configuration using the is_cluster_ready command-line tool:\n[root@oph-server ~]# is_cluster_ready Cluster is still configuring. The cluster is successfully configured when the command returns the following message:\n[root@oph-server ~]# is_cluster_ready Cluster configured! As SLURM is used as workload manager, it is possible to check the status of the working nodes by using the sinfo command, which provides information about Slurm nodes and partitions.\n[root@oph-server ~]# sinfo PARTITION AVAIL TIMELIMIT NODES STATE NODELIST debug* up infinite 1 down* oph-io2 debug* up infinite 1 idle oph-io1 Accessing the scientific eco-system ECAS provides two different ways to get access to its scientific eco-system: Ophidia client (oph_term) and JupyterHub.\nPerform some basic operations with Ophidia Run the Ophidia terminal as ophuser user.\nThe default parameters are already defined as environmental variables inside the .bashrc file:\nexport OPH_SERVER_HOST=\u0026#34;127.0.0.1\u0026#34; export OPH_SERVER_PORT=\u0026#34;11732\u0026#34; export OPH_PASSWD=\u0026#34;abcd\u0026#34; export OPH_USER=\u0026#34;oph-test\u0026#34; Create an empty container and a new datacube with random data and dimensions.\nNow, you can submit your first operation of data transformation: let\u0026rsquo;s reduce the whole datacube in a single value for grid point using the average along the time:\nLet\u0026rsquo;s have a look at the environment by listing the datacubes and containers in the session:\nBy default, the Ophidia terminal will use the last output datacube PID. So, you can use the oph_explorecube operator to visualize the first 100 values.\nFor further details about the Ophidia operators, please refer to the official documentation.\nAccessing the Jupyter interface To access the Jupyter interface, open the browser at https://\u0026lt;YOUR_CLUSTER_IP\u0026gt;:443/jupyter and log in to the system using the username and password specified in the jupyterhub_config.pyp configuration file (see the c.Authenticator.whitelist and c.DummyAuthenticator.password lines) located at the /root folder.\nFrom JupyterHub in ECAS you can do several things such as:\n create and run a Jupyter Notebook exploiting PyOphidia and Python libraries for visualization and plotting (e.g. matplotlib, basemap, NumPy); browse the directories, download and update the files in the home folder; execute operators and workflows directly from the Ophidia Terminal.  To get started with the ECAS environment capabilities, open the ECAS_Basics.ipynb notebook available under the notebooks/ folder in the home directory.\nReferences  https://ecaslab.cmcc.it/web/home.html https://ecaslab.dkrz.de/home.html http://ophidia.cmcc.it/ https://github.com/ECAS-Lab https://github.com/OphidiaBigData/ansible-role-ophidia-cluster http://www.grycap.upv.es/ec3 http://www.github.com/grycap/ec3  ","excerpt":"The following guide is intended for researchers who want to use ECAS, a complete environment …","ref":"/users/cloud-compute/ec3/ecas/","title":"ECAS"},{"body":"In this section we describe how users can easily discover the EGI Applications on Demand (AoD) service published in the EOSC portal Marketplace and submit a service-order request to deploy an elastic virtual cluster on the HNSciCloud pilot services. The virtual cluster will be deployed and configured with the requested software packages using the Elastic Cloud Compute Cluster (EC3) portal.\nSubmit a service-order request through the EOSC Portal Marketplace The EOSC Portal Marketplace is a single entry point where users can navigate the EOSC service catalogue, discover a service of interest, get information about it, and place an order in a few clicks by specifying the service requested along with the quantity, quality and duration.\nAll the available services of the EOSC Marketplace are grouped in 8 main categories and no authentication is required to browse and discover the list of services published in the marketplace.\nExoscale vouchers can be used when selecting he Elastic Cloud Compute Cluster (EC3) platform from the list of available services by submitting a service-order request.\nPlacing orders in the EOSC Marketplace requires the user to authenticate. There are two login options: use your personal academic credentials or use EGI Check-in service. The first time you login into the marketplace requires some extra information to be provided to configure the marketplace account.\nTwo different service options are available for EC3:\nTo deploy the virtual cluster on the HNSciCloud pilot services, select the voucher option and click on Next and provide additional information for profiling the order (e.g. the motivation for requesting the service).\nUsers with an existing Exoscale voucher to redeem can provide the voucherID during the submission request. Otherwise, a valid voucherID will be provided once the order if processed and accepted.\nOnce the service order is submitted, the marketplace will send a notification via email. Users can at any time the status of their orders through the user dashboard. This dashboard shows the history of service order(s) submitted.\nThe service order request will be processed within 3 working days. The user will be notified of the outcome of the evaluation via email.\nVoucher redemption In case the service order is accepted:\n The user will be notified by the Marketplace with the instructions to redeem the voucher (in case it was not provided), generate a client and secret keys and access the Elastic Cloud Compute Cluster (EC3) portal. To redeem an Exoscale voucher, open the provided voucher link included in the email sent by the Marketplace within a web browser. A typical link looks like:https://portal.exoscale.com/register?coupon=XXXXXXX Enter the email address and password you wish to use. Accept the terms and hit sign up.   A validation email is sent. Check out your mailbox and click on the verification link.   Choose \u0026ldquo;for team projects\u0026rdquo; and fill your details. Choose your \u0026ldquo;Company or team name\u0026rdquo; and submit the form.  Access to the Exoscale dashboard Access the Exoscale dashboard and check the tenant settings (click in the User profile on the left)\nCheck the voucher credit Access the Exoscale dashboard. The voucher credit is shown in the top-right of the dashboard. In case voucher credit is going to expire, a notification email will be sent by the dashboard.\nDeploy a virtual cluster on the Exoscale commercial resources Through a \u0026ldquo;job wizard\u0026rdquo; interface (see Figures below) the user can login to the Elastic Cloud Compute Cluster (EC3) portal and configure the virtual cluster with the related tools and applications to be deployed on top of Infrastructure as a Service (IaaS). The cluster is composed by a front node, where a batch job scheduler is running, and a number of compute nodes. These compute nodes will be dynamically deployed and provisioned to fit increasing load, and un-deployed when they are in idle status. The installation and configuration of the cluster is performed by means of the execution of Ansible receipts.\nAcknowledgement and report feedback The user MUST acknowledge the EOSC-hub and the HNSciCloud projects in the scientific publications/presentations benefiting from the service. The following acknowledgement statement can be used for this purpose:\n\u0026quot;This work used the EGI Applications on Demand service, which is co-funded by the EOSC-hub project (grant number 777536). The HNSciCloud project (grant number 687614) is also sponsoring the service, allowing users to access the HNSciCloud services pilot for limited scale usage using the voucher scheme provided by Exoscale.\u0026quot;\nReport feedback To report feedback on the Exoscale vouchers, please fill in the following web form: https://forms.gle/cVT7JRd4TFxZiYmQ8\n","excerpt":"In this section we describe how users can easily discover the EGI Applications on Demand (AoD) …","ref":"/users/applications-on-demand/exoscale/","title":"Exoscale vouchers"},{"body":"This section contains documentation about the EGI Internal Services, that are being operated centrally on behalf of EGI and supporting the coordination of the Federation.\n","excerpt":"This section contains documentation about the EGI Internal Services, that are being operated …","ref":"/internal/","title":"Internal Services"},{"body":"EGI Federated Cloud Site based on OpenNebula is an ordinary OpenNebula installation with some EGI-specific integration components. There are no additional requirements placed on internal site architecture. Follow OpenNebula documentation if you need advice on how to install and configure OpenNebula itself.\nSupprted OpenNebula versions:\n OpenNebula v5.2.x OpenNebula v5.4.x  Integration Prerequisites:\n Working OpenNebula installation. Valid IGTF-trusted host certificates for selected hosts.  Please consider that:\n CDMI storage endpoints are currently not supported for OpenNebula-based sites. OpenNebula GUI integration is not supported.  The following components must be installed:\n rOCCI-server -- provides a standard virtual machine management interface. keystorm -- serves federated authentication and authorization. cloudkeeper and cloudkeeper-one, synchronize site with appliances from AppDB. oneacct-export and apel-ssm -- collect accounting and publishe it into EGI's accounting database. cloud-info-provider and BDII, register site in the EGI Information System.  Open Ports The following ports must be open to allow access to an OpenNebula-based FedCloud site:\n   Port Application Host Note     2633/TCP OpenNebula/XML-RPC OpenNebula Communication between integration components and OpenNebula.   2170/TCP BDII/LDAP cloud-info-provider/BDII EGI Service Discovery/Information System.   11443/TCP OCCI/HTTPS rOCCI-server EGI Virtual Machine Management.   5000/TCP keystorm/HTTPS keystorm EGI User Management.   50505/TCP cloudkeeper/HTTP cloudkeeper EGI Image Management, needs to be accessible from cloudkeeper-one node only   50051/TCP cloudkeeper-one/gRPC cloudkeeper-one EGI Image Management, needs to be accessible from cloudkeeper node only    There are no additional requirements for OpenNebula hosts used to run virtual machines.\nService accounts This is an overview of service accounts used in an OpenNebula-based site. The names are default and can be changed if required.\n   Account name Host Use     rocci rOCCI-server Service account for rOCCI-server. It is only a service account, no access required.   keystorm keystorm Service account for keystorm. It is only a service account, no access required.   apel oneacct-export/APEL Service account for oneacct-export/APEL. Just a service account, no access required.   openldap cloud-info-provider/BDII Service account for cloud-info-provider/BDII. Just a service account, no access required.   cloudkeeper cloudkeeper Service account for cloudkeeper. Just a service account, no access required.   cloudkeeper-one cloudkeeper-one Service account for cloudkeeper-one. Just a service account, no access required.    EGI Virtual Machine Management Prerequisites Enable EPEL and install the following packages prior to installation:\nyum install -y epel-release wget Installation rOCCI-server is distributed as package for multiple Linux distributions which is available in AppDB. This guide will expect CentOS 7 distribution but installation on any other supported distribution is very similar.\n  Register rOCCI-server repositories\nwget http://repository.egi.eu/community/software/rocci.server/2.x/releases/repofiles/sl-7-x86_64.repo -O /etc/yum.repos.d/rocci-server.repo   Install package\nyum install -y occi-server   Configuration   Make rOCCI-server listen on a public interface\nmkdir -p /etc/systemd/system/occi-server.socket.d cat \u0026gt; /etc/systemd/system/occi-server.socket.d/override.conf \u0026lt;\u0026lt;EOS [Socket] # lines below are NOT duplicated by mistake ListenStream= ListenStream=0.0.0.0:11443 EOS sed -i \u0026#39;s/HOST=127.0.0.1/HOST=0.0.0.0/g\u0026#39; /etc/occi-server/variables   Uncomment and configure optional parameters in /etc/occi-server/variables\n# host certificate readable by the rocci user export HOST_CERT=/path/to/cert # host key readable by the rocci user export HOST_KEY=/path/to/key # URL pointing to keystorm installation export ROCCI_SERVER_KEYSTONE_URI=https://localhost:5000/ # URL pointing to OpenNebula installation export ROCCI_SERVER_OPENNEBULA_ENDPOINT=http://localhost:2633/RPC2 # crypto options MUST MATCH keystorm\u0026#39;s crypto options # see /etc/keystorm/variables export ROCCI_SERVER_ENCRYPTION_TOKEN_CIPHER= export ROCCI_SERVER_ENCRYPTION_TOKEN_KEY= export ROCCI_SERVER_ENCRYPTION_TOKEN_IV=   Enable and start the service\nsystemctl enable occi-server systemctl start occi-server   Runtime   Import resource templates to OpenNebula\n/opt/occi-server/bin/oneresource create --endpoint http://one.example.org:2633/RPC2 # --username PRIVILEGED_USER --password PASSWD # re-run with `--resources /opt/occi-server/embedded/app/rOCCI-server/lib/resources/gpu/` to enable GPU resource templates   In OpenNebula, set flags for groups by adding attributes:\n# Default cluster for this group DEFAULT_CLUSTER_ID=\u0026#34;0\u0026#34; # Default connectivity for this group: public|nat|private DEFAULT_CONNECTIVITY=\u0026#34;public\u0026#34;   In OpenNebula, set network type on networks used via OCCI by adding an attribute:\nNETWORK_TYPE=\u0026#34;public\u0026#34; # Supported types: public|nat|private   In OpenNebula, set flag for networks that should be treated as public IP pools (for IP reservations) by adding an attribute:\nFLOATING_IP_POOL=\u0026#34;yes\u0026#34;   In OpenNebula, set additional network attributes:\nNETWORK_ADDRESS=\u0026#34;\u0026#34; # e.g., \u0026#34;172.16.100.0\u0026#34; NETWORK_MASK=\u0026#34;\u0026#34; # e.g., \u0026#34;255.255.255.0\u0026#34; GATEWAY=\u0026#34;\u0026#34; # e.g., \u0026#34;172.16.100.1\u0026#34;   Migration from v1 to v2 In order to migrate from rOCCI-server v1 with Perun-managed user accounts, perform the following steps.\nPreparation  Disconnect direct propagation (slave scripts) Remove all user accounts that do not have any resource allocations  Migration   Merge multiple single-group accounts into one account with multiple groups\nSingle-group accounts owned by the same person can be identified as having:\n NAME following the naming convention $VONAME_$ID where the same user always has the same $ID TEMPLATE/X509_DN where the same user always has the same DN  Name of the merged user MUST be a SHA256 digest of the TEMPLATE/X509_DN attribute value.\nIn ruby, SHA256 digest can be generated as:\nrequire \u0026#39;digest\u0026#39; Digest::SHA256.hexdigest \u0026#39;DN_STRING_HERE\u0026#39;   Manually add user attributes\nFor each user, add the following attributes:\n TEMPLATE/ID TEMPLATE/NAME TEMPLATE/IDENTITY TEMPLATE/AUTHENTICATION  Where\n TEMPLATE/ID is a SHA256 digest of the TEMPLATE/X509_DN attribute value TEMPLATE/IDENTITY and TEMPLATE/NAME contain the old TEMPLATE/X509_DN value TEMPLATE/AUTHENTICATION is a static value \u0026lsquo;voms\u0026rsquo;    chown all user-owned resources to the new user\n  EGI User Management Prerequisites Enable EPEL and install the following packages prior to installation:\nyum install -y epel-release wget Installation keystorm is distributed as package for multiple Linux distributions which is available in AppDB. This guide will expect CentOS 7 distribution but installation on any other supported distribution is very similar.\n  Register keystorm repositories\nwget http://repository.egi.eu/community/software/keystorm/1.x/releases/repofiles/sl-7-x86_64.repo -O /etc/yum.repos.d/keystorm.repo   Install package\nyum install -y keystorm   Configuration   Uncomment and configure optional parameters in /etc/keystorm/variables\n# URL pointing to OpenNebula installation export KEYSTORM_OPENNEBULA_ENDPOINT=http://localhost:2633/RPC2 # Privileged OpenNebula credentials (with user \u0026amp; group management permissions) export KEYSTORM_OPENNEBULA_SECRET=oneadmin:opennebula   Enable and start the service\nsystemctl enable keystorm systemctl start keystorm   Configure Apache2/httpd\n# on Ubuntu/Debian only a2enmod ssl \u0026amp;\u0026amp; \\  a2enmod headers \u0026amp;\u0026amp; \\  a2enmod proxy \u0026amp;\u0026amp; \\  a2enmod proxy_http \u0026amp;\u0026amp; \\  a2enmod remoteip \u0026amp;\u0026amp; \\  a2enmod auth_openidc \u0026amp;\u0026amp; \\  a2enmod zgridsite # make sure the following files exist SSLCertificateFile /etc/grid-security/hostcert.pem SSLCertificateKeyFile /etc/grid-security/hostkey.pem # make sure the following directory exists SSLCACertificatePath /etc/grid-security/certificates   Enable and start Apache2/httpd\n# on Ubuntu/Debian only systemctl enable apache2 systemctl restart apache2 # on CentOS/SL only systemctl enable httpd systemctl start httpd   Enable support for EGI VOs via VOMS: VOMS configuraton\n  Enable support for EGI VOs via OIDC: TBD\n  Runtime   In OpenNebula, create empty groups for fedcloud.egi.eu, ops, and dteam with group attribute:\n# Allow keystorm to manage membership for this group KEYSTORM=\u0026#34;YES\u0026#34;   EGI Accounting Prerequisites oneacct-export uses Secure Stomp Messenger to send accounting records to the central repository. Please, refer to ssm documentation for installation instructions. By default, accounting records are placed in /var/spool/apel/outgoing/00000000. You have to configure and run ssmsend periodically, this is not handled by oneacct-export.\nEnable EPEL and install the following packages prior to oneacct-export installation: :\nyum install -y epel-release wget Installation oneacct-export is distributed as package for multiple Linux distributions which is available in AppDB. This guide will expect CentOS 7 distribution but installation on any other supported distribution is very similar.\n  Register oneacct-export repositories\nwget http://repository.egi.eu/community/software/oneacct.export/0.4.x/releases/repofiles/sl-7-x86_64.repo -O /etc/yum.repos.d/oneacct-export.repo   Install package\nyum install -y oneacct-export   Configuration   Edit /etc/oneacct-export/conf.yml\napel:# Usually a short provider name, e.g. CESNETsite_name:Undefined# CMF type, only OpenNebula is supportedcloud_type:OpenNebula# Public URL of your OCCI endpointendpoint:https://localhost.edu:11443/xml_rpc:# OpenNebula credentials, privilegedsecret:oneadmin:opennebula# OpenNebula XML RPC endpointendpoint:http://localhost:2633/RPC2  Add the following lines to /etc/one/oned.conf and restart OpenNebula\nINHERIT_IMAGE_ATTR = \u0026#34;VMCATCHER_EVENT_AD_MPURI\u0026#34; INHERIT_IMAGE_ATTR = \u0026#34;VMCATCHER_EVENT_DC_IDENTIFIER\u0026#34; INHERIT_IMAGE_ATTR = \u0026#34;VMCATCHER_EVENT_IL_DC_IDENTIFIER\u0026#34; INHERIT_IMAGE_ATTR = \u0026#34;VMCATCHER_EVENT_SL_CHECKSUM_SHA512\u0026#34; INHERIT_IMAGE_ATTR = \u0026#34;VMCATCHER_EVENT_HV_VERSION\u0026#34;   Set benchmark values on CLUSTERs (applies to all hosts in the cluster) or HOSTs (only for that host) in OpenNebula\n# benchmark type BENCHMARK_TYPE = \u0026#34;HEP-SPEC06\u0026#34; # represents a per-core measured value of said benchmark BENCHMARK_VALUE = \u0026#34;84.46\u0026#34;   Use /etc/oneacct-export/groups.include or /etc/oneacct-export/groups.exclude to control which information gets exported. Specify one group name per line.\n  Usage   Enable and register service 'redis'\nservice redis start chkconfig redis on   Enable and register service 'oneacct-export-sidekiq'\nservice oneacct-export-sidekiq start chkconfig oneacct-export-sidekiq on   Perform the first export manually\n# This process may take a long time, consider using **tmux** or **screen** sudo -u apel /usr/bin/oneacct-export-cron --all   Enable and register service 'oneacct-export-cron'\nservice oneacct-export-cron start chkconfig oneacct-export-cron on   This service registers a cron job which will run oneacct-export every 2 hours.\nEGI Information System Sites must publish information to EGI information system which is based on BDII. There is a common bdii provider for all cloud management frameworks. Information on installation and configuration is available in the cloud-bdii-provider README.md and in the FedClouds BDII instructions, there is a specific section with OpenNebula details.\nEGI VM Image Management cloudkeeper and cloudkeeper-one are tools used to ensure synchronization of virtual appliances with an OpenNebula-based cloud.\nPrerequisites cloudkeeper uses VO-wide image lists provided by AppDB to synchronize virtual appliances to clouds. In order to use VO-wide image lists you need to have a valid access token to AppDB. Check how to access to VO-wide image lists and how to subscribe to a private image list documentation for more information.\n  Install recent qemu-img and wget\nyum install -y centos-release-qemu-ev wget sudo   Installation Both cloudkeeper and cloudkeeper-one are distributed as packages for multiple Linux distributions which are available in AppDB. This guide will expect CentOS 7 distribution but installation on any other supported distribution is very similar.\n  Register cloudkeeper and cloudkeeper-one repositories\nwget http://repository.egi.eu/community/software/cloudkeeper/1.x/releases/repofiles/sl-7-x86_64.repo -O /etc/yum.repos.d/cloudkeeper.repo wget http://repository.egi.eu/community/software/cloudkeeper.one/1.x/releases/repofiles/sl-7-x86_64.repo -O /etc/yum.repos.d/cloudkeeper-one.repo   Install cloudkeeper and cloudkeeper-one\nyum install -y cloudkeeper cloudkeeper-one   cloudkeeper configuration cloudkeeper configuration file can be found in /etc/cloudkeeper/cloudkeeper.yml.\n image-lists  URLs of image lists containing appliances which you want to synchronize to your cloud. Must contain authentication token.\n  image-lists:# List of image lists to sync against- https://APPDB_TOKEN:x-oauth-basic@vmcaster.appdb.egi.eu/store/vo/somevo/image.list- https://APPDB_TOKEN:x-oauth-basic@vmcaster.appdb.egi.eu/store/vo/othervo/image.list authentication  Says whether cloudkeeper and cloudkeeper-one will communicate securely via TLS. This requires options certificate, key and backend-\u0026gt;certificate to be properly set.\n image-dir  Directory where images will be downloaded and converted before uploading to OpenNebula. Directory is cleaned after each appliance registration/update nonetheless, it should provide sufficient free space (some runs may require up to 200GB of free space).\n remote-mode  Says whether to serve downloaded images via web server or to copy them locally. Should be true especially if OpenNebula is running on different machine than cloudkeeper and cloudkeeper-one.\n nginx-\u0026gt;ip-address  IP address on which NGINX will serve images in remote mode. This address MUST be accessible from the machine hosting cloudkeeper-one and your OpenNebula installation.\n formats  List of image formats images can be converted to and are supported by the cloud.\n  cloudkeeper-one configuration cloudkeeper-one configuration file can be found in /etc/cloudkeeper-one/cloudkeeper-one.yml.\n authentication  Says whether cloudkeeper and cloudkeeper-one will communicate securely via TLS. This requires options certificate, key and core-\u0026gt;certificate to be properly set.\n appliances-\u0026gt;tmp-dir  Directory images will be copied to before registration in OpenNebula when in non-remote mode.\n appliances-\u0026gt;template-dir  Directory for ERB-enabled templates of OpenNebula images and templates used for registration. More information in the next section.\n opennebula-\u0026gt;datastores  List of OpenNebula datastores images are uploaded to.\n opennebula-\u0026gt;allow-remote-source  Allows OpenNebula to directly download images in remote mode.\n  Templates configuration The directory specified by option appliances-\u0026gt;template-dir contains templates for OpenNebula images and templates in files image.erb and template.erb. These files can be customized to register images and templates according to your needs. Files are using standard ERB templating mechanism. By default, these files can be found in /etc/cloudkeeper-one/templates/.\n image.erb available variables:   name  Name, under which will the image be registered\n appliance  Appliance object. Contains following attributes: identifier, title, description, mpuri, group, ram, core, version, architecture, operating_system, vo, expiration_date, image_list_identifier, attributes.\n image  Image object. Contains following attributes: format, uri, checksum, size\n   template.erb available variables:   name  Name, under which will the template be registered\n image_id  ID of the previously registered image (same appliance)\n appliance  Appliance object. Same as for image.erb\n image  Image object. Same as for image.erb\n  For compatibility with other integration components, add the following lines to ``image.rb``:\nVMCATCHER_EVENT_AD_MPURI=\u0026#34;\u0026lt;%= appliance.mpuri %\u0026gt;\u0026#34; VMCATCHER_EVENT_HV_VERSION=\u0026#34;\u0026lt;%= appliance.version %\u0026gt;\u0026#34; VMCATCHER_EVENT_DC_DESCRIPTION=\u0026#34;\u0026lt;%= appliance.description %\u0026gt;\u0026#34; VMCATCHER_EVENT_DC_TITLE=\u0026#34;\u0026lt;%= appliance.title %\u0026gt;\u0026#34; Usage   Start and enable cloudkeeper-one service\nsystemctl enable cloudkeeper-one systemctl start cloudkeeper-one   cloudkeeper-one will be now listening for communication from cloudkeeper.\n  Perform the first synchronization manually\n# This MAY take a long time, keep checking for successful exit with # `systemctl status cloudkeeper` systemctl start cloudkeeper   Start and enable systemd timer for cloudkeeper\nsystemctl enable cloudkeeper.timer systemctl start cloudkeeper.timer   This service registers a systemd timer which will run cloudkeeper approx. every 2 hours.\n","excerpt":"EGI Federated Cloud Site based on OpenNebula is an ordinary OpenNebula installation with some …","ref":"/providers/cloud-compute/opennebula/","title":"OpenNebula"},{"body":"EGI provides a training instance of the Notebooks service for training events.\nTo get started:\n  Go to https://training.notebooks.egi.eu.\nNote This instance may not use the same software version as in production and may not be always available, as it is typically configured only for specific training events.    Start the authentication process by clicking on Start your notebooks! button\n  Select the Identity Provider you belong to from the discovery page. If this is the first time you access an EGI service, Check-in will guide you through a registration process.\n  You will see the Jupyter interface once your personal server is started\n  Launching a notebook Click on the New \u0026gt; Python 3 option to launch your notebook with Python 3 kernel. When you create this notebook, a new tab will be presented with a notebook named Untitled.ipynb. You can easily rename it by right-clicking on the current name.\nStructure of a notebook The notebook consists of a sequence of cells. A cell is a multiline text input field, and its contents can be executed by using Shift-Enter, or by clicking either the \u0026ldquo;Play\u0026rdquo; button in the toolbar, or Cell -\u0026gt; Run in the menu bar.\nThe execution behaviour of a cell is determined by the cell\u0026rsquo;s type.\nThere are three types of cells: cells, markdown, and raw cells. Every cell starts off being a code cell, but its type can be changed by using a drop-down on the toolbar (which will be \u0026ldquo;Code\u0026rdquo;, initially).\nCode cells A code cell allows you to edit and write new code, with full syntax highlighting and tab completion. The programming language you use depends on the kernel.\nWhen a code cell is executed, its content is sent to the kernel associated with the notebook. The results that are returned from this computation are then displayed in the notebook as the cell\u0026rsquo;s output. The output is not limited to text, with many other possible forms of output are also possible, including figures and HTML tables.\nMarkdown cells You can document the computational process in a literate way, alternating descriptive text with code, using rich text. This is accomplished by marking up text with the Markdown language. The corresponding cells are called Markdown cells. The Markdown language provides a simple way to perform this text markup, that is, to specify which parts of the text should be emphasized (italics), bold, form lists, etc.\nIf you want to provide structure for your document, you can also use markdown headings. Markdown headings consist of 1 to 6 hash # signs followed by a space and the title of your section. The markdown heading will be converted to a clickable link for a section of the notebook. It is also used as a hint when exporting to other document formats, like PDF.\nWhen a Markdown cell is executed, the Markdown code is converted into the corresponding formatted rich text. Markdown allows arbitrary HTML code for formatting.\nRaw cells Raw cells provide a place in which you can write output directly. Raw cells are not evaluated by the notebook.\nKeyboard shortcuts All actions in the notebook can be performed with the mouse, but keyboard shortcuts are also available for the most common ones. These are some of the most common:\n Shift-Enter: run cell. Execute the current cell, show any output, and jump to the next cell below. If Shift-Enter is invoked on the last cell, it creates a new cell below. This is equivalent to clicking the Cell -\u0026gt; Run menu item, or the Play button in the toolbar. Esc: Command mode. In command mode, you can navigate around the notebook using keyboard shortcuts. Enter : Edit mode. In edit mode, you can edit text in cells.  Hands-on We pre-populate your home directory with some sample notebooks to get started, below you can find links to other notebooks that we have used in past trainings that may be useful to explore the system:\n A very basic notebook to get started Getting data and doing a simple plot. Connect to NOAA's GrADS Data Server to plot wind speed. Installing new libraries. Interact with Check-in  ","excerpt":"EGI provides a training instance of the Notebooks service for training events.\nTo get started:\n  Go …","ref":"/users/notebooks/training/","title":"Training instance"},{"body":"Users of the EGI Cloud create Virtual Machines (VMs) on the providers. Those VMs are started from images: templates for the root volume of the running instances, i.e. operating system and applications available initially on a VM. The AppDB collects the Virtual Machine Images available on the service as Virtual Appliances (VA).\nAny user can register new Virtual Appliances at the AppDB, these are then managed by special VO members that curate which appliances are available to their VO.\nAppDB Cloud Marketplace The AppDB is a browsable catalogue of Virtual Appliances that users can start at the providers. You can find below a set of reference guides for the catalogue:\n How to register a VA?: any registered user can register VAs in AppDB for anyone to download or for making them available at the EGI Cloud providers once a VO adds it to the VO-wide image list. Once registered, VAs can be managed as described in the VA management guide. VO managers select VAs to be available at the providers following the VO-wide image list management.  Check the full list of Cloud marketplace guides and Cloud marketplace FAQ for more information about the AppDB features.\nCustom images Packaging your application in a custom VM image is a suggested solution in one of the following cases:\n your particular OS flavor is not available at AppDB; installation of your application is very complex and time-consuming for being performed during contextualization; or you want to reduce the number of 'moving-parts' of your software stack and follow an immutable infrastructure approach for deploying your application.  Custom VM images can be crafted in different ways. The two main possibilities are:\n start from scratch, creating a virtual machine, installing an OS and the software on top of it, then taking the virtual machine OS disk as custom image; or dump an existing disk from a running VM or physical server and modify it, if needed, to run on a virtualisation platform.  In this guide we will focus on the first option, because it tends to produce cleaner images and reduces the risks of hardware conflicts. Snapshotting may be also restricted by the cloud providers or by security policies.\nAdvantages:\n Possibility to build the virtual disk directly from a legacy machine, dumping the contents of the disk. Possibility to speed-up the deployment for applications with complex and big installation packages. This because you do not need to install the application at startup, but the application is already included in the machine.  Disadvantages:\n Building a virtual disk directly from a legacy machine poses a set of compatibility issues with hardware drivers, which usually differs from a virtual and physical environment and even between different virtual environments. You need to keep your machine updated. Outdated VM disk images may take a long time to startup due to the need to download and install the latest OS updates. If you are using special drivers or you are not packaging correctly the disk, your custom VM image may not run (or run slowly) on different cloud providers based on different virtualisation technologies. VM images on public clouds are sometimes public, thus be aware of installing proprietary software on custom images, since other users may be able to run the image or download it. In general, the effort to implement this solution is higher than the basic contextualization.  Image size and layout The larger the VM image, the longer it will take to be distributed to the providers and the longer it will take to be started on the infrastructure. As a general rule, always try to make images as smaller as possible following these guidelines:\n  DO NOT include (big) data in your image. There are other mechanisms for accessing data from your VM (block/object storage, CVMFS)\n  DO NOT include (big) empty space or swap in your image. Extra space for your computation or swap can be added with block storage once the VM is booted or using VM flavors that have extra disk allocated for your VM.\n  DO NOT install un-needed software. Tools like GUI are of no-use in most cases since you will have no access to the graphical console of the VM.\n  DO adjust the size of the images as much as possible. As stated above, empty space can be allocated on runtime easily.\n  DO use compressed image formats, like qcow2 or vmdk (used in OVA) to minimize the size of the image. Preferred format for images in EGI is OVA as it's standardised.\n  DO fill with 0 the empty disk space of your image so when compressed it can be significantly reduced, e.g. using:\ndd if=/dev/zero of=/bigemptyfile bs=4096k rm -rf /bigemptyfile   DO use a single partition (no /boot, no swap) for the disk layout and avoid LVM. This will allow the cloud provider to easily resize your partition when instantiated and to modify files in it if needed.\n  Contextualization and credentials Danger Do NOT include any credentials on your images.  You should never include any kind of credentials on your images, instead you should use contextualization. cloud-init is a tool that will simplify the contextualization process for you. This is widely available as packages in major OS distributions and is supported by all the providers of the EGI Cloud and most of the commercial providers.\ncloud-init documentation contains detailed examples on how to create users, run scripts, install packages and several other actions supported by the tool.\nFor complex setups, especially when applications involve multiple VMs it may be useful to use cloud-init to bootstrap some Configuration Management Software that will manage the configuration of the VMs during runtime.\nSecurity  Always remove all default passwords and accounts from your VM. Disable all services unless necessary for the intended tasks. Make sure the firewall configuration (iptables for Linux, also on IPv6) is minimally open. Put no shared credentials (passwords) in any image.  You should also follow the best practice guides for each service that's exposed to the outside world. See for example guides for:\n ssh tomcat  See also AWS security Best Practices\nTools Whenever possible, automate the process of creating your images. This will allow you to:\n get reproducible results avoid tedious manual installation steps quickly produce updated versions of your images.  EGI uses packer as a tool for automating the creation of our base images. This tool can use VirtualBox as a hypervisor for the creation of the images and guarantees identical results under different platforms and providers.\nCheck the fedcloud-vmi-templates github repo with all the packer recipes used to build our images and re-use them as needed for your images.\n","excerpt":"Users of the EGI Cloud create Virtual Machines (VMs) on the providers. Those VMs are started from …","ref":"/users/cloud-compute/vmi/","title":"Virtual Machine Image Management"},{"body":"This page contains information about using Check-in for managing your Virtual Organisation (VO).\nVO management VOs in Check-in are represented as Collaborative Organisation Units (COUs). A COU is more than just a group. It is the concept of groups combined with membership management and advanced enrolment workflows. COUs can also be organised in a hierarchical structure for creating groups or subgroups within a VO.\nIt is assumed that VO managers and members have already registered their EGI Check-in account (A step-by-step guide is provided in this link.\nRegistering your VO Any person who can authenticate to the Operations Portal using their EGI Check-in account can register a new VO.\nThe person initiating the registration is called the VO manager. After the VO is set up and operational, the VO manager is the person who is primarily responsible for the operation of the VO and for providing sufficient information about VO activities for EGI and for VO members (to both people and sites).\nA step-by-step guide for the VO registration process is provided in the following link: https://wiki.egi.eu/wiki/PROC14_VO_Registration#VO_registration\nViewing VO members   Login to Check-in registry using any of the login credentials already linked to your EGI account.\n  To view the existing members, expand the People drop down menu and click on My VO-NAME Population (for example, My vo.example.org Population)\n  Then you are able to see all the VO members.\n  Accepting new VO members Users can request membership in your VO by following the VO enrollment URL. The enrollment URL has the following form:\nhttps://aai.egi.eu/registry/co_petitions/start/coef:## where ## is the unique numeric identifier for the enrollment flow of your VO.\nOnce a user submits a VO membership petition, all VO managers are notified with an email containing a link to the petition. Any of the VO managers can then review the petition and either approve or deny the request.\nThe VO enrollment URL can be found through the EGI Check-in Registry:\n  Login to Check-in registry using any of the login credentials already linked to your EGI account.\n  Expand the People drop down menu and click Enroll.\n  Copy the Begin link of the Enrollment flow of the VO you want the user to join and send it to the user\n  Once the user submits the VO membership request, the Role Attributes section of their profile page will include the new VO membership role in Pending Approval status\n  Once the VO manager accepts the new member, the Role Attributes section of the user\u0026rsquo;s profile page will include the VO membership role in Active status\n  Managing VO groups VO groups can only be created by Check-in platform administrators. Please contact Checkin Support indicating the following information for every (sub)group that you need to add/remove to/from your VO:\n VO name Group name Group description Optional, Group manager(s), i.e. the Check-in identifiers (in the form of \u0026quot;xxxxxxx@egi.eu\u0026quot;) of one or more users responsible for managing the VO group members. Group managers can also appoint other users as (sub)group managers. The manager(s) of the VO (or any parent group) are implicitly managers of the group. You can provide additional Check-in user identifiers to extend the list of group managers. Optional, Parent VO group name (in the case of a hierarchical group, e.g. \u0026lt;VO\u0026gt; \u0026ndash;\u0026gt; \u0026lt;PARENT_GROUP\u0026gt; \u0026ndash;\u0026gt; \u0026lt;GROUP\u0026gt;)  Known limitation: Group names must be unique so the names you suggest may need to be adjusted by the Check-in administrators to guarantee their uniqueness.\nAdding members to VO groups   Login to Check-in registry using any of the login credentials already linked to your EGI account.\n  Then expand the People drop down menu and click My \u0026lt;VO-NAME\u0026gt; Population (for example, My vo.example.org Population)\n  Find the user you want to add to the VO Group and click Edit.\n  Click Add at the Role Attributes section of the user profile\n  Fill in the fields in the form and click Add. The user now is a member of the new VO group. For more information about Affiliation and Role fields you can see below at section Managing Affiliation and Role of VO Member\n  Removing members From the VO members list (see Viewing VO members above):\n  Click Edit on the person that is going to be removed.\n  Under Role Attributes click Delete on the right of the COU entry of interest (for example, vo.example.com). On success the selected row will be removed. In this example we removed the vo.geoss.eu that we previously added.\n  Managing Affiliation and Role of VO Member User\u0026rsquo;s Affiliation to a VO, as defined in RFC4512, has eight permissible values. These are faculty, student, staff, alum, member, affiliate, employee, library-walk-in. EGI Check-in assigns to all user\u0026rsquo;s the affiliation Member by default, during the VO(COU) enrollment process. This value is immutable for the user but editable for the VO administrator. As a result, if there is a change of status the administrator can always step in and change it appropriately. Additionally, the user\u0026rsquo;s Role in a VO is the EGI User Community Title column, in Co Person Role\u0026rsquo;s View. This column can be either a custom text value; or a value chosen from a drop down list. The drop down list administration is an EGI Check-in CO administrator task and can not be managed by any VO admin.\nUpdate User\u0026rsquo;s VO affiliation   Navigate to Co Person Role view   Choose Affiliation from drop down list   Update User\u0026rsquo;s VO Role   Navigate to Co Person Role view   Choose Role from drop down list, if available, or add custom text if no list is present.   Subsequently, EGI Check-in uses the CO Person\u0026rsquo;s group membership and role information in order to construct the eduPersonEntitlement values, in short entitlements. These URN-formatted attributes can be used for representing group membership, as well as to indicate rights to resources. According to the AARC-G002 specification, a user that is a member of the VO vo.example.org, and has the role supervisor, obtains the following entitlements:\n  urn:mace:egi.eu:group:vo.example.org:role=member#aai.egi.eu\n  urn:mace:egi.eu:group:vo.example.org:role=supervisor#aai.egi.eu\n  Managing COU Admin members COU Admin Groups are used to determine COU Administrators. Admin Groups are automatically created when a COU is created. The default name for COU admin groups is\nCO:COU:\u0026lt;COU_Name\u0026gt;:admins\nFor example CO:COU:vo.example.org:admins\n A CO Person can be a member, an owner, both, or neither. Specifically:  A COU admins group member can manage COU members: Approve or decline membership petitions   Manage members\u0026rsquo; roles  A COU admins group owner has permission to add and remove members to and from the group, i.e. manage the list of CO Persons who can manage the COU members    A COU admins group owner can manage the admins group member as follows:\n  Login to Check-in registry using any of the login credentials already linked to your EGI account.\n  To view the available groups expand the Groups drop down list and click All Groups\n Expand the Filter section and find the COU admin group you are interested in. For the case of the service-integration COU with type the string service-integration in the text box with the placeholder Name. Then we click on Filter button    Locate Admins group click on Edit action\n  Assign COU member admin role From the steps defined above:\n  Follow Manage Group Memberships link\n  Filter out the CO Person you need to apply for the admin role. Use Given, Family Name, Email, Identifier or a combination of the former.\n  Remove COU admin role From the steps defined above:\n  Under Group Members tab, click on Delete action for the CO Person that needs to be removed from Admins group\n  VO membership API Check-in provides a REST API that allows clients to manage membership information only for the VOs they are authoritative for.\nFeatures:\n Members of the VO are identified via their EGI Check-in ePUID Membership can be limited to a specified period Different membership status values are supported, namely Active, Expired, Deleted Check-in automatically changes the membership status from Active to Expired beyond the validity period  Authentication The REST client is authenticated via username/password credentials transmitted over HTTPS using the Basic Authentication scheme. More sophisticated authentication mechanisms, such as OpenID Connect/OAuth 2.0 access tokens, may be supported in the future.\nMethods   Adding a user to a VO requires specifying the user\u0026rsquo;s EGI Check-in ePUID, the name of the VO (e.g. vo.access.egi.eu in the case of LToS), the status (Active) and the valid from/through dates. All these parameters are mandatory. Here is an example using curl (see example add.json file below):\ncurl -vX POST https://aai.egi.eu/api/v1/VoMembers \\  --user \u0026#34;example-client\u0026#34;:\u0026#34;veryverysecret\u0026#34; \\  --data @add.json \\  --header \u0026#34;Content-Type: application/json\u0026#34; ad.json:\n{ \u0026#34;RequestType\u0026#34;: \u0026#34;VoMembers\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;1.0\u0026#34;, \u0026#34;VoMembers\u0026#34;: [ { \u0026#34;Version\u0026#34;: \u0026#34;1.0\u0026#34;, \u0026#34;VoId\u0026#34;: \u0026#34;vo.access.egi.eu\u0026#34;, \u0026#34;Person\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;CO\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;01234567890123456789@egi.eu\u0026#34; }, \u0026#34;Status\u0026#34;: \u0026#34;Active\u0026#34;, \u0026#34;ValidFrom\u0026#34;: \u0026#34;2017-05-21\u0026#34;, \u0026#34;ValidThrough\u0026#34;: \u0026#34;2017-06-21\u0026#34; } ] }   Retrieving the VO membership information for a given EGI Check-in ePUID:\ncurl -vX GET https://aai.egi.eu/api/v1/VoMembers/01234567890123456789@egi.eu \\  --user \u0026#34;example-client\u0026#34;:\u0026#34;veryverysecret\u0026#34; output:\n[ { \u0026#34;id\u0026#34;: 85, \u0026#34;epuid\u0026#34;: \u0026#34;01234567890123456789@egi.eu\u0026#34;, \u0026#34;vo_id\u0026#34;: \u0026#34;vo.access.egi.eu\u0026#34;, \u0026#34;valid_from\u0026#34;: \u0026#34;2017-05-20T22:00:00.000Z\u0026#34;, \u0026#34;valid_through\u0026#34;: \u0026#34;2017-06-21T22:00:00.000Z\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;Active\u0026#34; } ] Beyond the valid_through date, the status will be automatically changed to Expired. So, when querying for VO membership information, it\u0026rsquo;s important to check that the status is actually set to Active for each of the identified VOs (see the vo_id attribute)\n  Updating existing VO membership record:\ncurl -vX PUT https://aai.egi.eu/api/v1/VoMembers \\  --user \u0026#34;example-client\u0026#34;:\u0026#34;veryverysecret\u0026#34; \\  --data @update.json \\  --header \u0026#34;Content-Type: application/json\u0026#34; The request body is the same as the one used for adding new members but update requires using PUT instead of POST.\n  Removing VO member:\nSame as the update but requires setting the membership status to Deleted\n  ","excerpt":"This page contains information about using Check-in for managing your Virtual Organisation (VO).\nVO …","ref":"/users/check-in/vos/","title":"Virtual Organisations"},{"body":"EGI Accounting is made of two main components:\n The Accounting Repository where all accounting data is collected. The Accounting Portal allowing to filter and display the data.  About the Accounting Repository Documentation about the Accounting Repository is currently available on the EGI Wiki.\n About the Accounting Portal The Accounting Portal is available at https://accounting.egi.eu.\nDocumentation about the Accounting Repository is currently available on the EGI Wiki.\n ","excerpt":"EGI Accounting is made of two main components:\n The Accounting Repository where all accounting data …","ref":"/internal/accounting/","title":"Accounting"},{"body":"The EGI Cloud service offers a multi-cloud IaaS federation that brings together research clouds as a scalable computing platform for data and/or compute driven applications and services for research and science.\nThis documentation focuses on using the service. Those resource providers willing to integrate into the service, please check the EGI Federated Cloud Integration documentation.\nCloud Compute gives you the ability to deploy and scale virtual machines on-demand. It offers computational resources in a secure and isolated environment controlled via APIs without the overhead of managing physical servers.\nCloud Compute service is provided through a federation of IaaS cloud sites that offer:\n Single Sign-On via EGI Check-in, users can login into every provider with their institutional credentials and use modern industry standards like OpenID Connect. Global VM image catalogue at AppDB with pre-configured Virtual Machine images that are automatically replicated to every provider based on your community needs. Resource discovery features to easily understand which providers are supporting your community and what are their capabilities. Global accounting that aggregates and allows visualisation of usage information across the whole federation. Monitoring of Availability and Reliability of the providers to ensure SLAs are met.  The flexibility of the Infrastructure as a Service can benefit various use cases and usage models. Besides serving compute/data intensive analysis workflows, Web services and interactive applications can be also integrated with and hosted on this infrastructure. Contextualisation and other deployment features can help application operators fine tune services in the cloud, meeting software (OS and software packages), hardware (number of cores, amount of RAM, etc.) and other types of needs (e.g. orchestration, scalability).\nSince the opening of the EGI Federated Cloud, the following usage models have emerged:\n Service hosting: the EGI Federated Cloud can be used to host any IT service as web servers, databases, etc. Cloud features, as elasticity, can help users to provide better performance and reliable services.  Example: NBIS Web Services, Peachnote analysis platform.   Compute and data intensive applications: for those applications needing considerable amount of resources in terms of computation and/or memory and/or intensive I/O. Ad-hoc computing environments can be created in the EGI cloud providers to satisfy extremly intensive HW resource requirements.  Example: VERCE platform, The Genetics of Salmonella Infections, The Chipster Platform.   Datasets repository: the EGI Cloud can be used to store and manage large datasets exploiting the large amount of disk storage available in the Federation. Disposable and testing environments: environments for training or testing new developments.  Example: Training infrastructure    EGI Federated Cloud task force The EGI Federated Cloud task force gathers together scientific communities, R\u0026amp;D projects, and technology and resource providers so they can design the tools and services that support the federation of providers, can share best practices, and can offer user support and training in a collaborative fashion. This enables community cloud solutions to develop faster, with a lower cost and with a more sustainable future. The task force members:\n Capture requirements from user communities needing federated cloud services. Identify, integrate and enhance open source tools and services that enable cloud federations for research and education. Develop and maintain tools and services to fill gaps in third party solutions to reach production quality cloud federations. Provide consultancy and training for communities on how to build a federated cloud to meet custom community demands under certain constraints. Provide training and support for existing and potential users of cloud federations about topics, such as how to port or develop cloud-native applications; how to operate services in the cloud; or how to join a cloud federation as a provider. Facilitate the reuse of cloud federation tools and services across participating cloud federations to lower total cost of development and to improve cloud sustainability. Promote Platform as a Service (PaaS) and Software as a Service (SaaS) environments that are proven to be robust and reusable across communities to interact with federated IaaS. Provide service management and security oversight for participating clouds and cloud federations. Act as a discussion forum where cloud federations can be discussed and specific questions can be analysed with top-world experts. Organise dissemination and marketing events, workshops and conferences relating to the topics of the collaboration.  If you are interested in joining the EGI FedCloud Task Force, please send an email to fedcloud-tf _at_ mailman.egi.eu introducing yourself.\nWe hold meetings regularly Tuesdays at 11.00 CE(S)T every two weeks. Check our indico category for minutes and upcoming events.\n","excerpt":"The EGI Cloud service offers a multi-cloud IaaS federation that brings together research clouds as a …","ref":"/users/cloud-compute/","title":"Cloud Compute"},{"body":"Connect to CheckIn an IdP federated in an hub and spoke federations I get an error similar to: \u0026ldquo;Error - No connection between institution and service\u0026rdquo; (SURFconext example) In case of a \u0026ldquo;hub and spoke\u0026rdquo; federation the federation coordinator may require that the IdP administrators explicitly request to connect to a SP and let their users to authenticate on these SP.\nIn most of the cases this is not a configuration problem neither for the CheckIn service nor for the Identity provider. The connection needs to be implemented in the hub and spoke IdP Proxy.\nOne example of such federation is SURFconext, the national IdP federation for research and education in the Netherlands operated by SURFnet. If you are using credentials from a Dutch IdP in eduGAIN, you or your IdP administrators need to request the connection. The following steps will lead you to perform the connection:\n Connect to SURFconext dashboard Search for \u0026ldquo;EGI AAI Service provider proxy\u0026rdquo;  If the service does not show in the search, you need to ask SURFnet to add it in the dashboard, please write to support at surfconext dot nl   In the dashboard, near the \u0026ldquo;EGI AAI Service provider proxy\u0026rdquo; there should be a \u0026ldquo;Connect\u0026rdquo; button, this will create a service ticket and the SURFconext team will make the connection active. After you received confirmation that the \u0026ldquo;EGI AAI Service provider proxy\u0026rdquo; is accessible, you will be able to login in CheckIn  Authentication error with ADFS-based Identity Providers Why do I get the error below after successfully authenticating at my Home IdP? opensaml::FatalProfileException at (https://aai.egi.eu/registry.sso/SAML2/POST) SAML response reported an IdP error. Error from identity provider: Status: urn:oasis:names:tc:SAML:2.0:status:Responder The Responder error status is typically returned from ADFS-based IdP implementations (notably Microsoft ADFS 2.0 and ADFS 3.0) that cannot properly handle Scoping elements. Check-in can be configured to omit the scoping element from the authentication requests sent to such IdPs in order to allow successful logins. Please contact the CheckIn support team and include a screenshot of your error.\n","excerpt":"Connect to CheckIn an IdP federated in an hub and spoke federations I get an error similar to: …","ref":"/users/check-in/faq/","title":"FAQ"},{"body":"How do I install library X? You can install new software easily on the notebooks using conda or pip. The %conda and %pip magics can be used in a cell of your notebooks to do so, e.g. installing rdkit:\n%conda install rdkit Once installed you can import the library as usual.\nWarning Any modifications to the libraries/software of your notebooks will be lost when your notebook server is stopped (automatically after 1 hour of inactivity)!  Can I request library X to be installed permanently? Yes! Just let us know what are your needs. You can contact us via:\n Opening a ticket in the EGI Helpdesk, or Creating a Github Issue  We will analyse your request and get back to you.\n","excerpt":"How do I install library X? You can install new software easily on the notebooks using conda or pip. …","ref":"/users/notebooks/faq/","title":"FAQ"},{"body":"Site endpoints must be registered in EGI Configuration Management Database (GOCDB). If you are creating a new site for your cloud services, check the PROC09 Resource Centre Registration and Certification procedure. Services can also coexist within an existing (grid) site.\nThese are the expected services for a working site:\n Site-BDII. This service collects and publishes site's data for the Information System. Existing sites should already have this registered. eu.egi.cloud.accounting. Register here the host sending the records to the accounting repository (executing SSM send). eu.egi.cloud.vm-metadata.vmcatcher for the VMI replication mechanism. Register here the host providing the replication (i.e. the host with cloudkeeper installation)  If offering OCCI interface, sites should register:\n  eu.egi.cloud.vm-management.occi for the OCCI endpoint offered by the site. The endpoint URL must follow this syntax:\nhttps://hostname:port/?image=\u0026lt;image_name\u0026gt;\u0026amp;resource=\u0026lt;resource_name\u0026gt;\nwhere \u0026lt;image_name\u0026gt; and \u0026lt;resource_name\u0026gt; cannot contain spaces. These attributes map to os_tpl and resource_tpl respectively and will be the ones used for monitoring purposes.\n  If offering native OpenStack access (nova), register:\n  org.openstack.nova for the Nova endpoint of the site. The endpoint URL must contain the Keystone v3 URL:\nhttps://hostname:port/url/v3\n  If offering native OpenStack access (swift), register:\n  org.openstack.swift for the swift endpoint of the site. The endpoint URL field must contain Keystone v3 URL:\nhttps://hostname:port/url/v3\n  ","excerpt":"Site endpoints must be registered in EGI Configuration Management Database (GOCDB). If you are …","ref":"/providers/cloud-compute/registration/","title":"GOCDB Registration"},{"body":"The EGI Helpdesk is provides you with the information and support you need to troubleshoot your product and service problems. You can report incidents, bugs or change requests.\nEGI provides support to users and operators through a distributed helpdesk with central coordinating. The central helpdesk provides a single interface for support. The support activities are grouped in first and second level support.\nDocumentation about the EGI Helpdesk is currently available on the EGI Wiki.\n ","excerpt":"The EGI Helpdesk is provides you with the information and support you need to troubleshoot your …","ref":"/internal/helpdesk/","title":"Helpdesk"},{"body":" EGI DataHub service  Overview slides Community Forum   System requirements Official Onedata documentation  Onedata homepage Getting started Source code    ","excerpt":" EGI DataHub service  Overview slides Community Forum   System requirements Official Onedata …","ref":"/users/datahub/links/","title":"Links"},{"body":"Overview Each instance of the FTS3 service, offers a Web monitoring interface, that can be accessed by end-users in order to monitor their submitted transfers and obtain statistics.\nFeatures The Web monitoring can be accessed without user authentication, only access to the transfer log files needs an X.509 user certificate installed on the browser.\nOverview page The Overview page offers a way to access the information about the transfers submitted and executed in the last 6 hours. Users can filter transfers per Virtual Organization, source or destination storage or JobId.\nJob details page By selecting a specific job the information about the job details are displayed. Each transfer part of the job is listed with his own information. From this page it\u0026rsquo;s also possible to access the transfer logs (upon authentication).\nOptimizer page The Optimizer page shows Optimizer information about a specific link, detailing the throughput evolution and the parallel transfer/stream per link at a given time.\n","excerpt":"Overview Each instance of the FTS3 service, offers a Web monitoring interface, that can be accessed …","ref":"/users/data-transfer/monitoring/","title":"Monitoring"},{"body":"Here you can find documentation about the internal architecture and operations of the EGI Notebooks service.\n","excerpt":"Here you can find documentation about the internal architecture and operations of the EGI Notebooks …","ref":"/providers/notebooks/","title":"Notebooks"},{"body":"General recommendations   All files and folders should be lower case;\n  EGI Services should be named exactly as in the EGI Services Portfolio;\n  Acronyms should be used only when it makes sense;\n  Service names should never be replaced by acronyms;\n  In the introduction of services it is appropriate to have a link to the service public page, if any:\n[EGI Cloud Compute](https://www.egi.eu/services/cloud-compute/)   Writing markdown Files have to be written in Markdown, using code compliant with CommonMark and GitHub Flavored Markdown which is based on CommonMark.\nNotable points  Lines should be wrapped at 80 characters. Sentences should be separated by one space only. Indent is made with tabs not with spaces. Indent secondary (and following) level lists with 2 spaces. Lines should end with a Line Feed character (\u0026quot;\\n\u0026rdquo;) Files should end with a Line Feed character (\u0026quot;\\n\u0026rdquo;), but not including an empty line.  Tips Syntax examples that can be used in the files is documented in the syntax section.  Automating formatting and checking Style should be enforced via the usage of Prettier. Prettier can be integrated with various editors.\n With VIM/neovim it can be used via a plugin like ALE as documented on the official documentation. With VScode one should check official documentation  Configuration is provided in .prettierrc, options can be set as follow:\n--print-width 80 --tab-width 2 --prose-wrap always When a Pull Request is received, the proposed changes are checked using various linters.\nAdding exceptions for style violations Successfully passing the checks is a firm requirement, but for some specific cases it\u0026rsquo;s possible to add some tags in the file to by pass the checks.\nThe situation when it\u0026rsquo;s possible to violate the style guide can be:\n long lines due to formatting constructs like tables in-line HTML tags that have to be used in tables or when no other proper solution is available  Warning Exceptions should only be used when there are no other choices, and should be confined to the smallest possible block of markdown code.  Dealing with long lines due to tables Tips Ideally when there is no real interest for having a long table it\u0026rsquo;s better to move to another way of formatting the documentation.  Nevertheless when a table is indeed the proper way to present the data, it can be encapsulated with some specific markdownlint code disabling the line-length check:\n\u0026lt;!-- markdownlint-disable line-length --\u0026gt; | Action | rOCCI | OpenStack | This is a very long column with important data | | ----------- | ------------------------ | ---------------------- | ---------------------------------------------- | | List images | `occi -a list -r os_tpl` | `openstack image list` | Lorem ipsum | \u0026lt;!-- markdownlint-enable line-length --\u0026gt;  Warning In case the table leads to the introduction of scroll bar, please reconsider using another formatting.  Dealing with in-line HTML tags In some specific it\u0026rsquo;s not possible to use anything but in-line HTML tags:\n presentation page leveraging bootstrap CSS classes or with advanced features adding some specific formatting like a list in a cell of a table.  When this is happening the part with the in-line HTML tags should be decorated with the proper markdownlint code disabling the no-inline-html check.\nIn this examples two checks are disabled at the same time: line-length and no-inline-html:\n\u0026lt;!-- markdownlint-disable line-length no-inline-html --\u0026gt; | Action | rOCCI | OpenStack | This is a very long column with important data | | ----------- | ------------------------ | ---------------------- | ---------------------------------------------- | | List images | `occi -a list -r os_tpl` | `openstack image list` | \u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;Lorem\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;ipsum\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt; | \u0026lt;!-- markdownlint-enable line-length no-inline-html --\u0026gt;  Warning Always use the tag that is providing the proper semantic: for a list use \u0026lt;ul\u0026gt; and \u0026lt;li\u0026gt;, not \u0026lt;br /\u0026gt;.  ","excerpt":"General recommendations   All files and folders should be lower case;\n  EGI Services should be named …","ref":"/about/contributing/style/","title":"Style guide"},{"body":"The EGI Application Database (AppDB) includes a web GUI for management of Virtual Machines (VMs) on the federated infrastructure.\nThis GUI is available for a set of selected VOs. If your VO is not listed and you are interested in getting support, please open a ticket or contact us at support _at_ egi.eu.\nMain user features  User identification with Check-in, with customised view of the VAs and resource providers based on the VO membership of the user. Management of VMs in topologies, containing one or more instances of a given VA. Attachment of additional block storage to the VM instances. Start/Stop VMs without destroying the VM (for all VMs of a topology or for individual instances within a topology) Single control of topologies across the whole federation.  Quick start   Log into the VMOps dashboard using EGI Check-in.\n  Click on \u0026quot;Create a new VM Topology\u0026quot; to start the topology builder, this will guide you through a set of steps:\n  Select the Virtual Appliance you want to start, these are the same shown in the AppDB Cloud Marketplace, you can use the search field to find your VA;\n  select the VO to use when instantiating the VA;\n  select the provider where to instantiate the VA; and finally\n  select the template (VM instance type) of the instance that will determine the number of cores, memory and disk space used in your VM.\n    Now you will be presented with a summary page where you can further customise your VM by:\n  Adding more VMs to the topology\n  Adding block storage devices to the VMs\n  Define contextualisation parameters (e.g. add new users, execute some script)\n    Click on \u0026quot;Launch\u0026quot; and your deployment will be submitted to the infrastructure.\n  The topology you just created will appear on your \u0026quot;Topologies\u0026quot; with all the details about it, clicking on a VM of a topology will give you details about its status and IP. VMOps will create a default cloudadm user for you and create ssh-key pair for login (you can create as many users as needed with the contextualisation options of the wizard described above).\n","excerpt":"The EGI Application Database (AppDB) includes a web GUI for management of Virtual Machines (VMs) on …","ref":"/users/cloud-compute/vmops/","title":"VMOps Dashboard"},{"body":"The EGI Cloud Container Compute service allows you to run container-based applications on the providers of the EGI Federated Cloud. There are two main ways of executing containers:\n  Using docker (or a similar container runtime) on a VM, so you can just interact directly with the container runtime to run your applications. This fits simpler applications that can easily fit on one node and are composed by a small number of containers.\n  Using a container orchestration platform, e.g. kubernetes on a set of VMs to manage the applications in an automated way for you. This is usually suited for more complex applications that spawn several nodes and are composed of several containers that need to cooperate to deliver the expected functionality.\n  Follow the guides below to learn more about them.\n","excerpt":"The EGI Cloud Container Compute service allows you to run container-based applications on the …","ref":"/users/cloud-container-compute/","title":"Cloud Container Compute"},{"body":"Hugo, the tool used to generate the static site from the source code, is using goldmark to parse and render markdown.\nIt\u0026rsquo;s compliant with CommonMark and GitHub Flavored Markdown which is also based on CommonMark.\nMarkdown provides various elements, and Hugo adds the support of shortcodes a feature allowing to use templates for easily including or displaying content, from image inclusion to advanced display structures.\nFor references The following shortcodes are available:\n Hugo\u0026rsquo;s shortcodes Docsy theme shortcodes  Linking to another page You can use the path to the other page:\nThis is a link to [another page](../my-other-page). Linking to another section in the same page You need to use an anchor targeting the section name, putting it in lower case and adding dashes to separate words:\nThis is a test of linking to a specic [section](#the-section-header) ## The section header  Second section content. Adding an information or warning message This is achieved using Docsy shortcodes.\nGeneral message The following code:\n{{% pageinfo %}} This is a placeholder. {{% /pageinfo %}} Will render as:\nThis is a placeholder.  Note or information message The following code:\n{{% alert title=\u0026#34;Note\u0026#34; color=\u0026#34;info\u0026#34; %}} This is a Note. {{% /alert %}} Will render as:\nNote This is a Note.  Warning message The following code:\n{{% alert title=\u0026#34;Warning\u0026#34; color=\u0026#34;warning\u0026#34; %}} This is a warning. {{% /alert %}} Will render as:\nWarning This is a warning.  Including file snippets The code should be surrounded with three backticks and include the file type as a parameter.\nThe supported languages are dependant on the syntax highlighter, which depends itself on the mardkown parser.\nNote For Hugo the goldmark parser is used and it relies on the Chroma highlighter.  The list of languages supported by chroma can be found in their GitHub repository.\nThe following code should be used for a shell excerpt:\n```sh ssh-keygen -f fedcloud echo $HOME ``` Will render as:\nssh-keygen -f fedcloud echo $HOME Including images The image files should be stored next to the markdown file that is including them.\nNote The image files should have a meaningful name (like datahub-replica-management.png).  The following code is used to include an image, providing a meaningful alternative text:\n![Viewing file distribution over the Oneproviders](datahub-replica-management.png) ","excerpt":"Hugo, the tool used to generate the static site from the source code, is using goldmark to parse and …","ref":"/about/contributing/syntax/","title":"Syntax"},{"body":"For collaboration purposes, it is best if you create a GitHub account and fork the repository to your own account. Once you do this you will be able to push your changes to your GitHub repository for others to see and use, and it will be easier to send pull requests.\nIf you are new to git and GitHub you are advised to start by the two following articles providing simple tutorials:\n Step by step guide to git Creating pull request with GitHub  GitHub official documentation is available at docs.github.com.\nTips The first-contributions is a repository allowing anyone to freely learn and test creating a real Pull Request to an existing GitHub repository.  Additional documentation about the main steps for working with GitHub is also available in this section.\nThe GitHub flow In order to be able to send code update to the repository you need to:\n fork the repository to your GitHub account clone the repository on your local computer create a feature branch where you will commit your changes push the feature branch to the repository fork in your GitHub account open a Pull Request against the upstream repository  In this process three git repositories are used:\n The upstream repository: EGI-Foundation/documentation Your fork, also named origin: \u0026lt;your_username\u0026gt;/documentation A local clone of your fork, containing references to your fork, its origin and to the upstream repository  Adding an SSH key to your GitHub account The most convenient way to authenticate with GitHub is to use SSH keys over the SSH protocol.\nYou can add an SSH public key to your GitHub account in the Settings on GitHub, at https://github.com/settings/keys.\nRefer to Connecting to GitHub with SSH for an extensive documentation on using SSH keys with GitHub.\nIt\u0026rsquo;s worth to mention that your ssh public keys can easily be retrieved using an URL like https://github.com/\u0026lt;your_username\u0026gt;.keys.\nIn order to manage repositories over ssh, you will will have to clone them via SSH, not HTTPS.\nIf you already have a local clone of a repository created via HTTPS, you can switch it to SSH by following Switching remote URLs from HTTPS to SSH.\nStarting with the GitHub CLI The GitHub Command Line Interface greatly helps with working with GitHub repositories from a terminal.\nIt can be installed using the packages available on their homepage. There is also a manual.\nOnce installed you will have to start by setting up authentication.\n# Authenticate with GitHub gh auth login # Favor ssh protocol gh config set git_protocol ssh Working with repositories The easiest way is to do it via the GitHub CLI that will also clone it locally. But it can also be done via the web interface, using the fork button and then cloning it locally manually.\nForking and cloning This command will fork the repository to your GitHub account and clone a local copy for you to work with.\ngh repo fork EGI-Foundation/documentation Cloning the fork If you want to clone an existing fork you should use:\ngh repo clone \u0026lt;your_username\u0026gt;/documentation Validating the local clone If your local clone of you fork is correctly setup you should see references to the origin and upstream repositories.\n$ git remote -v origin git@github.com:\u0026lt;your_username\u0026gt;/documentation (fetch) origin git@github.com:\u0026lt;your_username\u0026gt;/documentation (push) upstream git@github.com:EGI-Foundation/documentation.git (fetch) upstream git@github.com:EGI-Foundation/documentation.git (push) Running the site locally The documentation webiste is built from the source files using Hugo. The repository README can be used as a reference for building instructions.\nRequirements  mdl hugo NodeJS  postcss-cli autoprofixer    Building and testing To install npm+nodejs please check the instructions at: https://www.npmjs.com/get-npm\nThe rest of the tools can be installed as follows:\ngem install mdl npm install postcss-cli@7.1.2 npm install autoprefixer@9.0 The supported Hugo version packages are available under the binaries folder.\nTo build and run the site, from the repository root\ngit submodule update --init --recursive --depth 1 mdl -s relaxed -s style.rb -r ~MD002,~MD024 content/ # Pick the repository specific to your platform ./binaries/\u0026lt;platform\u0026gt;/hugo server -D The website is available at: http://localhost:1313/.\nBranches and Commits You should submit your patch as a git branch ideally named with a meaningful name related to the changes you want to propose. This is called a feature branch (sometimes also named topic branch). You will commit your modifications to this feature branch and submit a Pull Request (PR) based on the differences between the upstream master branch and your feature branch.\nCreating a feature branch Try to avoid committing changes to the master branch of your clone to simplify management, creating a dedicated feature branch helps a lot. Try to pick a meaningful name for the branch (my_nice_update in the example).\n# This should be done from the up-to-date master branch # Read furthermore to see documentation on updating a local clone git checkout -b my_nice_update Writing changes The documentation being made of plain text files you are free to use whatever text editor or Integrated Development Environment (IDE) suits you, from neovim to Visual Studio Code.\nSome environments may provide you plugins helping with syntax or offering a preview, they are worth checking.\nBe sure to commit files with having been formated using Prettier as documented in our style guide.\nCommitting changes It is the best practice to have your commit message have a summary line that includes the issue number, followed by an empty line and then a brief description of the commit. This also helps other contributors understand the purpose of changes to the code.\n#3 - platform_family and style * use platform_family for platform checking * update notifies syntax to \u0026#34;resource_type[resource_name]\u0026#34; instead of resources() lookup * GH-692 - delete config files dropped off by packages in conf.d * dropped debian 4 support because all other platforms have the same values, and it is older than \u0026#34;old stable\u0026#34; debian release # Select the modified files to be committed git add files1 path2/ # Commit the changes git commit -m \u0026lt;commit_message\u0026gt; Pushing the feature branch to the fork for preparing a PR From inside a feature branch you can push it to your remote fork.\n# Ask git to keep trace of the link between local and remote branches git push --set-upstream Once done git output will show a URL that you can click to generate a Pull Request (PR).\nAccessing GitHub upstream or fork repositories may also propose you to submit a PR.\nIf needed GitHub CLI can also be used to prepare the PR:\ngh pr create \u0026lt;your_username\u0026gt;:\u0026lt;feature_branch\u0026gt; --web Updating the local feature branch with changes made on the PR Once you PR have been opened it will be reviewed, and reviewers can propose and commit changes to your PR. If you need to make further changes be sure to update the local clone with the remote changes.\n# Retrieve changes made on your PR in the upstream repository git pull Then you can commit new changes and push them to your remote fork.\nUpdating a repository clone with the upstream changes # If you are still in a branch created for a previous PR, move to master git checkout master # Get the latest data from the upstream repository git fetch upstream # Update your local copy with this data git rebase upstream/master master # Update your remote GitHub fork with those changes git push Updating a local feature branch with changes made on the master branch In case the master branch evolved since the feature branch was created, it may be required to merge the new changes in the feature branch.\nIt can easily be done via the PR page on the GitHub web interface, but it can also be done in your repository clone using git rebase.\n# Retrieve changes made in the upstream repository git fetch upstream # Check out the feature branch git checkout feature_branch # Apply the new changes on main to your feature branch git rebase upstream/master In case some files have been changed on both sides you will will have to merge the conflicts manually.\nCloning a Pull Request to edit, test and review it locally It\u0026rsquo;s possible to clone a Pull Request to a local branch to test it locally. It\u0026rsquo;s done using the PR number.\n# List available PR and their identifiers. gh pr list # Clone specific PR gh pr checkout XX Once done it\u0026rsquo;s possible to build and run the site locally:\n# From the root of the repository clone # Here on MacOS X, adapt depending on your platform ./binaries/macos64/hugo server -D The documentation will then be accessible on http://localhost:1313.\n People having write access to the repository hosting the branch related to the PR (ie. usually the PR author) will be able to add and edit files.\n # From the local clone of the repository gh pr checkout XXX vim yyy.zz git add yyy.zz git commit yyy.zz -m \u0026lt;commit_message\u0026gt; git push Updating a local clone of a PR # It will ask you to merge changes git pull Then you can refer to the README.md to see how to test it locally.\nIn case the PR got commits that were forced pushed you may have troubles, in that case it may be easier to delete the local branch and do another checkout of the PR.\nCleaning a local clone of a PR In case you have troubles updating the local clone, as it can happens if changes were forced pushed to it, it maybe easier to delete the local copy of the PR and recreate it.\n# Switch to main branch git checkout master # Check local branches git branch -vv # Delete a specific branch git branch -d \u0026lt;branch_name\u0026gt; # If you need to force the deletion use -D git branch -D \u0026lt;branch_name\u0026gt; Using git stash to save changes for later usage Sometimes we realise just before committing a change that we are not in the correct branch (ie. that we forgot to create a dedicated feature branch), when this happens git stash can be helpful.\n# Saving a change git stash save \u0026lt;optional message\u0026gt; # Creating the forgotten branch git checkout -b \u0026lt;my_feature_branch\u0026gt; # Reviewing the saved changes, use TAB completion git stash show \u0026lt;TAB\u0026gt; # Applying the saved changes, use TAB completion git stash pop \u0026lt;TAB\u0026gt; # Review the changes to be committed git diff If you already committed your change(s) you may have to look at git reset.\n# Viewing the diff of the two last commits git log -n 2 -p # Reverting the last change, keeping the change in the local directory git reset HEAD^ ","excerpt":"For collaboration purposes, it is best if you create a GitHub account and fork the repository to …","ref":"/about/contributing/git/","title":"Using Git and GitHub"},{"body":"OpenStack providers of the EGI Cloud Compute service offer native OpenStack features via native APIs integrated with EGI Check-in accounts.\nThe extensive OpenStack user documentation includes details on every OpenStack project, most providers offer access to:\n keystone, for identity nova, for VM management glance, for VM image management cinder, for block storage neutron, for network management horizon, as a web dashboard  Web-dashboard of the integrated providers can be accessed using your EGI Check-in credentials directly: select OpenID Connect or EGI Check-in in the Authenticate using drop-down menu of the login screen. You can explore Horizon dashboard documentation for more information on how to manage your resources from the browser. The rest of this guide will focus on CLI/API access.\nInstallation TBC\npip install requests pip install openstackclient  jq to easily manage JSON output  Add IGTF CA to python's CA store:\ncat /etc/grid-security/certificates/*.pem \u0026gt;\u0026gt; $(python -m requests.certs) Authentication Check the documentation at the authentication and authorisation sectionon how to get the right credentials for accessing the providers.\nOpenStack token for other clients Most OpenStack clients allow authentication with tokens, so you can easily use them with EGI Cloud providers just doing a first step for obtaining the token. With the OpenStack client you can use the following command to set the OS_TOKEN variable with the needed token:\n$ OS_TOKEN=$(openstack --os-auth-type v3oidcaccesstoken \\  --os-protocol openid --os-identity-provider egi.eu \\  --os-auth-url \u0026lt;keystone url\u0026gt; \\  --os-access-token \u0026lt;your access token\u0026gt; \\  --os-project-id \u0026lt;your project id\u0026gt; token issue -c id -f value) You can refresh the access token and obtain an OpenStack token with the egicli command:\n# Export OIDC env export CHECKIN_CLIENT_ID=\u0026lt;CLIENT_ID\u0026gt; export CHECKIN_CLIENT_SECRET=\u0026lt;CLIENT_SECRET\u0026gt; export CHECKIN_REFRESH_TOKEN=\u0026lt;REFRESH_TOKEN\u0026gt; # Retrieve project ID export OS_PROJECT_ID=\u0026lt;PROJECT_ID\u0026gt; # Retrieve OpenStack token eval \u0026#34;$(egicli endpoint token --site \u0026lt;name of the site\u0026gt;)\u0026#34; echo $OS_TOKEN Useful commands with OpenStack CLI Please refer to the nova documentation for a complete guide on the VM management features of OpenStack. We list in the sections below some useful commands for the EGI Cloud.\nRegistering an existing ssh key It's possible to register an ssh key that can later be used as the default ssh key for the default user of the VM (via the --key-name argument to openstack server create:\nopenstack keypair create --public-key ~/.ssh/id_rsa.pub mykey Creating a VM openstack flavor list FLAVOR=\u0026lt;FLAVOR_NAME\u0026gt; openstack image list IMAGE_ID=\u0026lt;IMAGE_ID\u0026gt; openstack network list # Pick FedCloud network NETWORK_ID=\u0026lt;NETOWRK_ID\u0026gt; openstack security group list openstack server create --flavor $FLAVOR --image $IMAGE_ID \\  --nic net-id=$NETWORK_ID --security-group default \\  --key-name mykey oneprovider # Creating a floating IP openstack floating ip create \u0026lt;NETOWRK_NAME\u0026gt; # Assigning floating IP to server openstack server add floating ip \u0026lt;SERVER_ID\u0026gt; \u0026lt;IP\u0026gt; # Removing floating IP from server openstack server show \u0026lt;SERVER_ID\u0026gt; # Deleting server openstack server remove floating ip \u0026lt;SERVER_ID\u0026gt; \u0026lt;IP\u0026gt; openstack server delete \u0026lt;SERVER_ID\u0026gt; # Deleting floating IP openstack floating ip delete \u0026lt;IP\u0026gt;  OpenStack: launch an instance on the provider network OpenStack: Manging IP addresses  Using cloud-init openstack server create --flavor m3.medium \\  --image d0a89aa8-9644-408d-a023-4dcc1148ca01 \\  --user-data userdata.txt --key-name My_Key server01.example.com  OpenStack: providing user data (cloud-init) cloudinit documentation  Shell script data as user data #!/bin/sh adduser --disabled-password --gecos \u0026#34;\u0026#34; clouduser cloud-config data as user data #cloud-confighostname:mynodefqdn:mynode.example.commanage_etc_hosts:true Official cloud-config examples Cloud-init example  Creating a snapshot image from running VM You can create a new image from a snapshot of an existing VM that will allow you to easily recover a previous version of your VM or to use it as a template to clone a given VM.\nopenstack server image create \u0026lt;your VM\u0026gt; --name \u0026lt;name of the snapshot\u0026gt; Once the snapshot is ready (openstack image show \u0026lt;name of the snapshot\u0026gt; will give your the details you can use it as any other image at the provider:\nopenstack server create --flavor \u0026lt;flavor\u0026gt; \\  --image \u0026lt;name of the snapshot\u0026gt; \\  \u0026lt;name of the new VM\u0026gt; You can override files in the snapshot if needed, e.g. changing the SSH keys:\nopenstack server create --flavor \u0026lt;flavor\u0026gt; \\  --image \u0026lt;name of the snapshot\u0026gt; \\  --file /home/ubuntu/.ssh/authorized_keys=my_new_keys \\  \u0026lt;name of the new VM\u0026gt; Terraform Terraform supports EGI Cloud OpenStack providers by using valid access tokens for Keystone. For using this, just configure your provider as usual in Terraform, but do not include user/password information:\n# Configure the OpenStack Provider provider \u0026#34;openstack\u0026#34; { project_id = \u0026#34;\u0026lt;your project id\u0026gt;\u0026#34; auth_url = \u0026#34;http://\u0026lt;your keystone url\u0026gt;/v3\u0026#34; }# Create a server resource \u0026#34;openstack_compute_instance_v2\u0026#34; \u0026#34;test-server\u0026#34; {# ... } when launching Terraform, set the OS_TOKEN environment variable to a valid token as shown in :ref:OpenStack token for other clients. You may also set the Keystone URL and project id in the OS_AUTH_URL and OS_PROJECT_ID environment variables:\nprovider \u0026#34;openstack\u0026#34; { } data \u0026#34;openstack_images_image_v2\u0026#34; \u0026#34;ubuntu16\u0026#34; { most_recent = true properties { APPLIANCE_MPURI = \u0026#34;https://appdb.egi.eu/store/vo/image/8df7ba00-8467-57aa-bf1e-05754a2a73bf:6428/\u0026#34; } } data \u0026#34;openstack_compute_flavor_v2\u0026#34; \u0026#34;small\u0026#34; { vcpus = 1 ram = 2048 disk = 20 } resource \u0026#34;openstack_compute_instance_v2\u0026#34; \u0026#34;vm\u0026#34; { name = \u0026#34;testvm\u0026#34; image_id = \u0026#34;${data.openstack_images_image_v2.ubuntu16.id}\u0026#34; flavor_id = \u0026#34;${data.openstack_compute_flavor_v2.small.id}\u0026#34; security_groups = [\u0026#34;default\u0026#34;] } $ export CHECKIN_CLIENT_ID=\u0026lt;CLIENT_ID\u0026gt; $ export CHECKIN_CLIENT_SECRET=\u0026lt;CLIENT_SECRET\u0026gt; $ export CHECKIN_REFRESH_TOKEN=\u0026lt;REFRESH_TOKEN\u0026gt; $ export OS_AUTH_URL=\u0026lt;OPENSTACK_URL\u0026gt; $ export OS_PROJECT_ID=\u0026lt;PROJECT_ID\u0026gt; $ export OS_TOKEN=$(python get-token.py) $ terraform plan Refreshing Terraform state in-memory prior to plan... The refreshed state will be used to calculate this plan, but will not be persisted to local or remote state storage. data.openstack_compute_flavor_v2.small: Refreshing state... data.openstack_images_image_v2.ubuntu16: Refreshing state... ------------------------------------------------------------------------ An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: + openstack_compute_instance_v2.vm id: \u0026lt;computed\u0026gt; access_ip_v4: \u0026lt;computed\u0026gt; access_ip_v6: \u0026lt;computed\u0026gt; all_metadata.%: \u0026lt;computed\u0026gt; availability_zone: \u0026lt;computed\u0026gt; flavor_id: \u0026#34;2\u0026#34; flavor_name: \u0026lt;computed\u0026gt; force_delete: \u0026#34;false\u0026#34; image_id: \u0026#34;ceb0434d-37af-4d1f-9efe-13f6f9937df2\u0026#34; image_name: \u0026lt;computed\u0026gt; name: \u0026#34;testvm\u0026#34; network.#: \u0026lt;computed\u0026gt; power_state: \u0026#34;active\u0026#34; region: \u0026lt;computed\u0026gt; security_groups.#: \u0026#34;1\u0026#34; security_groups.3814588639: \u0026#34;default\u0026#34; stop_before_destroy: \u0026#34;false\u0026#34; Plan: 1 to add, 0 to change, 0 to destroy. ------------------------------------------------------------------------ Note: You didn\u0026#39;t specify an \u0026#34;-out\u0026#34; parameter to save this plan, so Terraform can\u0026#39;t guarantee that exactly these actions will be performed if \u0026#34;terraform apply\u0026#34; is subsequently run. Note that as in the example above you can get images using information from AppDB if needed.\nlibcloud Apache libcloud support OpenStack and EGI authentication mechanisms by setting the ex_force_auth_version to 3.x_oidc_access_token or 2.0_voms respectively. Check the libcloud docs on connecting to OpenStack for details. See below two code samples for using them\nOpenID Connect import requests from libcloud.compute.types import Provider from libcloud.compute.providers import get_driver refresh_data = { \u0026#39;client_id\u0026#39;: \u0026#39;\u0026lt;your client_id\u0026gt;\u0026#39;, \u0026#39;client_secret\u0026#39;: \u0026#39;\u0026lt;your client_secret\u0026gt;\u0026#39;, \u0026#39;grant_type\u0026#39;: \u0026#39;refresh_token\u0026#39;, \u0026#39;refresh_token\u0026#39;: \u0026#39;\u0026lt;your refresh_token\u0026gt;\u0026#39;, \u0026#39;scope\u0026#39;: \u0026#39;openid email profile\u0026#39;, } r = requests.post(\u0026#34;https://aai.egi.eu/oidc/token\u0026#34;, auth=(client_id, client_secret), data=refresh_data) access_token = r.json()[\u0026#39;access_token\u0026#39;] OpenStack = get_driver(Provider.OPENSTACK) # first parameter is the identity provider: \u0026#34;egi.eu\u0026#34; # Second parameter is the access_token # The protocol \u0026#39;openid\u0026#39; is specified in ex_tenant_name # and tenant/project cannot be selected :( driver = OpenStack(\u0026#39;egi.eu\u0026#39;, access_token, ex_tenant_name=\u0026#39;openid\u0026#39;, ex_force_auth_url=\u0026#39;https://keystone_url:5000\u0026#39;, ex_force_auth_version=\u0026#39;3.x_oidc_access_token\u0026#39;) VOMS from libcloud.compute.types import Provider from libcloud.compute.providers import get_driver OpenStack = get_driver(Provider.OPENSTACK) # assume your proxy is available at /tmp/x509up_u1000 # you can obtain a proxy with the voms-proxy-init command # no need for username driver = OpenStack(None, \u0026#39;/tmp/x509up_u1000\u0026#39;, ex_tenant_name=\u0026#39;EGI_FCTF\u0026#39;, ex_force_auth_url=\u0026#39;https://sbgcloud.in2p3.fr:5000\u0026#39;, ex_force_auth_version=\u0026#39;2.0_voms\u0026#39;) ","excerpt":"OpenStack providers of the EGI Cloud Compute service offer native OpenStack features via native APIs …","ref":"/users/cloud-compute/openstack/","title":"Using OpenStack providers"},{"body":"This section provides the needed steps for supporting a new VO in your infrastructure\nEGI AAI OpenStack The usual method of supporting a VO is by creating a local project for it. You should assign quotas to this project as agreed in the OLA defining the support for the given VO.\nCheck-in VOs (OpenID Connect) Follow these steps if you are using OpenID Connect to integrate with EGI:\n  Create a group where users belongig to the VO will be mapped to: :\ngroup_id=$(openstack group create -f value -c id \u0026lt;new_group\u0026gt;)   Add that group to the desired local project: :\nopenstack role add member --group $group_id --project \u0026lt;your project\u0026gt;   Expand your mapping.json with the VO membership to the created group (substitute group_id and vo_name as appropriate): :\n[ \u0026lt;existing mappings\u0026gt;, { \u0026#34;local\u0026#34;: [ { \u0026#34;user\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;{0}\u0026#34; }, \u0026#34;group\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;\u0026lt;group_id\u0026gt;\u0026#34; } } ], \u0026#34;remote\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;HTTP_OIDC_SUB\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;HTTP_OIDC_ISS\u0026#34;, \u0026#34;any_one_of\u0026#34;: [ \u0026#34;https://aai-dev.egi.eu/oidc/\u0026#34; ] }, { \u0026#34;type\u0026#34;: \u0026#34;OIDC-eduperson_entitlement\u0026#34;, \u0026#34;regex\u0026#34;: true, \u0026#34;any_one_of\u0026#34;: [ \u0026#34;^urn:mace:egi.eu:group:\u0026lt;vo_name\u0026gt;:role=vm_operator#aai.egi.eu$\u0026#34; ] } ] } ]   Update the mapping in your Keystone IdP: :\nopenstack mapping set --rules mapping.json egi-mapping   Legacy VOs (VOMS) When using the Keystone-VOMS module, you should follow these steps:\n  Configure your LSC files according to the VOMS documentation, e.g.: :\nmkdir -p /etc/grid-security/vomsdir/ops cat \u0026gt; /etc/grid-security/vomsdir/ops/lcg-voms2.cern.ch.lsc \u0026lt;\u0026lt; EOF /DC=ch/DC=cern/OU=computers/CN=lcg-voms2.cern.ch /DC=ch/DC=cern/CN=CERN Grid Certification Authority EOF cat \u0026gt; /etc/grid-security/vomsdir/ops/voms2.cern.ch.lsc \u0026lt;\u0026lt; EOF /DC=ch/DC=cern/OU=computers/CN=voms2.cern.ch /DC=ch/DC=cern/CN=CERN Grid Certification Authority EOF   Add the mapping to your voms.json mapping. It must be proper JSON (you can check its correctness online or with python -mjson.tool /etc/keystone/voms.json). Edit the file, and add an entry like this:\n{ \u0026#34;\u0026lt;voname|FQAN\u0026gt;\u0026#34;: { \u0026#34;tenant\u0026#34;: \u0026#34;\u0026lt;project_name\u0026gt;\u0026#34; } } Note that you can use the FQAN from the incoming proxy, so you can map a group within a VO into a tenant, like this:\n{ \u0026#34;dteam\u0026#34;: { \u0026#34;tenant\u0026#34;: \u0026#34;dteam\u0026#34; }, \u0026#34;/dteam/NGI_IBERGRID\u0026#34;: { \u0026#34;tenant\u0026#34;: \u0026#34;dteam_ibergrid\u0026#34; } }   Restart Apache server, and it's done.\n  OpenNebula TBC\nEGI Accounting OpenStack Add the project supporting the VO to cASO:\n  projects in /etc/caso/caso.conf :\nprojects = vo_project1, vo_project2, \u0026lt;your_new_vo_project\u0026gt;   as a new mapping in /etc/caso/voms.json :\n{ \u0026#34;\u0026lt;your new vo\u0026gt;\u0026#34;: { \u0026#34;projects\u0026#34;: [\u0026#34;\u0026lt;your new vo project\u0026gt;\u0026#34;] } }   Be sure to include the user running cASO as member of the project if it does not have admin privileges:\nopenstack role add member --user \u0026lt;your caso user\u0026gt; --project \u0026lt;your new vo project\u0026gt; OpenNebula Update /etc/oneacct-export/groups.include or /etc/oneacct-export/groups.exclude to allow extracting information from the new group. Specify one group name per line.\nEGI Information System OpenStack Add the user configured in your cloud-info-provider as member of the new project:\nopenstack role add member \\  --user \u0026lt;your cloud-info-provider user\u0026gt; \\  --project \u0026lt;your new vo project\u0026gt; EGI VM Image Management cloudkeeper-core Add the new image list to the cloudkeeper configuration in /etc/cloudkeeper/cloudkeeper.yml (or /etc/cloudkeeper/image-lists.conf if using the appliance), new entry should look similar to:\nhttps://\u0026lt;APPDB_TOKEN\u0026gt;:x-oauth-basic@vmcaster.appdb.egi.eu/store/vo/\u0026lt;your new vo\u0026gt;/image.list\nOpenStack Add the user configured in cloudkeeper-os as member of the new project:\nopenstack role add member \\  --user \u0026lt;your cloudkeeper-os user\u0026gt; \\  --project \u0026lt;your new vo project\u0026gt; Add the mapping of the project to the VO in /etc/cloudkeeper-os/voms.json:\n{ \u0026#34;\u0026lt;your new vo\u0026gt;\u0026#34;: { \u0026#34;tenant\u0026#34;: \u0026#34;\u0026lt;your new vo project\u0026gt;\u0026#34; } } ","excerpt":"This section provides the needed steps for supporting a new VO in your infrastructure\nEGI AAI …","ref":"/providers/cloud-compute/configuration/","title":"VO Configuration"},{"body":"Grid Storage Grid Storage allows you to store data in a reliable and high-quality environment and share it across distributed teams. Your data can be accessed through different protocols and can be replicated across different providers to increase fault-tolerance. Grid Storage gives you complete control over the data you share and with whom. Main features:\n Access highly-scalable storage from anywhere Control the data you share Organise your data using a flexible hierarchical structure  Grid Storage file access is based on gridFTP and WebDav/HTTP protocols together with XRootD and legacy SRM (under deprecation at some of the endpoints).\nSeveral Grid storage implementation are available on the infrastructure, the most common are the following:\n dCache DPM StoRM  Endpoint Discovery The Storage endpoints that are available to user\u0026rsquo;s Virtual Organizations are discoverable via the EGI Information System (BDII).\nThe lcg-infosites command can be used to obtain VO-specific information on existing grid storages\nThe syntax is the following:\nlcg-infosites --vo voname -[v] -f [site name] [option(s)] [-h| --help] [--is BDII] For example, to list the Storage Elements (SEs) available to the biomed VO one could issue the following command:\nlcg-infosites --vo biomed se lcg-infosites --vo biomed se Avail Space(kB) Used Space(kB) Type SE ------------------------------------------ 280375465082 n.a SRM ccsrm.ihep.ac.cn 10995116266 11 SRM cirigridse01.univ-bpclermont.fr Client access The access via client requires the user to obtain a valid X.509 user VOMS proxy. Please refer to the Check-in doc for more information. Integration with OpenID Connect and the EGI Check-in service is under piloting at some of the endpoints on the infrastructure , but it has not yet reached the production stage.\nThe client widely used to access grid-storage is gfal2 which is available for installation both on RHEL and Debian compatible systems.\nIn particular, gfal2 provides and abstraction layer on top of several storage protocols (XRootD, WebDAV, SRM, gsiftp, etc) and therefore is quite convenient as the same API can be used to access different protocols.\nThe gfal2 CLI can be installed as follows (for RHEL compatible systems):\nyum install gfal2-util gfal2-all where gfal2-all will install all the plug-ins to deal with all the available protocols.\nIn the following example the command to access storages via gfal2 are documented. Please note that the access via gsiftp protocol in the following example can be replaced by any other supported protocols\nList files on a given endpoint:\ngfal-ls gsiftp://dcache-door-doma01.desy.de/dteam 1G.header-1 domatest gb SSE-demo test tpctest Create a folder:\ngfal-mkdir gsiftp://dcache-door-doma01.desy.de/dteam/test Copy a local file:\ngfal-copy test.json gsiftp://dcache-door-doma01.desy.de/dteam/test Copying file:///root/Documents/test.json [DONE] after 0s Copy files between storages:\ngfal-copy gsiftp://prometheus.desy.de/VOs/dteam/public-file gsiftp://dcache-door-doma01.desy.de/dteam/test Copying gsiftp://prometheus.desy.de/VOs/dteam/public-file [DONE] after 3s Download a file to a local folder:\ngfal-copy gsiftp://prometheus.desy.de/VOs/dteam/public-file /tmp Copying gsiftp://prometheus.desy.de/VOs/dteam/public-file [DONE] after 0s Delete a file:\ngfal-rm gsiftp://dcache-door-doma01.desy.de/dteam/test/public-file gsiftp://dcache-door-doma01.desy.de/dteam/test/public-file DELETED More commands are available, please refer to the gfal2-util documentation\nAccess via the EGI Data Transfer service The EGI Data Transfer service provides mechanism to optimize the transfer of files between EGI Online storage endpoints. Both a graphical interface and CLI are available to perform bulk movement of data. Please check the related documentation for more information.\nIntegration with Data Management frameworks Grid Storage access most of the time is hidden to users by the integration performed within the Data Management framework used by Collaborations and Experiments.\nIn EGI for instance, the EGI Workload Management System EGI Workload Manager, provides a way to efficiently access grid storage endpoints in order to read and store files on the infrastructures and to catalogue the existing file and related location.\nThe users when running computation via DIRAC does not actually access the storage directly, but they can of course retrieve the output of the computation which has been stored by the system on the grid.\n","excerpt":"Grid Storage Grid Storage allows you to store data in a reliable and high-quality environment and …","ref":"/users/online-storage/grid-storage/","title":"Grid Storage"},{"body":"Object Storage Object storage is a standalone service that stores data as sets of individual objects organized within containers. Each object has its own URL, which can be used to access the resource, to share the file with other people, and to setup custom metadata and access control lists. These objects are accessed and managed via a REST API. There is virtually no limit to the amount of data you can store, only the space used is accounted, you can access the data from any location (from any VM running at any EGI provider or even from other cloud providers or from your own laptop/browser), you can expose the data via external portals (using HTTP as transport protocol), you can set access control lists per container and even make the data publicly available. On the other hand, data is accessed via a API requests, thus integration with existing applications may require a change to the application logic.\nUsage from your application The Object storage in EGI is offered via OpenStack SWIFT deployments on some of the EGI Cloud providers.\nAvailable SWIFT providers resources can be discovered in GOCDB.\nFor accessing the endpoint check the URL of the specific provider.\nOpenStack SWIFT offers a RESTful API to manage your storage and you can manage it via the OpenStack CLI or web dashboard. Check the complete OpenStack object store API for more information. More advanced usage include access via the S3 protocol and the EGI Data Transfer Service which are also described in the following sections.\nAccess via Openstack CLI The Openstack CLI can be used to perform operations over the SWIFT endpoints available on the infrastructure.\nFirst the Openstack environment needs to be properly setup, and for this purpose the egicli components is quite handy. For instance to setup the access to the SWIFT endpoint at IFCA-LCG2 via the Pilot VO (vo.access.egi.eu) the following is needed:\negicli endpoint projects --site IFCA-LCG2 id Name enabled site -------------------------------- ------------------------- --------- --------- 13c11c4073f4456fac7df84c4eb8f85b VO:vo.nextgeoss.eu True IFCA-LCG2 5eb8959a799240a98f4f303f5fbd80be VO:dteam True IFCA-LCG2 9170e65775964a3ba6b18d83a2ad1968 eosc-hub.eu:d4science.org True IFCA-LCG2 999f045cb1ff4684a15ebb338af69460 VO:vo.access.egi.eu True IFCA-LCG2 f1d0308880134d04964097524eace710 VO:training.egi.eu True IFCA-LCG2 and then simply\neval \u0026#34;$(egicli endpoint env --site IFCA-LCG2 --project-id 999f045cb1ff4684a15ebb338af69460)\u0026#34; Now the Openstack CLI can be used to perform operations on the SWIFT endpoint.\nStarting from listing the available containers(buckets):\nopenstack container list +------------------+ | Name | +------------------+ | egi_endorsed_vas | +------------------+ Creating a new container:\nopenstack container create test-egi +---------+-----------+------------------------------------------------------+ | account | container | x-trans-id | +---------+-----------+------------------------------------------------------+ | v1 | test-egi | tx000000000000000000afc-005f845160-2bb3ed4-RegionOne | +---------+-----------+------------------------------------------------------+ Creating a new Object by uploading a file:\nopenstack object create test-egi file1.txt +-----------+-----------+----------------------------------+ | object | container | etag | +-----------+-----------+----------------------------------+ | file1.txt | test-egi | 5bbf5a52328e7439ae6e719dfe712200 | +-----------+-----------+----------------------------------+ Listing objects inside a container:\nopenstack object list test-egi +-----------+ | Name | +-----------+ | file1.txt | +-----------+ Download an object:\nopenstack object save test-egi file1.txt Removing an object from the container:\nopenstack object delete test-egi file1.txt Removing the entire container (-r option for recursive):\nopenstack container delete test-egi Access via S3 protocol Openstack SWIFT is compatible with S3 protocol, therefore if the SWIFT deployment are properly configured they can be accessed as any other S3 compatible storage.\nIn order to access the storage via S3 you need to create first the EC2 credentials from the Openstack deployment.\nThe following command is needed:\nopenstack ec2 credentials create +------------+------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +------------+------------------------------------------------------------------------------------------------------------------------------------------+ | access | zxxxxxxxxxxxxxxxxxxxxxxxxxx | | links | {\u0026#39;self\u0026#39;: \u0026#39;https://api.cloud.ifca.es:5000/v3/users/5495cd688ad7401b8e87b46bdea92f33/credentials/OS-EC2/xxxxxxxxxxxxxxxxx\u0026#39;} | | project_id | 999f045cb1ff4684a15ebb338af69460 | | secret | xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx | | trust_id | None | | user_id | xxxxxxxxxxxxxxxxxxxxxxxxxxxx | +------------+------------------------------------------------------------------------------------------------------------------------------------------+ The access and secret values are needed in order to access the SWIFT via the S3 protocol\nA lot of clients are available to access S3 compatible storages (awscli, s3cmd, etc). In EGI we are using the Davix client, which has been developed at CERN and is available both in RHEL and Debian environments.\nIn order to list via S3 protocol the SWIFT server just type:\ndavix-ls --s3accesskey \u0026#39;access\u0026#39; --s3secretkey \u0026#39;secret\u0026#39; --s3alternate s3s://api.cloud.ifca.es:8080/swift/v1/test-egi davix-get, davix-put and davix-del are also available to download, store and delete objects from the storage.\nAccess via the EGI Data Transfer The EGI Data Transfer can be also configured to move file to/from Object storages using the S3 protocol.\nThis will require to upload the EC2 access keys to the EGI Data Transfer service, which will be then entitled to generate the proper signed URL to access the storage.\nPlease contact the support (support_at_egi_dot_eu) in order to have more details.\n","excerpt":"Object Storage Object storage is a standalone service that stores data as sets of individual objects …","ref":"/users/online-storage/object-storage/","title":"Object Storage"},{"body":"The EGI Online Storage includes a wide category of services which allows storing, sharing and accessing files on the EGI infrastructure. The service comprises different categories of storage services depending on the technology and usage that is foreseen. The 3 following service offerings are available:\n Grid Storage Object Storage Block Storage, which is described under the Cloud Compute section  A summary of the main differences between Grid, Block and Object Storage is reported in the following table.\n   Access Sharing Accounting Usage     Grid Storage from any device connected to the internet Available for the data stored Grid protocols and HTTP/Webdav requests   Block Storage only from within a VM only at the same site the VM is located Not possible for the entire block POSIX access, use as local disk   Object Storage from any device connected to the internet Possible only for the data stored via HTTP requests to server    Grid Storage is mainly serving data access and storage for EGI High Throughput Compute scenarios. For EGI Federated Cloud use cases it depends on the application needs either Block or Object storage could be use. In general, block storage is a good and simple solution for temporary data and data which you do not need to share beside the single application running on a single VM. If you need to have your data exposed within portals or shared between different steps of your processing workflow, it is usually best to use the object storage.\n","excerpt":"The EGI Online Storage includes a wide category of services which allows storing, sharing and …","ref":"/users/online-storage/","title":"Online Storage"},{"body":"What is High Throughput Compute? High Throughput Compute (HTC) can be described as computing paradigm that focuses on the efficient execution of a large number of loosely-coupled tasks (that could be data analysis tasks, also computing jobs for analysing data or other similar tasks). HTC systems are independent jobs that can be individually scheduled on many different computing resources across multiple administrative boundaries. Users usually submit these tasks to the infrastructure as jobs and once the jobs have been scheduled and executed in the distributed resources of the infrastructure, the user can collect the output from the services that have executed their jobs.\nThe EGI High Throughput Compute service is provided by a distributed network of computing centres, accessible via a standard interface and membership of a Virtual Organisation.\nThe EGI High Throughput Compute Infrastructure The EGI High Throughput Compute infrastructure is the federation of GRID resources provided by EGI providers, that aims to share and federate in a secure way distributed IT resources as part of the EGI infrastructure. It comprises:\n Computer resources \u0026ndash; execution environment of computing tasks in clusters distributed in many different resource centers over Europe and outside Europe ; Data infrastructure \u0026ndash; storage servers where users can upload and download their data/files in a distributed manner in the different resource centers Federated operations \u0026ndash; a set of federated operations that are constituted of global tasks (central activities/ services, e.g., AAI, accounting, helpdesk) that are needed to federate the heterogeneous resources from different resource centers and their operation activities that are carried out by the different NGIs. User support \u0026ndash; NGIs also carry out user support. EGI.eu provides the central user support and coordinates NGIs’ support activities.  Target Users The target customers for EGI High Throughput Compute service are research communities who need to share, store, process, and produce large sets of data. Typically, their research collaborations involve different organizations across Europe and the world. They may already have local resources, for example, universities, and research institutions, and these local resources normally can only be accessed by local users, according to the organisational authentication rules and access policies. For example, university researchers can go to their IT department and ask for grant access to the university cluster. However, when researchers join collaborations that need to share their research activities, data collections, repositories among different organisations, they will need more homogenous and coordinated operation of the resources that are not currently uniformly accessible. In addition, nowadays, many researcher collaborations generate a big amount of data, and managing such big data is time consuming and error prone.\nThe EGI High Throughput Compute not only provides the basic access to resources but also offers a set of high-level tools allowing users to manage a large amount of data in a collaborative, for example, there are authorization and access control tools that can be regulated by the research collaboration in a central manner and uniformly distributed in the distributed infrastructure. And there are also tools to handle and manage a big amount of data (to move data, to create data catalogs for the distributed datasets, to balance the execution workloads, etc.).\nMain features EGI High Throughput Compute provides easy access to shared computing and data services from independent resource providers in a uniform way optimizing usage. Most software deployed in the distributed resources centers are based on open standards, and are open source middleware services. Resource access is based on Virtual Organisation (VO). VOs are fully managed by communities allowing them to manage their users and grant control access to their services and resources. In order to optimize the usage of the resources, users can have opportunistic usage of unused resources. This means users can either own their resources and use EGI services to federate them and have easy access to them or use the resources already available in the EGI infrastructure. The opportunity resources are not dedicated to the users’ organization, but since you are enabled in these resources as the part of the EGI infrastructure, you can access when the research centers have some spare resources. And in this way, the resource providers are also happy since their resources are used in a more efficient way.\nIn summary, the main feature of the EGI High Throughput Compute service are as follows:\n Access to high-quality computing resources Integrated monitoring and accounting tools to provide information about the availability and resource consumption Workload and data management tools to manage all computational tasks Large amounts of processing capacity over long periods of time Faster results for your research Shared resources among users, enabling collaborative research  EGI High Throughput Compute Architecture and the Access Models Architecture and Service Components Key Components:\n Data Transfer Service (FTS) Storage Services Computing Elements (CE): Computing resources are made available through GRID interfaces called Computing Elements. The most common implementations of CEs in the EGI infrastructure are HTCondor-CE and ARC-CE.  Access Models Access to EGI High Throughput Compute resources is based on Virtual Organisations, you will need to enrol into one VO before using the service. VOs for the EGI High Throughput Compute service relies on X.509 proxy certificates with VOMS extensions.\n","excerpt":"What is High Throughput Compute? High Throughput Compute (HTC) can be described as computing …","ref":"/users/high-throughput-compute/","title":"High Throughput Compute"},{"body":"Once the site services are registered in GOCDB (and flagged as \u0026quot;monitored\u0026quot;) they will appear in the EGI service monitoring tools. EGI will check the status of the services (see Infrastructure Status for details). Check if your services are present in the EGI service monitoring tools and passing the tests; if you experience any issues (services not shown, services are not OK...) please contact back EGI Operations or your reference Resource Infrastructure.\nExtra checks for your installation:\n  Check in ARGO-Mon2 that your services are listed and are passing the tests. If all the tests are OK, your installation is already in good shape.\n  Check that you are publishing cloud information in your site BDII: :\nldapsearch -x -h \u0026lt;site bdii host\u0026gt; -p 2170 -b Glue2GroupID=cloud,Glue2DomainID=\u0026lt;your site name\u0026gt;,o=glue   Check that all the images listed in the AppDB for the VOs you support (e.g. AppDB page for fedlcoud.egi.eu VO) are listed in your BDII. This sample query will return all the template IDs registered in your BDII: :\nldapsearch -x -h \u0026lt;site bdii host\u0026gt; -p 2170 -b Glue2GroupID=cloud,Glue2DomainID=\u0026lt;your site name\u0026gt;,o=glue objectClass=GLUE2ApplicationEnvironment GLUE2ApplicationEnvironmentRepository   Try to start one of those images in your cloud. You can do it with [onetemplate instantiate]{.title-ref} or OCCI commands, the result should be the same.\n  Execute the site certification manual tests against your endpoints.\n  Check in the accounting portal that your site is listed and the values reported look consistent with the usage of your site.\n  ","excerpt":"Once the site services are registered in GOCDB (and flagged as \u0026quot;monitored\u0026quot;) they will …","ref":"/providers/cloud-compute/validation/","title":"Installation Validation"},{"body":"If you are in need of more storage than the one provided within image disk of your VMs, or need to persist data independently from the VMs storage, you will need to use one of the solutions available as part of the EGI online storage service.\nThis page describes the Block Storage offering of the online storage which is only accessible from VMs running on the EGI Cloud.\nBlock Storage Block storage provides additional storage blocks which can be attached to a virtual machine. A storage block is a virtual disk of a given size, which can be exposed as a virtual device in the VM. You can think of this can of devices as a USB stick that can be plugged into the VMs and can be used as a regular drive. You can format it with any file system you want and mount it in your VM. Block devices are persistent, thus they keep all the data after VM shutdown and need to be explicitly destroyed when data is not needed anymore. Block storage disks can be accessed only from within a VM, and only from VMs running at the same provider where the block storage is located. Also, they can be accessed by only one VM at the same time. As part of the IaaS service, block storage is managed via OpenStack/OCCI APIs. There is a limit on the number of block storage devices you can attach on a VM and there is a limit to the maximum size of such virtual disks. These values will depend on the particular provider and your SLA. Moreover, the disk space is accounted for the entire block storage device, regardless how much of it is actually used.\nBlock storage is created and managed via requests to specific APIs. Once the storage is attached to a VM, it is managed as a regular disk that can be used as any other disk from within the VM.\nManagement OpenStack providers offer block storage using their native API. Both the CLI client or dashboard can be used. Main commands for managing volumes are listed below:\n   Command function     volume create --size \u0026lt;size\u0026gt; \u0026lt;name\u0026gt; create a volume of size \u0026lt;size\u0026gt; GBs and name \u0026lt;name\u0026gt;   volume list list available volumes   volume show \u0026lt;volume\u0026gt; show details of a given volume   volume delete \u0026lt;volume\u0026gt; deletes a volume   server add volume \u0026lt;server\u0026gt; \u0026lt;volume\u0026gt; Attach a volume to a server   server remove volume \u0026lt;server\u0026gt; \u0026lt;volume\u0026gt; Dettach a volume from a server    For using the legacy OCCI interface refer to OCCI How-to.\nUsing block storage from your VMs Block Storage will appear as block devices into your VM. Usually these devices are empty upon creation. The first time you attach them to a VM, you will need to partition and create filesystems on the device.\nYou can just create a filesystem on the block device with the following command (run this at your VM!).\nDanger Only run this command the first time you use the device, it deletes all data!  # mkfs.ext4 /dev/\u0026lt;volume device\u0026gt; The \u0026lt;volume device\u0026gt; (e.g vdb) can be obtained with the openstack volume show command\nOnce you have a filesystem you can mount it at the desired path:\n# mount /dev/\u0026lt;volume device\u0026gt; /\u0026lt;path\u0026gt; With that you can access /\u0026lt;path\u0026gt; where all your data will be available. Applications will not see any difference between a block storage device and a regular disk, thus no major changes should be required in the application logic.\n","excerpt":"If you are in need of more storage than the one provided within image disk of your VMs, or need to …","ref":"/users/cloud-compute/storage/","title":"Storage"},{"body":"Why joining the EGI Cloud?  To support international communities supported by EGI (e.g. these research communities and applications or these research infrastructures in EOSC-hub or these business pilots in the EOSC Digital Innovation Hub. To participate in e-Infrastructure projects (H2020, EOSC) as an EGI compliant IaaS cloud provider. To participate in resource allocation and in pay-for-use campaigns run by EGI. To align access policies and operational model of your cloud with international good practices. To adopt best practices of multi-cloud federation for the benefit of your local users.  Do I lose control on who can access my resources if I join federated cloud? No. EGI uses the concept of Virtual Organisation (VO) to group users. The resource provider has complete control on which VOs he wants to allow on its resources and which quotas or restrictions to assign to each VO. In the case of OpenStack, each VO is mapped to a regular OpenStack project that can be managed as any other and are isolated to other projects you may have configured in your deployment. Although not recommended, you can even restrict the automatic access of users within a VO and manually enable individual members.\nHow many components do I have to install? Depending on your cloud management framework and the kind of integration this will vary.\nIn general, the federation requires your cloud management framework to be configured to support Federated AAI with EGI Check-in. This may require changes in your current setup.\nOther components are designed to access your cloud management framework public APIs and do not require modification of your deployment. For OpenStack, these components can be run on a single VM that encapsulates them for convenience.\nWhich components of my cloud will interact with the federated cloud components? For OpenStack they are:\n Keystone Nova Glance Swift (optional)  Users will also interact with:\n Neutron Cinder  to perform their regular activities.\nHow will my daily operational activities change? For the most part daily operations will not change.\nA resource centre part of the EGI Federation, and supporting international communities, needs to provide support through the EGI channels. This means following up GGUS tickets. This includes requests from user communities and tickets triggered by failures detected by the monitoring infrastructure.\nA resource centre needs to maintain the services federated in EGI properly configured with the EGI AAI.\nThe resource centre will have to comply with the operational and security requirements. All the EGI policies aim at implementing service provisioning best practices and common requirements. EGI operations may conduct campaigns targeted to mitigate security vulnerabilities and to update unsupported operating system and software. These activities are part of the regular activities of a resource centre anyways (also for the non-federated ones). EGI and the Operations Centres coordinate these actions in order to have them implemented in a timely manner.\nIn summary, most of the site activities that are coordinated by EGI and the NGIs are already part of the work plan of a well-maintained resource centre, the additional task for a site manager is to acknowledge to EGI that the task has been performed.\n","excerpt":"Why joining the EGI Cloud?  To support international communities supported by EGI (e.g. these …","ref":"/providers/cloud-compute/faq/","title":"FAQ"},{"body":"GPU resources on EGI Cloud GPUs resources are available on selected providers of the EGI Cloud. These are available as specific flavours that when used to instantiate a Virtual Machine will make the hardware available to the user.\nThe table below summarises the available options:\n   Site VM configuration options Flavors Supported VOs with GPUs Access conditions     IISAS-GPUCloud up to 2 NVIDIA Tesla K20m gpu1cpu6, gpu2cpu12 acc-comp.egi.eu, eosc-synergy.eu, enmr.eu, training.egi.eu Sponsored access for limited testing, conditions to be negotiated for long-term usage   IISAS-Nebula up to 2 NVIDIA Tesla K20m resource_tpl#large_gpu acc-comp.egi.eu, biomed Sponsored access for limited testing, conditions to be negotiated for long-term usage   IFCA-LCG2 up to 4 NVIDIA GT200GL, up to 1 NVIDIA TITAN X, up to 10 NVIDIA GeForce GTX 1080Ti   Pay-per-use   CESNET-MCC up to 2 NVIDIA T4 hpc.8core-64ram-nvidia-1080-glados, hpc.19core-176ram-nvidia-1080-glados, hpc.38core-372ram-nvidia-1080-glados, hpc.19core-176ram-nvidia-2080-glados, hpc.38core-372ram-nvidia-2080-glados vo.clarin.eu, biomed, eosc-synergy.eu, peachnote.com Sponsored, conditions to be negotiated    Access to GPU resources on EGI Cloud GPUs sites can be accessed by different ways: via site-specific dashboards and endpoints or via common federated-cloud services like common Horizon dashboard, VMOps dashboard, or Infrastructure manager.\nSite-specific dashboards and endpoints are described in the following table:\n   Site Openstack Horizon dashboard Keystone endpoint     IISAS-GPUCloud https://nova3.ui.savba.sk/horizon https://keystone3.ui.savba.sk:5000/   IFCA-LCG2 https://portal.cloud.ifca.es/ https://api.cloud.ifca.es:5000/   CESNET-MCC https://dashboard.cloud.muni.cz/ https://identity.cloud.muni.cz/    A VM image with pre-installed NVIDIA driver and Docker is available at AppDB. Some VOs (acc-comp.egi.eu, eosc-synergy.eu) have the image included in the VO image list.\n","excerpt":"GPU resources on EGI Cloud GPUs resources are available on selected providers of the EGI Cloud. …","ref":"/users/cloud-compute/gpgpu/","title":"GPUs"},{"body":"What is the EGI Workload Manager? The EGI Workload Manager is a service provided to the EGI community to efficiently manage and distribute computing workloads on the EGI infrastructure. The service, based on the DIRAC technology, is configured to support a number of HTC and cloud resource pools from the EGI Federation. This pool of computing resources can be easily extended and customized to support the needs of new scientific communities. In the LHCb experiment the service has proven production scalability up to peaks of more than 100.000 concurrently running jobs. WeNMR, the structural biology community, uses the service for a number of community services. The community reported an improvement of jobs submission in the infrastructure from previous 70% to 99% with the EGI Workload Manager service. The delivery of the service is coordinated by the EGI Foundation and operated by IN2P3 on resources provided by CYFRONET.\nMain Features The EGI Workload Manager:\n  Maximizes usage efficiency by choosing appropriately computing and storage resources on real-time.\n  Provides a large-scale distributed environment to manage and handle data storage, data movement, accessing and processing.\n  Handles job submission and workload distribution in a transparent way.\n  Improves the general job throughput compared with native management of EGI grid or cloud computing resources.\n  Offers pilot-based task scheduling method, that submits pilot jobs to resources to check the execution environment before to start the user\u0026rsquo;s jobs. From a technical standpoint, the user\u0026rsquo;s job description is delivered to the pilot, which prepares its execution environment and executes the user application. The pilot-based scheduling feature solves many problems of using heterogeneity and unstable distributed computing resources.\n  Includes easy extensions to customize the environment checks to address the needs of a particular community. Users can choose appropriately computing and storage resources maximising their usage efficiency for particular user requirements.\n  Handles different storage supporting both cloud and grid capacity.\n  Provides a user-friendly interface that allows users to choose among different DIRAC services.\n  Target User Groups The service suits for the established Virtual Organization communities, long tail of users, SMEs and Industry\n EGI and EGI Federation participants Research communities  Architecture The EGI Workload Manager service is a cluster of DIRAC services running on EGI resources (HTC, CLOUD, HPC) supporting multi-VO. All the DIRAC services are at or above TRL8. The main service components include:\n  Workload Management System (WMS) architecture is composed of multiple loosely coupled components working together in a collaborative manner with the help of a common Configuration Services ensuring reliable service discovery functionality. The modular architecture allows to easily incorporate new types of computing resources as well as new task scheduling algorithms in response to evolving user requirements. DIRAC services can run on multiple geographically distributed servers which increases the overall reliability and excellent scalability properties.\n  REST server providing language neutral interface to DIRAC service.\n  Web portal provides simple and intuitive access to most of the DIRAC functionalities including management of computing tasks and distributed data. It also has a modular architecture designed specifically to allow easy extension for the needs of particular applications.\n  The DIRAC Web portal\nHow to access the EGI Workload Manager service There are several options to access the service:\n Members of a scientific community whose resources pool is already configured in the EGI Workload Manager instance \u0026gt; can use the EGI Workload Manager web portal to access the service, or use DIRAC Client. Individual researchers who want to do some number crunching for a limited period of time, with a reasonable (not too high) number of CPUs \u0026gt; can use the catch-all VO resource pool (vo.access.egi.eu). Submit a request through the EGI Marketplace selecting:\nCompute \u0026gt; Workload Manager from the top menu Representatives of a community who want to try DIRAC and EGI \u0026gt; Same as #2. Representative of a community who wants to request DIRAC for the community\u0026rsquo;s own resource pool \u0026gt; Submit a request through the EGI Marketplace selecting\nCompute \u0026gt; Workload Manager from the top menu  Getting Started Submit a service order via the Marketplace User can request access to the service submitting a service-order to use the EGI HTC service directly from the EOSC or the EGI Marketplace:\nEOSC Marketplace: https://marketplace.eosc-portal.eu/services/egi-workload-manager\nEGI Marketplace: https://marketplace.egi.eu/compute/73-workload-manager.html\nService orders are usually handled within 5 working days by the EGI User Support Team on shift.\nBefore starting Apply for your user credentials DIRAC uses X.509 certificates to identify and authenticate users. These certificates are delivered to each individual by trusted certification authorities. If you have a personal certificate issued by a EUGridPMA-certified authority you can use it for this tutorial. Otherwise refer to the information available in this section, to obtain a certificate. Your certificate may take a few days to be delivered, so please ask for your certificate well in advance and in any case, before the tutorial starts.\nInstall your credentials Your personal certificate is usually delivered to you via a web site and is automatically loaded in your browser. You need to export it from the browser and put it in the appropriate format for DIRAC to use. This is a one-time operation. Please follow the instructions in detailed in VOMS documentation page to export and in install your certificate.\nSend your certificate\u0026rsquo;s subject to the DIRAC team In order to configure the DIRAC server so that you gets registered as a user, the team needs to know your certificate\u0026rsquo;s subject.\nPlease use the command below on any Unix machine and send its output to\ndirac-support \u0026lt;AT\u0026gt; mailman.egi.eu\nopenssl x509 -in $HOME/.globus/usercert.pem -subject -noout The EGI Workload Manager Web Portal To access the EGI Workload Manager open a web browser to: https://dirac.egi.eu/DIRAC/\nThe EGI Workload Manager service Web portal\n  If you are a new user, you can see the welcome page where you can find links to user documentations.\n  VO options: you can switch to different VOs that you have membership.\n  Log In options: the service supports both X.509, Certificate and Check-in log-in.\n  View options: allow to choose either desktop or tabs layout.\n  Menu: a list of tools that enable the selected VO.\n  Upload Proxy Before submitting your job, you need to upload your Proxy. Login to the portal. Go to:\nMenu \u0026gt; Tools \u0026gt; Proxy Upload, enter your certificates .p12 file and the passphrase, click Upload.\nThe wizard to upload the .p12 proxy certificate\nJob Submission Go to:\nMenu \u0026gt; Tools \u0026gt; Job Launchpad. First check the Proxy Status, click it until it shows Valid in green color.\nIn the Job Launchpad, you can select your jobs from the list; add parameters, indicating the output Sandbox location.\nNow, select Helloworld from the job list, and click Submit, you just launch your very first job to the EGI HTC cluster.\nSubmit a job with the Job Launchpad\nMonitor Job status Go to:\nMenu \u0026gt; Applications \u0026gt; Job Monitor.\nThe left panel gives all kinds of search options for your jobs. Set your search criteria, and click Submit, the jobs will list on the right panel.\nTry the various options to view different information about the jobs.\nMonitor the job execution with the Job Monitor panel\nGet Results from Sandbox Once the job has been successfully processed, the Status of the job will change to green. Right click the job, select:\nSandbox \u0026gt; Get Output file(s), you can get the result file(s).\nFull User Guide for DIRAC Web Portal For further instructions, please refer to DIRAC Web Portal Guide\nThe DIRAC client tool The easiest way to install the client is via Docker Container. If you have a Docker client installed in your machine, install the DIRAC CLI as follows:\ndocker run -it -v $HOME:$HOME -e HOME=$HOME diracgrid/client:egi Once the client software is installed, it should be configured in order to access the EGI Workload Manager service:\nsource /opt/dirac/bashrc To proceed further a temporary proxy of the user certificate should be created. This is necessary to get information from the central Configuration Service:\n$ dirac-proxy-init -x Generating proxy... Enter Certificate password: ... Now the client can be configured to work in conjunction with the EGI Workload Manager service:\n$ dirac-configure defaults-egi.cfg Executing: /home/jdoe/DIRAC/DIRAC/Core/scripts/dirac-configure.py defaults-egi.cfg Checking DIRAC installation at \u0026#34;/home/jdoe/DIRAC\u0026#34; Created vomsdir file /home/jdoe/DIRAC/etc/grid-security/vomsdir/vo.formation.idgrilles.fr/cclcgvomsli01.in2p3.fr.lsc [..] Created vomsdir file /home/jdoe/DIRAC/etc/grid-security/vomsdir/fedcloud.egi.eu/voms2.grid.cesnet.cz.lsc Created vomses file `/home/jdoe/DIRAC/etc/grid-security/vomses/fedcloud.egi.eu` Generate the proxy containing the credentials of your VO. Specify the VO in the --group option:\nIn this example, we are going to use the resources allocated for the WeNMR project.\n$ dirac-proxy-init --debug --group wenmr_user -U --rfc $ dirac-proxy-init --debug --group wenmr_user -U --rfc Generating proxy... Enter Certificate password: Contacting CS... Checking DN /DC=org/DC=terena/DC=tcs/C=NL/O=Stichting EGI/CN=Jane Doe jdoe@egi.eu Username is jdoe Creating proxy for jdoe@wenmr_user (/DC=org/DC=terena/DC=tcs/C=NL/O=Stichting EGI/CN=Jane Doe jdoe@egi.eu) Requested adding a VOMS extension but no VOMS attribute defined for group wenmr_user Uploading proxy for wenmr_user... Uploading wenmr_user proxy to ProxyManager... Loading user proxy Uploading proxy on-the-fly Cert file /home/jdoe/.globus/usercert.pem Key file /home/jdoe/.globus/userkey.pem Loading cert and key User credentials loaded Uploading... Proxy uploaded Proxy generated: subject : /DC=org/DC=terena/DC=tcs/C=NL/O=Stichting EGI/CN=Jane Doe jdoe@egi.eu/CN=0123456789 issuer : /DC=org/DC=terena/DC=tcs/C=NL/O=Stichting EGI/CN=Jane Doe jdoe@egi.eu identity : /DC=org/DC=terena/DC=tcs/C=NL/O=Stichting EGI/CN=Jane Doe jdoe@egi.eu timeleft : 23:59:58 DIRAC group : wenmr_user rfc : True path : /tmp/x509up_u0 username : jdoe properties : LimitedDelegation, GenericPilot, Pilot, NormalUser Proxies uploaded: DN | Group | Until (GMT) /DC=org/DC=terena/DC=tcs/C=NL/O=Stichting EGI/CN=Jane Doe jdoe@egi.eu | access.egi.eu_user | 2021/09/14 23:54 /DC=org/DC=terena/DC=tcs/C=NL/O=Stichting EGI/CN=Jane Doe jdoe@egi.eu | fedcloud_user | 2021/09/14 23:54 /DC=org/DC=terena/DC=tcs/C=NL/O=Stichting EGI/CN=Jane Doe jdoe@egi.eu | access.egi.eu_admin | 2021/09/14 23:54 /DC=org/DC=terena/DC=tcs/C=NL/O=Stichting EGI/CN=Jane Doe jdoe@egi.eu | wenmr_user | 2021/09/14 23:54 As a result of this command a user proxy with the same validity period of the certificate is uploaded to the DIRAC ProxyManager service.\nFor checking the details of you proxy, run the following command:\n$ dirac-proxy-info subject : /DC=org/DC=terena/DC=tcs/C=NL/O=Stichting EGI/CN=Jane Doe jdoe@egi.eu/CN=0123456789 issuer : /DC=org/DC=terena/DC=tcs/C=NL/O=Stichting EGI/CN=Jane Doe jdoe@egi.eu identity : /DC=org/DC=terena/DC=tcs/C=NL/O=Stichting EGI/CN=Jane Doe jdoe@egi.eu timeleft : 23:59:26 DIRAC group : wenmr_user rfc : True path : /tmp/x509up_u0 username : jdoe properties : LimitedDelegation, GenericPilot, Pilot, NormalUser Managing simple jobs    DIRAC commands Note     dirac-wms-job-status To check the status of a job   dirac-wms-job-delete To delete a job   dirac-wms-job-logging-info To retrieve history of transitions for a DIRAC job   dirac-wms-job-get-output To retrieve the job output   dirac-wms-job-submit To submit a job    DIRAC commands\nHave a look at the official command reference documentation for the complete list of the Workload Management commands.\nIn general, you can submit jobs, check their status, and retrieve the output. For example:\nCreate a simple JDL file (test.jdl) to submit the job:\n[ JobName = \u0026#34;Simple_Job\u0026#34;; Executable = \u0026#34;/bin/ls\u0026#34;; Arguments = \u0026#34;-ltr\u0026#34;; StdOutput = \u0026#34;StdOut\u0026#34;; StdError = \u0026#34;StdErr\u0026#34;; OutputSandbox = {\u0026#34;StdOut\u0026#34;,\u0026#34;StdErr\u0026#34;}; ] Submit the job:\ndirac-wms-job-submit test.jdl JobID = 53755998 Check the job status:\n$ dirac-wms-job-status 53755998 JobID=23844073 Status=Waiting; MinorStatus=Pilot Agent Submission; Site=ANY; $ dirac-wms-job-status 53755998 JobID=53755998 Status=Done; MinorStatus=Execution Completed; Site=EGI.NIKHEF.nl; Site=EGI.HG-08-Okeanos.gr; Retrieve the outputs of the job (when the status is Done):\n$ dirac-wms-job-get-output --Dir joboutput/ 53755998 Job output sandbox retrieved in joboutput/53755998/ Jobs with Input Sandbox and Output Sandbox In most cases the job input data or executable files are available locally and should be transferred to the grid to run the job. In this case the InputSandbox attribute can be used to move the files together with the job.\nCreate the InputAndOuputSandbox.jdl\nJobName = \u0026#34;InputAndOuputSandbox\u0026#34;; Executable = \u0026#34;testJob.sh\u0026#34;; StdOutput = \u0026#34;StdOut\u0026#34;; StdError = \u0026#34;StdErr\u0026#34;; InputSandbox = {\u0026#34;testJob.sh\u0026#34;}; OutputSandbox = {\u0026#34;StdOut\u0026#34;,\u0026#34;StdErr\u0026#34;}; Create a simple shell script (testJob.sh)\n#!/bin/bash /bin/hostname /bin/date /bin/ls -la After creation of JDL file the next step is to submit the job, using the command:\ndirac-wms-job-submit InputAndOuputSandbox.jdl JobID = XXXXXXXX More details  JDL language and simple jobs submission: JDLs and Job Management Basic Submitting Parametric and MPI jobs, using DIRAC API: Advanced Job Management Past tutorials  Technical Support   DIRAC User Guide: https://dirac.readthedocs.io/en/latest/UserGuide/\n  For technical issues and bug reports, please submit a ticket in GGUS, in Assign to support unit, indicate:\nEGI Services and Service Components \u0026gt; Workload Manager (DIRAC).\n  ","excerpt":"What is the EGI Workload Manager? The EGI Workload Manager is a service provided to the EGI …","ref":"/users/workload-manager/","title":"Workload Manager"},{"body":"Overview The EGI Data Transfer Service is based on the FTS3 service, developed at CERN. It allows you to move any type of data files asynchronously from one storage to another. The service includes dedicated interfaces to display statistics of on-going transfers and manage storage resources parameters.\nThe EGI Data Transfer is ideal to move large amounts of files or very large files as the service has mechanisms to verify checksums and ensure automatic retry in case of failures.\nFeatures  Simplicity  Easy user interfaces for submitting transfers: CLI, Python Bindings, WebFTS and Web Monitoring.\n Reliability  Checksums and retries are provided per transfer\n Flexibility  Multi-protocol support (Webdav/https, GridFTP, xrootd, SRM, S3, GCloud).\n Intelligence  Parallel transfers optimization to get the most from network without burning the storages. Priorities/Activities support for transfers classification.\n  Components  FTS3 Server  The service is responsible of the asynchronous execution of the file transfer, checksumming and retries in case of errors\n FTS3 REST  The RESTFul server which is contacted by clients via REST APIs, CLI and Python bindings\n FTS3 Monitoring  A Web interface to monitor transfers activity and server parameters\n WebFTS  A web interface that provides a file transfer and management solution in order to allow users to invoke reliable, managed data transfers on distributed infrastructures\n  Service Instances EGI has signed OLAs with 2 Providers, CERN and STFC, in order to access their FTS3 Service instances.\nThe following endpoints are available:\nCERN  FTS REST FTS Mon WebFTS - N.B. Needs personal X.509 certificate installed in your Browser  STFC  FTS REST FTS Mon  N.B. if you access the endpoints via Browser the following CA certificates need to be installed:\n CERN CA certificates UK eScience CA certificates  ","excerpt":"Overview The EGI Data Transfer Service is based on the FTS3 service, developed at CERN. It allows …","ref":"/users/data-transfer/","title":"Data Transfer"},{"body":"EC3 (Elastic Cloud Compute Cluster) is a tool to create elastic virtual clusters on Infrastructure as a Service (IaaS) providers, either public (such as Amazon Web Services, Google Cloud or Microsoft Azure) or on-premises (such as OpenNebula and OpenStack). It supports the provisioning of clusters running TORQUE, SLURM, HTCondor, Mesos, Nomad, Kubernetes and others that will be automatically resized to fit the load (e.g. number of jobs at the batch system).\nThe following section of the documentation will guide you on how to:\n Request access to EC3, Deploy simple EC3 elastic cluster on top of the IaaS providers of the EGI Cloud, either using the web interface or the command-line interface, Run pre-configured scientific applications in the EC3 elastic cluster.  ","excerpt":"EC3 (Elastic Cloud Compute Cluster) is a tool to create elastic virtual clusters on Infrastructure …","ref":"/users/cloud-compute/ec3/","title":"EC3"},{"body":"Overview The DataHub allows to:\n Bring data close to the computing to exploit it efficiently. Publish a dataset and make it available to a specific community or worldwide across federated sites.  The main features offered by the DataHub are:\n Discovery of data via a central portal. Access to data conforming to required policies which may be:  unauthenticated open access; access after user registration or access restricted to members of a Virtual Organization (VO).\nThis access may be via a GUI (e.g. a webpage) or an API (e.g. programmatic access to the data)   Replication of data from data providers for resiliency and availability purposes. Replication may take place either on­demand or automatically. Replication will require the introduction of a file catalogue to enable tracking of logical and physical copies of data. Access to data from the AppDB to enable VOs to associate appropriate data with matching Virtual Appliances Authentication and Authorization Infrastructure (AAI) integration between the EGI DataHub and with other EGI components and with user communities existing infrastructure File catalog to track replication of data: logical and physical file  It is based on the OneData technology.\nMotivations  Putting up a (scalable) distributed data infrastructure needs specific expertise, resources and knowledge No easy way to discover and transfer data No easy way of making data (publicly) accessible without transferring it with a sharing service No easy way of combining multiple datasets from different data providers Users need to access data locally and from compute resources  Components and concepts  Space  a virtual volume where users will organize their data. A space is supported by one or multiple Oneproviders providing actual storage resources\n Onezone  a central component federating providers. It takes care of Authentication and Authorization and other management tasks (like space creation). EGI DataHub is a Onezone instance.\n EGI DataHub  the central Onedata Onezone instance of the EGI Federation. Single Sign On (SSO) with all the connected storage providers (Oneprovider) is guaranteed through EGI Check-in\n Oneprovider  a data management component deployed in the data centres, provisioning data and managing transfers. A Oneprovider is typically deployed at a site near the local storage resources, and can access local storage resources over multiple connectors (CEPH, POSIX,...). A default one is operated for EGI by CYFRONET.\n Oneclient  a client application providing access to the spaces through a FUSE mount point (local POSIX access). Spaces are accessible as if they were part of the local file system. Oneclient can be used from VM, containers, desktop,...\nWeb interfaces and APIs are also available\n  Highlighted features Using the EGI DataHub web interface it's possible to manage the space.\nUsing Oneclient it's possible to mount a space locally, and access it over a POSIX interface, using files as they were stored locally. The file's blocks are downloaded on demand.\nIn Onedata the file distribution is done on a block basis, blocks will be replicated on the fly, and it's possible to instrument the replication.\nThree different formats of metadata can be attached to files: basic (key/value), JSON and RDF. The metadata can be managed using the Web interface and the APIs. It's also possible to create indexes and query them.\nIt's possible to view the popularity of a file and manage smart caching.\n","excerpt":"Overview The DataHub allows to:\n Bring data close to the computing to exploit it efficiently. …","ref":"/users/datahub/","title":"DataHub"},{"body":"","excerpt":"","ref":"/users/applications-on-demand/","title":"Applications on Demand (AoD)"},{"body":"The training infrastructure is a resource pool within the EGI Federated Cloud infrascture providing IaaS as well as access services (login, application catalogue and application management portal) for face-to-face events, online training courses or self-paced learning modules.\nThe training infrastructure is integrated with Check-in allowing trainers to generate short-lived user accounts for training participants. Such accounts can identify students individually, and for a limited lifetime - typically few hours or days, depending on the length of the training event - allow them to interact with the services.\nThe infrastructure currently includes enough capacity to scale up to class-room size audiences, approximately up to 100 participants.\nAn introductory slideset and poster of the infrastructure from EGI Community Forum 2015, Bari. (Outdated in some parts).\nUsage models The training infrastructure is suitable for two types of courses:\n Cloud computing courses: Such courses teach students about IaaS clouds and on how Virtual Appliances, Virtual Machines, block storage and other types of \u0026lsquo;low level\u0026rsquo; resources are managed. For such courses, the trainer does not need to deploy applications or online services in advance of the course. The applications/services will be deployed by the students themselves as training exercises. Such courses typically target developers or other rather technical members of scientific communities or projects. Scientific courses: Such courses teach scientists or developers about a specific software suite relevant for their work. For example a specific gene sequence analysis application, an earthquake visualisation tool, or a data processing pipeline. In this operational mode, the trainer deploys the domain specific application/tool on the training infrastructure before the training and the students interact directly with those applications/tools without even knowing where those are deployed and running. Depending on how computationally or data intensive the exercises are, multiple students may share a single software deployment instance, or each student can have their own. The configuration can be controlled by the trainer when the setup is deployed.  In both cases the deployment of applications/tools/services can happen in the form of \u0026lsquo;Virtual Appliances\u0026rsquo; (VAs), and block storage - the latter basically behaving like a virtual USB drive that can be attached/detached to VMs to provide data and storage space for applications.\nThe AppDB has a growing catalogue of Virtual Appliances that includes both basic applications (e.g. latest version of clean Linux distribution) and more specialised applications (e.g. Jupyter Notebook). The list of VAs available on the training infrastructure is configurable and listed in the training.egi.eu VO entry of AppDB.\nThe VMOps can be used as web interface for both trainers and students to deploy and manage VMs.\nAvailable resources The available resources are offered by a set of providers included in the training.egi.eu VO Operation Level Agreement (OLA). Check the document for the exact amount of resources and conditions of access for each provider.\nJoin the training infrastructure! Do you want to join as a resource provider? Please email at support _at_ egi.eu.  The list of providers and VAs is also discoverable in the training.egi.eu VO entry of AppDB. The VO is also described at the EGI Operations Portal training.egi.eu VO id card.\nBooking the infrastructure The infrastructure currently includes enough capacity to scale up to class-room size audiences, approximately up to 100 participants.\nDo you want to book the infrastructure for a course? Please send a request through our website.\n","excerpt":"The training infrastructure is a resource pool within the EGI Federated Cloud infrascture providing …","ref":"/users/training/infrastructure/","title":"Training Infrastructure"},{"body":"Authentication Some EGI services authentication is based on X.509 certificates. The certificates are issued by Certification Authorities (CAs) part of the EUGridPMA federation which is also part of IGTF (International Global Trust Federation).\nThe role of a Certification Authoritie (CA) is to guarantee that users are who they claim to be and are entitled to own their certificate. It is up to the users to discover which CA they should contact. In general, CAs are organised geographically and by research institutes. Each CA has its own procedure to release certificates.\nEGI sites, endpoints and tools accept certificates part of the EUGridPMA distribution. If your community VO is enabled on that site, your certificate will be accepted by that site since all certificates are recognized at site level.\nUsually, a certificate can be installed by command line tools, but they can also be stored in the web browser to access EGI web tools and services.\nGet a Certificate The list of EGI recognised CAs provides a clickable map to find your nearby CA. Several of these offer the option to get an \u0026lsquo;eScience Personal\u0026rsquo; certificate online from the Terena Certificate Service CA. Check the countries where this is available.\nIf eScience Personal certificate is not available in your country, then request a certificate from a regular IGTF CA. The request is normally generated using either a web-based interface or console commands. Details of which type of request a particular CA accepts can be found on each CA\u0026rsquo;s website.\nFor a web-based certificate request, a form must usually be filled in with information such as the name of the user, home institute, etc. After submission, a pair of private and public keys are generated, together with a request for the certificate containing the public key and the user data. The request is then sent to the CA, while the private key stays in the browser, hence the same browser must be used to retrieve the certificate once it is issued.\nUsers must usually install the CA root certificate in their browser first. This is because the CA has to sign the user certificate using its private key, and the user\u0026rsquo;s browser must be able to validate the signature.\nFor some CAs, the certificate requests are generated using a command line interface. The details of the exact command and the requirements of each CA will vary and can be found on the CA\u0026rsquo;s website.\nOnce received the request, the CA will have to confirm your authenticity through your certificate. This usually involves a physical meeting or a phone call with a Registration Authority (RA). A RA is delegated by the CA to verify the legitimacy of a request, and approve it if it is valid. The RA is usually someone at your home institute, and will generally need some kind of ID to prove your identity.\nInstall a Certificate After approval, the certificate is generated and delivered to you. This can be done via e-mail, or by giving instructions to you to download it from a web page.\nBrowser installation Install the certificate in your browser. If you don’t know how to upload your certificate in your browser have a look at the examples.\nHost installation To use EGI services with your certificate, you must first save your certificate to disk.\nThe received certificate will usually be in one of two formats:\n Privacy Enhanced Mail Security Certificate (PEM) with extension .pem or Personal Information Exchange File (PKCS12) with extensions .p12 or .pfx.  The latter is the most common for certificates exported from a browser (e.g. Internet Explorer, Mozilla and Firefox), but the PEM format is currently needed on EGI user interface. The certificates can be converted from one format to the other using the openssl command.\nIf the certificate is in PKCS12 format, then it can be converted to PEM using pkcs12:\n  First you will need to create the private key, use -nocerts. Open your terminal, enter the following command:\nopenssl pkcs12 -nocerts -in my_cert.p12 -out userkey.pem where:\n   File Name Description     my_cert.p12 is the input PKCS12 format file;   userkey.pem is the output private key file;   usercert.pem is the output PEM certificate file.    When prompted to “Enter Import Password”, simply press enter since no password should have been given when exporting from keychain. When prompted to “Enter PEM pass phrase”, enter the pass phrase of your choice, e.g. 1234.\n  Now you can create the certificate, use -clcerts, (use -nokeys hereu will not output private key), and the command is:\nopenssl pkcs12 -clcerts -nokeys -in my_cert.p12 -out usercert.pem When prompted to “Enter Import Password”, simply press enter since no password should have been given when exporting from keychain.\nFor further information on the options of the pkcs12 command, consult man pkcs12\n  It is strongly recommended that the names of all these files are kept as shown. Once in PEM format, the two files, userkey.pem and usercert.pem, should be copied to a User Interface (UI). For example, the ‘standard’ location for Mac would be .globus directory in your $HOME. I.e. $HOME/.globus/\nRenewing the Certificate CAs issue certificates with a limited duration (usually one year); this implies the need to renew them periodically. The renewal procedure usually requires that the certificate holder sends a request for renewal signed with the old certificate and/or that the request is confirmed by a phone call; the details depend on the policy of the CA. The certificate usually needs to be renewed before the old certificate expires; CAs may send an email to remind users that renewal is necessary, but users should try to be aware of the renewal date, and take appropriate action if they are away for extended periods of time.\nTaking Care of Private Keys A private key is the essence of your identity. Anyone who steals it can impersonate the owner and if it is lost, it is no longer possible to do anything. Certificates are issued personally to individuals, and must never be shared with other users. To user EGI services, users must agree to an Acceptable Use Policy, which among other things requires them to keep their private key secure.\nOn a UNIX UI, the certificate and private key are stored in two files. Typically they are in a directory called $HOME/.globus and are named usercert.pem and userkey.pem, and it is strongly recommended that they are not changed. The certificate is public and world-readable, but the key must only be readable by the owner. The key should be stored on a disk local to the user\u0026rsquo;s UI rather than, for example, an NFS-mounted disk. If a certificate has been exported from a browser, a PKCS12-format file (.p12 or .pfx), which contains the private key, will have been locally stored and this file must be either encrypted, hidden or have its access rights restricted to only the owner.\nIf a private key is stored under the Andrew File System (AFS), access is controlled by the AFS Access Control Lists (ACL) rather than the normal file permissions, so users must ensure that the key is not in a publicly-readable area.\nWeb browsers also store private keys internally, and these also need to be protected. The details vary depending on the browser, but password protection should be used if available; this may not be the default (it is not with Internet Explorer). The most secure mode is one in which every use of the private key needs the password to be entered, but this can cause problems as some web sites ask for the certificate many times. Reaching a compromise between security and convenience is vital here, so that neither come too short.\nIt is important not to lose the private key, as this implies loss of all access to the services, and registration will have to be started again from scratch. Having several securely protected copies in different places is strongly advised, so the certificate can be used from a web browser and several UI machines.\nA private key stored on a UI must be encrypted, meaning that a passphrase must be typed whenever it is used. A key must never be stored without a passphrase. The passphrase should follow similar rules to any computer password. Users should be aware of the usual risks, like people watching them type or transmitting the passphrase over an insecure link.\nAuthorisation The sites authorise the access to their resources to a VO according to their own access policies, resource location, how many resources is the VO allowed to use. There are finer authorization policies, including groups, roles, in this way, the users can be structured in a VO. So, it is not a 0/1 authorization policy.\nThe community has full control of the access to the VO according to community authorization policies. The VO membership, groups and roles are managed by VO managers (Privileged VO members) independently by using the Virtual Organization Membership Service (VOMS).\nVOMS The Virtual Organization Membership Service (VOMS) is an attribute authority which serves as central repository for VO user authorization information, providing support for sorting users into group hierarchies, keeping track ofu their roles and other attributes in order to issue trusted attribute certificates and SAML assertions used in the Grid environment for authorization purposes. VOMS is composed of two main components:\n the VOMS core service, which issues attribute certificates to authenticated clients the VOMS Admin service, which is used by VO manager to administer VOs and manage user membership details.  How does it work? Usually, users submit tasks/jobs to the infrastructure that are attached with their own credential, and the credential is attached with a proxy certificate that is a short-term credential signed with the user certificate and is extended with the VO attributes. In general speaking, a user credential is just an ID, and a proxy contains the VO details, so a resource site by receiving the proxy can recognize that the user is part of such a VO with such a role from such a group. A user can be part of multiple VO, thus can generate multiple proxies.\nRegister to a VO Visit Operation Portal to search for existing VOs\n  If there are any community VOs matching your requirements (with Registry System is VOMS), then click Action-\u0026gt; Details to look at the VO information. In the VO Id Card page, click the link for Enrollment Url, it will take you to the VO VOMS page. You should have already discussed with the EGI support team, they would help you to contact the VO managers and get approval for your access.   If there are no relevant VOs, you can send a request to register a new VO. (Note, for EGI services, you should request for VOMS configuration, once VO is configured, you will be notified about your VO VOMS link). More information can be found at Guideline for VO registration. Again, this is usually guided by the EGI support team. You should already have a meeting with them to discuss your requirements. They will help you to get resources from EGI providers, and sign SLA with you.\n  Request your VO membership at VO VOMS page. You will have to enter required information and then wait for approval.\n  Creating a proxy VOMS configuration Every VO needs two different pieces of information:\n the vomses configuration files, where the details of the VO are stored (e.g. name, server, ports). These are stored by default at /etc/vomses and are normally named following this convention: \u0026lt;vo name\u0026gt;.\u0026lt;server name\u0026gt; (e.g. for fedcloud.egi.eu VO, you would have fedcloud.egi.eu.voms1.grid.cesnet.cz and fedcloud.egi.eu.voms2.grid.cesnet.cz. the .lsc files that describe the trust chain of the VOMS server. These are stored at /etc/grid-security/vomsdir/\u0026lt;vo name\u0026gt; and there should be one file for each of the VOMS server of the VO.  You can check specific configuration for your VO at the Operations portal. Normally each VOMS server has a Configuration Info link where the exact information to include in the vomses and .lsc files is shown.\nProxy creation Once you have the VO information configured (vomses and .lsc) and your certificate available in your $HOME/.globus directory you can create a VOMS proxy to be used with clients with:\nvoms-proxy-init --voms \u0026lt;name of the vo\u0026gt; --rfc See for example, using fedcloud.egi.eu VO:\nvoms-proxy-init --voms fedcloud.egi.eu --rfc Enter GRID pass phrase: Your identity: /DC=org/DC=terena/DC=tcs/C=NL/O=EGI/OU=UCST/CN=Enol Fernandez Creating temporary proxy ......................................................... Done Contacting voms1.grid.cesnet.cz:15002 [/DC=cz/DC=cesnet-ca/O=CESNET/CN=voms1.grid.cesnet.cz] \u0026#34;fedcloud.egi.eu\u0026#34; Done Creating proxy ................................................................... Done Your proxy is valid until Mon Feb 4 23:37:21 2019 ","excerpt":"Authentication Some EGI services authentication is based on X.509 certificates. The certificates are …","ref":"/users/check-in/vos/voms/","title":"VOMS"},{"body":"The EGI Federated Cloud is a multi-national cloud system that integrates community, private and/or public clouds into a scalable computing platform for research. The Federation pools services from a heterogeneous set of cloud providers using a single authentication and authorisation framework that allows the portability of workloads across multiple providers and enable bringing computing to data. The current implementation is focused on IaaS services but can be easily applied to PaaS and SaaS layers.\nEach resource centre of the federated infrastructure operates a Cloud Management Framework (CMF) according to its own preferences and constraints and joins the federation by integrating this CMF with components of the EGI service portfolio. CMFs must at least be integrated with EGI AAI so users can access services with a single identity, integration with other components and APIs to be provided are agreed by the community the resource centre provides services to.\nEGI follows a Service Integration and Management (SIAM) approach to manage the federation with processes that cover the different aspects of the IT Service Management. Providers in the federation keep complete control of their services and resources. EGI VO OLAs establish a reliable, trust-based communication channel between the Customer and the providers to agree on the services, their levels and the types of support. The EGI VO OLAs are not legal contracts but, as agreements, they outline the clear intentions to collaborate and support research.\nFederated IaaS The EGI Federated Cloud Infrastructure as a Service (IaaS) resource centres deploy a Cloud Management Framework (CMF) that provide users with an API-based service for management of Virtual Machines and associated Block Storage to enable persistence and Networks to enable connectivity of the Virtual Machines among themselves and third party resources.\nThe IaaS federation is a thin layer that brings the providers together with:\n federated authentication; resource discovery; central VM image catalogue; usage accounting; and monitoring.  The IaaS capabilities (VM, block storage, network management) must be provided via community agreed APIs (OpenStack and/or OCCI are supported at the moment) that allow integration with EGI Check-in for authentication and authorisation of users. Those providers that limit the interaction to web dashboards and do not expose APIs to direct consumption for users cannot be considered part of the EGI IaaS Cloud Compute service.\nThe information system provides a real-time view about the actual capabilities of federation participants. The EGI Configuration Database (GOCDB) contains the list of resource centres and their entry endpoints. Information about these endpoints is expressed in a standard format (GlueSchema 2.1) and pushed to consumers via the Argo Messaging System. The AppDB Information System collects this information in a central service for discovery.\nUsers can instantiate VMs on the providers from a set of Virtual Machine Images available on a central catalogue implemented in AppDB's Cloud Marketplace. Virtual Machine Images are synchronised to the providers periodically using the HEPiX image lists format.\nUsage of resources is gathered centrally using EGI Accounting repository and available for visualisation at EGI Accounting portal.\nThose endpoints published in the EGI Configuration Database are monitored via ARGO. The set of probes check the availability of the providers and their correct functionality.\nUsers and Community platforms built on top of the EGI IaaS can interact with the cloud providers at three different layers:\n Directly using the IaaS APIs to manage individual resources. This option is recommended for pre-existing use cases with requirements on specific APIs. Using IaaS Federated Access Tools that allow managing the complexity of dealing with different providers in a uniform way. These tools include:  IaaS provisioning systems that allow to define infrastructure as code and manage and combine resources from different providers, thus enabling the portability of application deployments between them (e.g. IM or Terraform); and cloud brokers, that provide matchmaking for workloads to available providers (e.g. the INDIGO-DataCloud Orchestrator).   Using the AppDB VMOps dashboard, a web-based GUI that simplifies the management of VMs on any provider of the EGI infrastructure. AppDB VMOps in turn relies on the Infrastructure Manager.  EGI provides ready-to-use software components to enable the federation for OpenStack and OpenNebula. These components rely on public APIs of the IaaS system and use Check-in accounts for authenticating into the provider.\nImplementation AAI Federated identity ensures that users of the federation can use a single account for accessing the resources.\nOpenID Connect Providers of the EGI Cloud support authentication with OAuth2.0 tokens provided by Check-in OpenID Connect Identity provider. Support builds on the AAI guide for SPs with detailed configuration provided at the EGI Cloud integration manual.\nThe integration relies on the OpenStack Keystone OS-FEDERATION API.\nLegacy VOMS / X.509 certificates EGI can support users still using X.509 certificates extended with VO attributes (e.g. acknowledging that the user is member of the VO) in a so called VOMS proxy. This VOMS proxy certificate is used in subsequent calls to the endpoints which map the certificate and VO information via specific integration modules for VOMS authentication.\nThere are two implementations for the support of VOMS proxies:\n KeyStorm provides federated authentication for OpenNebula/rOCCI. Keystone-VOMS is an OpenStack Keystone plugin to enable VOMS authentication. It allows users to get tokens which can be used to access any of the OpenStack services. Users are generated on the fly in Keystone, it does not need regular synchronization with the VO Management server Perun.  Information discovery The information system provides a real-time view about the actual capabilities of federation participants. The information system can be used by both human users and online services.\nConfiguration DataBase EGI\u0026rsquo;s central configuration database (GOCDB) is used to catalogue the static information of the production infrastructure topology. To allow Resource Providers to expose IaaS federation endpoints, the following service types are avialable:\n org.openstack.nova, org.openstack.swift, eu.egi.cloud.accounting, eu.egi.cloud.vm-management.occi, and eu.egi.cloud.vm-metadata.marketplace.  All providers must enter cloud service endpoints to GOCDB to enable integration with EGI..\nThe Cloud-info-provider extracts information from the resource centres using their native APIs and formats it following Glue, and OGC recommended standard. This information is pushed to the Argo Messaging System and consumed by AppDB to provide a central information discovery service that aggregates several other sources of information of the infrastructure on a single endpoint.\nVirtual Machine Image management In a distributed, federated IaaS service, users need solutions for efficiently managing and distributing their VM Images across multiple resource providers. EGI provides a catalogue of Virtual Machine images (VMIs) that allows any user to share their VMI and communities to select those relevant for distribution across providers. These images are automatically replicated at the providers supporting the community and converted as needed to ensure the correct instantiation when used.\nAppDB includes a Virtual Appliance Marketplace supporting Virtual Appliances (VAs), which are clean-and mean virtual machine images designed to run on a virtualisation platform, that provide a software solution out-of-the-box, ready to be used with minimal or no set-up within the IaaS providers.\nAppDB allows representatives of research communities (VOs) to generate a VM image list via GUI that resource centres subscribe to. The subscription enables the periodic download, conversion and storage of those images in the local IaaS image repository. cloudkeeper provides this automated synchronisation between AppDB and OpenStack/OpenNebula.\nAccounting Federated Accounting provides an integrated view about resource/service usage: it pulls together usage information from the federated sites and services, integrates the data and presents them in such a way that both individual users as well as whole communities can monitor their own resource/service usage across the whole federation.\nCloud Usage Record The federated cloud task force has agreed on a Cloud Usage Record, which inherits from the OGF Usage Record. This record defines the data that resource providers must send to EGI\u0026rsquo;s central Accounting repository.\nVersion 0.4 of the Cloud Accounting Usage Record was agreed at the FedCloud Face to Face in Amsterdam in January 2015. A summary table of the format is shown below:\n   Cloud Usage Record Property Type Null Definition     VMUUID varchar(255) No Virtual Machine's Universally Unique Identifier concatenation of CurrentTime, SiteName and MachineName   SiteName varchar(255) No GOCDB SiteName - GOCDB now has cloud service types and a cloud-only site is allowed.   CloudComputeService (NEW) varchar(255)  Name identifying cloud resource within the site. Allows multiple cloud resources within a sitei.e. a level of granularity.   MachineName varchar(255) No VM Id - the site name for the VM   LocalUserId varchar(255)  Local user name   LocalGroupId varchar(255)  Local group name   GlobalUserName varchar(255)  Global identity of user (certificate DN)   FQAN varchar(255)  Use if VOs part of authorization mechanism   Status varchar(255)  Completion status - completed, started or suspended   StartTime datetime  Must be set when Status = started   EndTime datetime  Set to NULL until Status = completed   SuspendDuration datetime  Set when Status = suspended (Timestamp)   WallDuration int  WallClock time - actual time used   CpuDuration int  CPU time consumed (Duration)   CpuCount int  Number of CPUs allocated   NetworkType varchar(255)  Needs clarifying   NetworkInbound int  GB received   NetworkOutbound int  GB sent   PublicIPCount (NEW) int  Number of public IP addresses assigned to VM Not used.   Memory int  Memory allocated to the VM   Disk int  Size in GB allocated to the VM   BenchmarkType (NEW) varchar(255)  Name of benchmark used for normalization of times (eg HEPSPEC06)   Benchmark (NEW) Decimal  Value of benchmark of VM using ServiceLevelType benchmark’   StorageRecordId varchar(255)  Link to other associated storage record Need to check feasibility   ImageId varchar(255)  Every image has a unique ID associated with it. For images from the EGI FedCloud AppDB this should be VMCATCHER_EVENT_AD_MPURI; for images from other repositories it should be a vmcatcher equivalent; for local images - local identifier of the image.   CloudType varchar(255)   Type of cloud infrastructure: OpenNebula; OpenStack; Synnefo; etc.    Public IP Usage Record The fedcloud task force has agreed on an IP Usage Record. The format uses many of the same fields as the Cloud Usage Record. The Usage Record should be a \u0026quot;snapshot\u0026quot; of the number of IPs currently assigned to a user. A table defining v0.2 of the format is shown below:\n   Cloud Usage Record Property Type Null Definition Notes     MeasurementTime datetime No The time the usage was recorded. In the message format, must be a UNIX timestamp, i.e. the number of seconds that have elapsed since 00:00:00 Coordinated Universal Time (UTC), Thursday, 1 January 1970)   SiteName varchar(255) No The GOCDB site assigning the IP    CloudComputeService varchar(255) Yes See Cloud Usage Record    CloudType varchar(255) No See Cloud Usage Record    LocalUser varchar(255) No See Cloud Usage Record    LocalGroup varchar(255) No See Cloud Usage Record    GlobalUserName varchar(255) No See Cloud Usage Record    FQAN varchar(255) No See Cloud Usage Record    IPVersion byte No 4 or 6    IPCount int(11) No The number of IP addresses of IPVersion this user currently assigned to them     A JSON schema defining a valid Public IP Usage message can be found at: https://github.com/apel/apel/blob/9476bd86424f6162c3b87b6daf6b4270ceb8fea6/apel/db/__init__.py\nAPEL and accounting portal Once generated, records are delivered to the central accounting repository using APEL SSM (Secure STOMP Messenger). SSM client packages can be obtained at https://apel.github.io. A Cloud Accounting Summary Usage Record has also been defined and summaries created on a daily basis from all the accounting records received from the Resource Providers are sent to the EGI Accounting Portal. The Accounting portal also runs SSM to receive these summaries and provides a web view of the accounting data received from the Resource Providers.\nAccounting Probes Implementation of the extactor probes for accounting are listed below:\n OpenNebula: https://github.com/the-oneacct-export-project/oneacct-export OpenStack: https://github.com/IFCA/caso  Monitoring Services in the EGI infrastructure are monitored via ARGO. Specific probes to check functionality and availability of services must be provided by service developers, The current set of probes used for monitoring IaaS resources consists of:\n OCCI probes (eu.egi.cloud.OCCI-VM and eu.egi.cloud.OCCI-Context): OCCI-VM creates an instance of a given image by using OCCI, checks its status and deletes it afterwards. OCCI-Context checks that the OCCI interfaces correctly supports the standard and the FedCloud contextualization extension. Accounting probe (eu.egi.cloud.APEL-Pub): Checks if the cloud resource is publishing data to the Accounting repository TCP checks (org.nagios.Broker-TCP, org.nagios.CDMI-TCP, org.nagios.OCCI-TCP and org.nagios.CloudBDII-Check): Basic TCP checks for services. VM Marketplace probe (eu.egi.cloud.AppDB-Update): gets a predetermined image list from AppDB and checks its update interval. Perun probe (eu.egi.cloud.Perun-Check): connects to the server and checks the status by using internal Perun interface  Roadmap The TCB-Cloud board defines the roadmap for the technical evolution of the EGI Cloud. All the components are continuously maintained to:\n Improve their programmability, providing complete APIs specification in adequate format for facilitating the generation clients (e.g. following the OpenAPI initiative and Swagger). Lower the barriers to integrate and operate resource centres in the federation by a) minimizing the number of components used; b) contributing code to upstream distributions; and c) use only public APIs of the Cloud Management Frameworks.  Currently the EGI FedCloud TaskForce is focused on moving to a central operations model, where providers only need to integrate their system with EGI Check-in but do not need to deploy and configure the different tools (accounting, discovery, VMI management, etc.) locally but delegate this to a central EGI team.\n","excerpt":"The EGI Federated Cloud is a multi-national cloud system that integrates community, private and/or …","ref":"/users/cloud-compute/federation/","title":"Federation Architecture and Implementation"},{"body":"The more you go in data analysis, the more you understand that the most suitable tool for coding and visualizing is not a pure code, or SQL IDE, or even simplified data manipulation diagrams (aka workflows or jobs). From some point you realize that you need a mix of these all \u0026ndash; that\u0026rsquo;s what \u0026ldquo;notebook\u0026rdquo; platforms are, with Jupyter being the most popular notebook software out there.\nNotebooks is an 'as a Service' environment based on the Jupyter technology, offering a browser-based, scalable tool for interactive data analysis. The Notebooks environment provides users with notebooks where they can combine text, mathematics, computations and rich media output. EGI Notebooks is a multi-user service and can scale to multiple servers based on the EGI Cloud service.\nEGI Notebooks Unique Features EGI Notebooks provides the well-known Jupyter interface for notebooks with the following added features:\n Integration with EGI Check-in for authentication, login with any EduGAIN or social accounts (e.g. Google, Facebook) Persistent storage associated with each user, available in the notebooks environment. Customisable with new notebook environments, expose any existing notebook to your users. Runs on EGI e-Infrastructure so can easily use EGI compute and storage from your notebooks.  Service Modes We offer different service modes depending on your needs:\n  Individual users can use the centrally operated service from EGI. Users can login, write and play and re-play notebooks just by creating an EGI account. This instance has limits on the amount of resources available for each user (1 CPU core, 1 GB RAM and 10 GB of storage). It will also kill inactive sessions after 1 hour.\n  User communities can have their customised EGI Notebooks service instance. EGI offers consultancy, support, and can operate the setup as well. A community specific setup allows the community to use the community's own Virtual Organisation (i.e. federated compute and storage sites) for Jupyter, add custom libraries into Jupyter (e.g. discipline-specific analysis libraries) or have fine grained control on who can access the instance (based on the information available to the EGI Check-in AAI service).\n  ","excerpt":"The more you go in data analysis, the more you understand that the most suitable tool for coding and …","ref":"/users/notebooks/","title":"Notebooks"},{"body":"Basics How can I get access to the cloud compute service? There is a VO available for 6 months piloting activities that any researcher in Europe can join. Just place an order into the EGI Marketplace.\nHow can I get an OAuth2.0 token? Authentication via CLI or API requires a valid Check-in token. The FedCloud Check-in client allows you to get one as needed. Check the Authentication and Authorisation guide for more information.\nIs OCCI still supported? OCCI is now deprecated as API for the EGI Cloud providers using OpenStack. Some providers still support OCCI (a list of active endpoints can be queried at GOCDB) but it should note be used for any new developments.\nMigration from rOCCI CLI to OpenStack CLI is quite straightforward, we summarize the main commands in rOCCI and OpenStack equivalent in the table below:\n   Action rOCCI OpenStack     List images occi -a list -r os_tpl openstack image list   Describe images occi -a describe -r \u0026lt;image_id\u0026gt; openstack image show \u0026lt;image_id\u0026gt;   List flavors occi -a list -r resorce_tpl openstack flavor list   Describe flavors occi -a describe -r \u0026lt;template_id\u0026gt; openstack flavor show \u0026lt;image_id\u0026gt;   Create VM occi -a create -r compute -t occi.core.title=\u0026quot;MyFirstVM\u0026quot; -M \u0026lt;flavor id\u0026gt; -M \u0026lt;image id\u0026gt; -T user_data=\u0026quot;file://\u0026lt;file\u0026gt;\u0026quot; openstack server create --flavor \u0026lt;flavor\u0026gt; --image \u0026lt;image\u0026gt; --user-data \u0026lt;file\u0026gt; MyFirstVM   Describe VM occi -a describe -r \u0026lt;vm id\u0026gt; openstack server show \u0026lt;vm id\u0026gt;   Delete VM occi -a delete -r \u0026lt;vm id\u0026gt; openstack server delete \u0026lt;vm id\u0026gt;   Create volume occi -a create -r storage -t occi.storage.size='num(\u0026lt;site in GB\u0026gt;)' -t occi.core.title=\u0026lt;storage_resource_name\u0026gt; openstack volume create --size \u0026lt;size in GB\u0026gt; \u0026lt;storage resource name\u0026gt;   List volume occi -a list -r storage openstack volume list   Attach volume occi -a link -r \u0026lt;vm_id\u0026gt; -j \u0026lt;storage_resource_id\u0026gt; openstack server add volume \u0026lt;vm id\u0026gt; \u0026lt;volume id\u0026gt;   Dettach volume occi -a unlink -r \u0026lt;storage_link_id\u0026gt; openstack server remove volume \u0026lt;vm id\u0026gt; \u0026lt;volume id\u0026gt;   Delete volume occi -a delete -r \u0026lt;volume id\u0026gt; openstack volume delete \u0026lt;volume id\u0026gt;   Attach public IP occi -a link -r \u0026lt;vm id\u0026gt; --link /network/public openstack server add floating ip \u0026lt;vm id\u0026gt; \u0026lt;ip\u0026gt;    If you still rely on OCCI for your access, please contact us at support _at_ egi.eu for support on the migration. OpenNebula sites still use OCCI as main API, but its direct use is not recommended as the support will be deprecated. Instead use an Orchestrator like IM for interacting with those sites.\nDiscovery How can I get the list of the EGI Cloud providers? The list of certified providers is available in GOCDB. The egicli endpoint list command can help you to get that list:\n$ egicli endpoint list Site type URL ------------------ ------------------ ------------------------------------------------ IFCA-LCG2 org.openstack.nova https://api.cloud.ifca.es:5000/v3/ IN2P3-IRES org.openstack.nova https://sbgcloud.in2p3.fr:5000/v3 UA-BITP org.openstack.nova https://openstack.bitp.kiev.ua:5000/v3 RECAS-BARI org.openstack.nova https://cloud.recas.ba.infn.it:5000/v3 NCG-INGRID-PT org.openstack.nova https://nimbus.ncg.ingrid.pt:5000/v3 CLOUDIFIN org.openstack.nova https://cloud-ctrl.nipne.ro:443/v3 IISAS-GPUCloud org.openstack.nova https://keystone3.ui.savba.sk:5000/v3/ IISAS-FedCloud org.openstack.nova https://nova.ui.savba.sk:5000/v3/ UNIV-LILLE org.openstack.nova https://thor.univ-lille.fr:5000/v3 INFN-PADOVA-STACK org.openstack.nova https://egi-cloud.pd.infn.it:443/v3 CYFRONET-CLOUD org.openstack.nova https://api.cloud.cyfronet.pl:5000/v3/ SCAI org.openstack.nova https://fc.scai.fraunhofer.de:5000/v3 CESNET-MCC org.openstack.nova https://identity.cloud.muni.cz/v3 INFN-CATANIA-STACK org.openstack.nova https://stack-server.ct.infn.it:35357/v3 CESGA org.openstack.nova https://fedcloud-osservices.egi.cesga.es:5000/v3 100IT org.openstack.nova https://cloud-egi.100percentit.com:5000/v3/ The providers also generate dynamic information about their characteristics via the Argo Messaging System which is easily browsable from AppDB.\nHow can I choose which site to use? Sites offer their resources to users through Virtual Organisations (VO). First, you need to join a Virtual Organisation that matches your research interests, see authorisation section on how VOs work. AppDB shows the supported VOs and for each VO you can browse the resource providers that support it.\nHow can I get information about the available VM images? The Application Database contains information about the VM images available in the EGI Cloud. Within the AppDB Cloud Marketplace, you can look for a VM and get all the information about which VO the VM is associated, the sites where the VM is available and the endpoints and identifiers to use it in practice.\nManaging VMs The disk on my VM is full, how can I get more space? There are several ways to increase the disk space available at the VM. The fastest and easiest one is to use block storage, creating a new storage disk device and attaching it to the VM. Check the storage guide for more information.\nHow can I keep my data after the VM is stopped? After a VM has been stopped and unless backed up in a block storage volume, all data in the VM is destroyed and cannot be recovered. To ensure your data will be available after the VM is deleted, you need to use some form of persistent storage.\nHow can I assign a public IP to my VM? Some providers do not automatically assign a public IP address to a VM during the creation phase. In this case, you can attach a public IP by first allocating a new public IP and then assigning it to the VM.\nHow can I assign a DNS name to my VM? If you need a domain name for your VMs, we offer a Dynamic DNS service that allows any EGI user to create names for VMs under the fedcloud.eu domain.\nJust go to EGI Cloud nsupdate and login with your Check-in account. Once in, you can click on \u0026quot;Add host\u0026quot; to register a new hostname in an available domain.\nWhat is contextualisation? Contextualisation is the process of installing, configuring and preparing software upon boot time on a pre-defined virtual machine image. This way, the pre-defined images can be stored as generic and small as possible, since customisations will take place on boot time.\nContextualisation is particularly useful for:\n Configuration not known until instantiation (e.g. data location). Private Information (e.g. host certs) Software that changes frequently or under development.  Contextualisation requires passing some data to the VMs on instantiation (the context) and handling that context in the VM.\nHow can I inject my public SSH key into the machine? The best way to login into the virtual server is to use SSH keys. If you don't have one, you need to generate it with the ssh-keygen command:\nssh-keygen -f fedcloud This will generate two files:\n fedcloud, the private key. This file should never be shared fedcloud.pub, the public key. That will be sent to your VM.  To inject the public SSH key into the VM you can use the key-name option when creating the VM in OpenStack. Check keypair management option in OpenStack documentation. This key will be available for the default configured user of the VM (e.g. ubuntu for Ubuntu, centos for CentOS).\nYou can also create users with keys with a contextualisation file:\n#cloud-configusers:- name:cloudadmsudo:ALL=(ALL)NOPASSWD:ALLlock-passwd:truessh-import-id:cloudadmssh-authorized-keys:- \u0026lt;pasteherethecontentsofyourSSHkeypubfile\u0026gt; Warning YAML format requires that the spaces at the beginning of each line is respected in order to be correctly parsed by cloud-init.  How can I use a contextualisation file? If you have a contextualisation file, you can use it with the --user-data option to server create in OpenStack.\nopenstack server create --flavor \u0026lt;your-flavor\u0026gt; --image \u0026lt;your image\u0026gt; \\  --user-data \u0026lt;your contextualisation file\u0026gt; \\  \u0026lt;server name\u0026gt;  Note We recommend using cloud-init for contextualisation. EGI images in AppDB do support cloud-init. Check the documentation for more information.  How can I pass secrets to my VMs? EGI Cloud endpoints use HTTPS so information passed to contextualise the VMs can be assumed to be safe and only readable within your VM. However, take into account that anyone with access to the VM may be able to access also the contextualisation information.\nWarning Take into account that anyone with access to the VM may be able to access also the contextualisation information, so ensure that no sensitive data like clear text passwords is used during contextualisation.  How can I use ansible? Ansible relies on ssh for accessing the servers it will configure. VMs at EGI Cloud can be also accessed via ssh, just make sure you inject the correct public keys in the VMs to be able to access.\nIf you don't have public IPs for all the VMs to be managed, you can also use one as a gateway as described in the Ansible FAQ.\n","excerpt":"Basics How can I get access to the cloud compute service? There is a VO available for 6 months …","ref":"/users/cloud-compute/faq/","title":"FAQ"},{"body":"Objectives ","excerpt":"Objectives ","ref":"/users/training/","title":"Training"},{"body":"EGI Foundation - https://www.egi.eu\n","excerpt":"EGI Foundation - https://www.egi.eu","ref":"/_footer/","title":""},{"body":" The documentation covering the EGI Services is maintained by the EGI Community and coordinated by the EGI Foundation. Everyone is invited to participate by following the Contributing Guide.  Acknowledgement  This documentation is written in Markdown built using Hugo and the Docsy Hugo theme.  ","excerpt":" The documentation covering the EGI Services is maintained by the EGI Community and coordinated by …","ref":"/about/","title":"About"},{"body":" Welcome to EGI Documentation! This website hosts the first version of the new EGI documentation.\nIt will be further improved with more sections in the coming months.\nYour feedback and suggestions are welcome! User documentation   Learn More about EGI   Contribute   EGI Documentation for users and service providers.\n\n          Users Contains step-to-step documentation on how to use the EGI services.\nRead more …\n   Providers Depicts how to join the EGI infrastructure as a service providers offering innovative services to the European Research Area.\nRead more …\n   Internal services Hosts the documentation of the EGI services enabling the federation.\nRead more …\n        Learn more about EGI! The EGI Federation is supporting lots of different user communities.\nRead more …\n   Contributions welcome! We do a Pull Request contributions workflow on GitHub. New users are always welcome!\nRead more …\n   Follow us on Twitter! Find out about new features and how our users are using EGI.\nRead more …\n    ","excerpt":"Welcome to EGI Documentation! This website hosts the first version of the new EGI documentation.\nIt …","ref":"/","title":"EGI documentation"},{"body":"Service-specific support can usually be requested using the EGI Helpdesk.\nIt\u0026rsquo;s also always possible to reach us by email using support@egi.eu.\n","excerpt":"Service-specific support can usually be requested using the EGI Helpdesk.\nIt\u0026rsquo;s also always …","ref":"/support/","title":"Support"}]